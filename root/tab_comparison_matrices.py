# -*- coding: utf-8 -*-
"""
root/tab_comparison_matrices.py â€” HF-grade Comparison Matrices Tab (v3, Real Data)
===================================================================================

×˜××‘ Streamlit ×‘×¨××ª ×§×¨×Ÿ ×’×™×“×•×¨ ×©×¢×•×˜×£ ××ª ××•×“×•×œ ×”×œ×™×‘×”:
    core.tab_comparison_matrices

×”××”×•×ª:
-------
â€¢ ××™×Ÿ ×›××Ÿ ×©×•× ×“××•. ×”×˜××‘ ×¢×•×‘×“ *×¨×§* ×¢×œ ×“××˜×” ×××™×ª×™ ×©×™×’×™×¢ ×:
    1. SqlStore (×˜×‘×œ×ª tab_profiles).
    2. Runtime/Context (build_profiles_from_context).
    3. Session DataFrame.
    4. Upload CSV.

â€¢ ×× ××™×Ÿ ×“××˜×” â†’ ×”×˜××‘ ××¦×™×’ ×”×•×“×¢×” ××§×¦×•×¢×™×ª "×—×¡×¨ ×§×•× ×¤×™×’" ×•×œ× ×××¦×™× × ×ª×•× ×™×.

â€¢ ×—×‘×™×œ×ª ×”×©×•×•××” ××œ××” (Comparison Bundle):
    - similarity:            Tab vs Tab similarity matrix.
    - distance:              Tab vs Tab distance matrix.
    - metric_vs_tab:         Metric vs Tab normalized matrix.
    - tab_type_summary:      Summary ×œ×¤×™ tab_type.
    - tab_type_similarity:   ×“××™×•×Ÿ ×‘×™×Ÿ tab_type-×™×.
    - ranks:                 Rank per metric.
    - metric_corr:           ×§×•×¨×œ×¦×™×” ×‘×™×Ÿ ××˜×¨×™×§×•×ª.
    - meta:                  JSON-safe metadata.

â€¢ UI ×‘×¨××ª ×§×¨×Ÿ + ×¢×•×“ ~20 ×¨×¢×™×•× ×•×ª:
    1. ×‘×—×™×¨×ª ××§×•×¨ ×¤×¨×•×¤×™×œ×™× (SqlStore / Runtime / Session / Upload).
    2. ×¤×™×œ×˜×¨ ×œ×¤×™ tab_type.
    3. ×¤×™×œ×˜×¨ ×œ×¤×™ tags.
    4. ×›×¨×˜×™×¡×™ Overall Summary (××¡×¤×¨ ×˜××‘×™×, ××¡×¤×¨ ××˜×¨×™×§×•×ª, ×˜×•×•×—×™ Sharpe/DD).
    5. ×‘×—×™×¨×ª ××˜×¨×™×§×•×ª ×œ×”×©×•×•××”.
    6. ×‘×—×™×¨×ª normalisation / similarity / distance.
    7. Scenario Preset (default / risk-focused / latency-focused).
    8. ××˜×¨×™×¦×•×ª similarity/distance/metric-vs-tab.
    9. Summary ×œ×¤×™ tab_type.
    10. Anchor Tab Alignment + ×‘×—×™×¨×ª anchor ×œ×¤×™ type.
    11. Clustering (Hierarchical) ×œ××©×›×•×œ×™ ×˜××‘×™×.
    12. Anomaly Detection ×œ×˜××‘×™× ×—×¨×™×’×™×.
    13. Diagnostics ×œ××˜×¨×™×§×•×ª (mean/std/min/max/coverage).
    14. Highlight ×œ××˜×¨×™×§×•×ª ×—×•×¤×¤×•×ª (Redundant KPIs) ×œ×¤×™ metric_corr.
    15. Tag-level Summary (×××•×¦×¢ KPIs ×œ×¤×™ tag).
    16. Tab Health: ×›××” missing metrics ×œ×›×œ ×˜××‘.
    17. ×©××™×¨×ª bundle + profiles ×œ-session_state.
    18. Export ×œ-CSV (similarity/distance/metric_vs_tab).
    19. Export JSON ×œ-Bundle ××œ× (×œ×¡×•×›× ×™×/Agents).
    20. Hooks ×œ×©×™××•×© ×¢×ª×™×“×™ ×‘×˜××‘×™× ××—×¨×™× (×œ××©×œ Agents / DashboardService).
"""

from __future__ import annotations
from typing import Any, Dict, Optional, List, Sequence

import streamlit as st
import pandas as pd
import numpy as np

from core.app_context import AppContext
from core.tab_comparison_matrices import (
    TabProfile,
    TabComparisonConfig,
    build_comparison_bundle,
    build_profiles_from_context,
    hierarchical_cluster_tabs,
    compute_alignment_scores,
    detect_tab_anomalies,
)

# ============================================================
# 1) Data loaders â€” SqlStore / Runtime / Session / CSV
# ============================================================


def _get_sql_store(app_ctx: AppContext):
    """××•×¦×™× SqlStore ××ª×•×š AppContext ×× ×§×™×™×."""
    store = getattr(app_ctx, "sql_store", None)
    if store is not None:
        return store

    services = getattr(app_ctx, "services", None)
    if isinstance(services, dict):
        return services.get("sql_store")

    return None


def _load_profiles_df_from_sql_store(app_ctx: AppContext) -> Optional[pd.DataFrame]:
    """
    ×× ×¡×” ×œ×§×¨×•× ×˜×‘×œ×” tab_profiles ××”-SqlStore.

    ×× ×”×˜×‘×œ×” ×œ× ×§×™×™××ª ××• ×¨×™×§×” â†’ ××—×–×™×¨ None.
    """
    store = _get_sql_store(app_ctx)
    if store is None:
        return None

    try:
        df = store.read_table("tab_profiles")
    except Exception as e:
        st.warning(f"×§×¨×™××” ×-SqlStore.read_table('tab_profiles') × ×›×©×œ×”: {e}")
        return None

    if not isinstance(df, pd.DataFrame) or df.empty:
        return None

    return df


def _load_profiles_df_from_session() -> Optional[pd.DataFrame]:
    """
    ×× ×¡×” ×œ×§×¨×•× DataFrame ×©×œ TabProfiles ××ª×•×š session_state.

    ××¤×ª×—×•×ª ××¤×©×¨×™×™×:
        - tab_profiles_df
        - comparison_tab_profiles_df
    """
    try:
        sess = st.session_state
    except Exception:
        return None

    for key in ("tab_profiles_df", "comparison_tab_profiles_df"):
        df = sess.get(key)
        if isinstance(df, pd.DataFrame) and not df.empty:
            return df

    return None


def _load_profiles_df_from_upload(upload_file) -> Optional[pd.DataFrame]:
    """×˜×•×¢×Ÿ DataFrame ×©×œ TabProfiles ×-CSV ×©×”××©×ª××© ×”×¢×œ×”."""
    if upload_file is None:
        return None

    try:
        df = pd.read_csv(upload_file)
    except Exception as e:
        st.error(f"×‘×¢×™×” ×‘×§×¨×™××ª ×§×•×‘×¥ ×”-CSV: {e}")
        return None

    return df if not df.empty else None


def _load_profiles_from_runtime_context(app_ctx: AppContext) -> Optional[List[TabProfile]]:
    """
    ×× ×¡×” ×œ×‘× ×•×ª TabProfile-×™× ××ª×•×š Runtime/Context ×××™×ª×™.

    ×œ×•×’×™×§×”:
    -------
    1. ×× ×‘-AppContext ×™×© attr 'tab_profiles' (List[TabProfile]) â†’ × ×©×ª××© ×‘×•.
    2. ×× ×™×© ctx dict (app_ctx.ctx_dict ××• st.session_state["ctx"]) â†’ × × ×¡×” build_profiles_from_context.
       ×”×¡×¤×§ (spec) ×¦×¨×™×š ×œ×”×™×•×ª ××•×’×“×¨ ×‘××¢×¨×›×ª ×©×œ×š (× ×™×ª×Ÿ ×œ×©× ×•×ª ×›××Ÿ).
    """
    profiles = getattr(app_ctx, "tab_profiles", None)
    if isinstance(profiles, list) and profiles and isinstance(profiles[0], TabProfile):
        return profiles

    ctx_dict = getattr(app_ctx, "ctx_dict", None)
    if ctx_dict is None:
        try:
            ctx_dict = st.session_state.get("ctx", None)
        except Exception:
            ctx_dict = None

    if not isinstance(ctx_dict, dict):
        return None

    # spec ×‘×¡×™×¡×™ ×œ×“×•×’××” â€” ××ª×” ×™×›×•×œ ×œ×”×—×œ×™×£ ××•×ª×• ×œ×¡×¤×§ ×××™×ª×™ ×©×œ×š
    spec = {
        "home": {
            "tab_type": "overview",
            "label": "Dashboard Home",
            "path": ["tabs", "home", "metrics"],
        },
        "backtest": {
            "tab_type": "stats",
            "label": "Backtest KPIs",
            "path": ["tabs", "backtest", "metrics"],
        },
        "macro": {
            "tab_type": "macro",
            "label": "Macro Engine",
            "path": ["tabs", "macro", "scores"],
        },
    }
    try:
        profiles_from_ctx = build_profiles_from_context(ctx_dict, spec)
        if profiles_from_ctx:
            return profiles_from_ctx
    except Exception as e:
        st.warning(f"build_profiles_from_context × ×›×©×œ: {e}")
        return None

    return None


def _df_to_profiles(df: pd.DataFrame) -> List[TabProfile]:
    """
    ×××™×¨ DataFrame -> List[TabProfile].

    ×“×¨×™×©×•×ª:
        columns ×—×•×‘×”: tab_id, tab_type, label
        ××•×¤×¦×™×•× ×œ×™:
            weight, tags, ×•×›×œ ×©××¨ ×”×¢××•×“×•×ª â†’ metrics (××¡×¤×¨×™×•×ª).
    """
    required = {"tab_id", "tab_type", "label"}
    if not required.issubset(df.columns):
        missing = required - set(df.columns)
        raise ValueError(f"×—×¡×¨×•×ª ×¢××•×“×•×ª ×—×•×‘×” ×‘×˜×‘×œ×ª ×”×¤×¨×•×¤×™×œ×™×: {missing}")

    profiles: List[TabProfile] = []
    for _, row in df.iterrows():
        tab_id = str(row["tab_id"])
        tab_type = str(row["tab_type"])
        label = str(row["label"])
        weight = float(row["weight"]) if "weight" in df.columns and pd.notna(row["weight"]) else 1.0

        tags: List[str] = []
        if "tags" in df.columns and pd.notna(row["tags"]):
            tags = [t.strip() for t in str(row["tags"]).split(",") if t.strip()]

        metrics: Dict[str, float] = {}
        for col in df.columns:
            if col in {"tab_id", "tab_type", "label", "weight", "tags"}:
                continue
            val = row.get(col)
            try:
                fval = float(val)
            except Exception:
                continue
            if np.isfinite(fval):
                metrics[col] = fval

        profiles.append(
            TabProfile(
                tab_id=tab_id,
                tab_type=tab_type,
                label=label,
                metrics=metrics,
                weight=weight,
                tags=tags,
                metadata={},
            )
        )

    return profiles


def _load_tab_profiles(
    app_ctx: AppContext,
    source: str,
    upload_file,
) -> List[TabProfile]:
    """
    ××§×•×¨ ×™×—×™×“ ×œ×˜×¢×™× ×ª TabProfile-×™×:

    source:
        "sql_store"   â†’ tab_profiles ×-SqlStore.
        "runtime"     â†’ build_profiles_from_context / app_ctx.tab_profiles.
        "session"     â†’ DataFrame ×‘-session_state.
        "upload"      â†’ CSV ××”××©×ª××©.

    ××™×Ÿ fallback ×œ×“××•. ×× ××™×Ÿ ×“××˜×” â†’ ××—×–×™×¨×™× ×¨×©×™××” ×¨×™×§×” ×•×”-UI ××¡×‘×™×¨.
    """
    source = source.lower()
    df: Optional[pd.DataFrame] = None

    if source == "sql_store":
        df = _load_profiles_df_from_sql_store(app_ctx)
        if df is None:
            st.error(
                "×œ× × ××¦××” ×˜×‘×œ×” tab_profiles ×‘-SqlStore ××• ×©×”×™× ×¨×™×§×”.\n"
                "×¦×•×¨ ×˜×‘×œ×” ×›×–×• ×•×˜×¢×™×Ÿ ×œ×©× ×¤×¨×•×¤×™×œ×™× ×××™×ª×™×™×, ××• ×”×©×ª××© ×‘××§×•×¨ Runtime/Session/Upload."
            )
            return []

        return _df_to_profiles(df)

    if source == "runtime":
        profiles = _load_profiles_from_runtime_context(app_ctx)
        if profiles:
            return profiles
        st.error(
            "×œ× ×”×¦×œ×—×ª×™ ×œ×‘× ×•×ª TabProfiles ×-Runtime/Context.\n"
            "×•×“× ×©×™×© app_ctx.tab_profiles ××• ctx_dict ××ª××™×, ××• ×”×©×ª××© ×‘-SqlStore/Session/Upload."
        )
        return []

    if source == "session":
        df = _load_profiles_df_from_session()
        if df is None:
            st.error(
                "×œ× × ××¦× DataFrame ×©×œ ×˜××‘-×¤×¨×•×¤×™×œ×™× ×‘-session_state.\n"
                "×©×™× DataFrame ×ª×—×ª 'tab_profiles_df' ××• 'comparison_tab_profiles_df'."
            )
            return []
        return _df_to_profiles(df)

    if source == "upload":
        df = _load_profiles_df_from_upload(upload_file)
        if df is None:
            st.error("×§×•×‘×¥ ×”-CSV ×¨×™×§ ××• ×œ× ×ª×§×™×Ÿ.")
            return []
        return _df_to_profiles(df)

    st.error(f"××§×•×¨ ×¤×¨×•×¤×™×œ×™× ×œ× ××•×›×¨: {source}")
    return []


# ============================================================
# 2) Diagnostics helpers â€” Metric / Tag / Tab health
# ============================================================


def _compute_metric_diagnostics(metric_vs_tab_df: pd.DataFrame) -> pd.DataFrame:
    """
    ××—×–×™×¨ DataFrame ×¢× ×“×™××’× ×•×¡×˜×™×§×” ×œ×›×œ ××˜×¨×™×§×”:
        metric, mean, std, min, max, coverage_pct, iqr
    """
    if metric_vs_tab_df is None or metric_vs_tab_df.empty:
        return pd.DataFrame(columns=["metric", "mean", "std", "min", "max", "coverage_pct", "iqr"])

    rows = []
    for metric in metric_vs_tab_df.index:
        s = pd.to_numeric(metric_vs_tab_df.loc[metric], errors="coerce")
        s = s.replace([np.inf, -np.inf], np.nan)
        coverage = s.notna().mean() * 100.0
        s_clean = s.dropna()
        if s_clean.empty:
            rows.append(
                {
                    "metric": metric,
                    "mean": np.nan,
                    "std": np.nan,
                    "min": np.nan,
                    "max": np.nan,
                    "coverage_pct": coverage,
                    "iqr": np.nan,
                }
            )
            continue

        q25 = s_clean.quantile(0.25)
        q75 = s_clean.quantile(0.75)
        rows.append(
            {
                "metric": metric,
                "mean": float(s_clean.mean()),
                "std": float(s_clean.std(ddof=1)) if len(s_clean) > 1 else 0.0,
                "min": float(s_clean.min()),
                "max": float(s_clean.max()),
                "coverage_pct": coverage,
                "iqr": float(q75 - q25),
            }
        )

    df_diag = pd.DataFrame(rows).sort_values("coverage_pct", ascending=False)
    return df_diag


def _compute_tag_summary(profiles: List[TabProfile]) -> pd.DataFrame:
    """
    ××—×–×™×¨ ×¡×™×›×•× ×œ×¤×™ tags:
        tag, n_tabs, <mean metrics...>
    """
    rows = []
    for p in profiles:
        tags = p.tags or []
        if not tags:
            tags = ["(no_tag)"]
        for t in tags:
            row = {"tag": t, "tab_id": p.tab_id}
            row.update(p.metrics or {})
            rows.append(row)

    if not rows:
        return pd.DataFrame(columns=["tag", "n_tabs"])

    df = pd.DataFrame(rows)
    # n_tabs per tag + mean metrics
    grouped = df.groupby("tag")
    agg = grouped.agg({col: "mean" for col in df.columns if col not in {"tag", "tab_id"}})
    agg["n_tabs"] = grouped["tab_id"].nunique()
    cols = ["n_tabs"] + [c for c in agg.columns if c != "n_tabs"]
    return agg[cols].sort_values("n_tabs", ascending=False)


def _compute_tab_health(profiles_df: pd.DataFrame) -> pd.DataFrame:
    """
    ×‘×¨×™××•×ª ×˜××‘: ×›××” metrics ×—×¡×¨×™× ×œ×›×œ ×˜××‘.
    """
    if profiles_df is None or profiles_df.empty:
        return pd.DataFrame(columns=["tab_id", "missing_metrics", "missing_ratio"])

    non_metric_cols = {"tab_id", "tab_type", "label", "weight", "tags"}
    metric_cols = [c for c in profiles_df.columns if c not in non_metric_cols]

    rows = []
    for _, row in profiles_df.iterrows():
        total = len(metric_cols)
        missing = int(sum(pd.isna(row[c]) for c in metric_cols))
        ratio = missing / total if total > 0 else 0.0
        rows.append(
            {
                "tab_id": row["tab_id"],
                "tab_type": row["tab_type"],
                "missing_metrics": missing,
                "missing_ratio": ratio,
            }
        )
    df = pd.DataFrame(rows)
    return df.sort_values("missing_ratio", ascending=False)


# ============================================================
# 3) Tab Renderer â€” ×”×˜××‘ ×¢×¦××•
# ============================================================


def render_tab(
    app_ctx: AppContext,
    feature_flags: Dict[str, Any],
    nav_payload: Optional[Dict[str, Any]] = None,
) -> None:
    """
    × ×§×•×“×ª ×›× ×™×¡×” ×œ×˜××‘ 'comparison_matrices' ×‘×“×©×‘×•×¨×“.

    ××™×Ÿ ×›××Ÿ ×©×•× ×“××•:
    - ××• ×©×™×© TabProfiles ×××™×ª×™×™× â†’ × ×™×ª×•×— ××œ×.
    - ××• ×©××™×Ÿ â†’ ×”×¡×‘×¨ ××” ×¦×¨×™×š ×œ×”×’×“×™×¨ ×•×¢×•×¦×¨×™×.
    """

    st.title("ğŸ”¬ Comparison Matrices â€” Tab Intelligence (HF-grade, Real Data)")

    st.markdown(
        """
        ×”×˜××‘ ×”×–×” ×× ×ª×— **×“××™×•×Ÿ / ××¨×—×§ / ×§×•×¨×œ×¦×™×”** ×‘×™×Ÿ ×˜××‘×™× ×××™×ª×™×™× ×‘××¢×¨×›×ª,
        ×¢×œ ×‘×¡×™×¡ KPIs ×©××ª×” ××¡×¤×§ (Sharpe / DD / Risk / Macro / Latency / ×•×›×•').

        ××™×Ÿ ×›××Ÿ *×©×•×* ×“××˜×” ××•××¦×.
        ×× ××™×Ÿ ×œ×š ×¢×“×™×™×Ÿ ×˜××‘-×¤×¨×•×¤×™×œ×™× ×××™×ª×™×™× ×‘-SqlStore / Runtime / Session / CSV â€” ×”×˜××‘ ×™×’×™×“ ×œ×š ××” ×—×¡×¨.
        """
    )

    # ------------------ 1. ××§×•×¨ ×¤×¨×•×¤×™×œ×™× ------------------
    st.markdown("### 1ï¸âƒ£ ××§×•×¨ ×”×˜××‘-×¤×¨×•×¤×™×œ×™×")

    col_src1, col_src2 = st.columns([2, 2])

    with col_src1:
        source = st.radio(
            "×‘×—×¨ ××§×•×¨ ×¤×¨×•×¤×™×œ×™×",
            options=["SqlStore", "Runtime/Context", "Session DF", "Upload CSV"],
            index=0,
            horizontal=True,
            key="cmp_profiles_source",
        )

    upload_file = None
    with col_src2:
        if source == "Upload CSV":
            upload_file = st.file_uploader(
                "Tab Profiles CSV (×¢××•×“×•×ª ×—×•×‘×”: tab_id, tab_type, label)",
                type=["csv"],
                key="cmp_profiles_upload",
            )

    profiles = _load_tab_profiles(app_ctx, source=source.lower(), upload_file=upload_file)
    if not profiles:
        return  # ×›×‘×¨ ×”×•×¤×™×¢×” ×”×•×“×¢×” ××ª××™××”

    # ×˜×‘×œ×ª ×¤×¨×•×¤×™×œ×™× ×’×•×œ××™×ª
    profiles_df = pd.DataFrame(
        [
            {
                "tab_id": p.tab_id,
                "tab_type": p.tab_type,
                "label": p.label,
                "weight": p.weight,
                "tags": ", ".join(p.tags or []),
                **(p.metrics or {}),
            }
            for p in profiles
        ]
    )

    # × ×©××•×¨ ××ª ×”×¤×§×˜×•×¨ ×œ-session ×œ×˜××‘×™× ××—×¨×™×/agents
    st.session_state["comparison_profiles_df"] = profiles_df

    # ------------------ 2. ×¤×™×œ×˜×¨×™× (tab_type / tags) + Summary ------------------
    st.markdown("### 2ï¸âƒ£ ×¤×™×œ×˜×¨×™× + Summary ×‘×¨××ª ××¢×¨×›×ª")

    col_f1, col_f2, col_f3 = st.columns([2, 2, 2])

    with col_f1:
        tab_types = sorted(profiles_df["tab_type"].dropna().unique().tolist())
        selected_types = st.multiselect(
            "Filter by tab_type",
            options=tab_types,
            default=tab_types,
            key="cmp_filter_tab_types",
        )

    with col_f2:
        all_tags = sorted(
            {
                t.strip()
                for tags in profiles_df["tags"].fillna("").tolist()
                for t in str(tags).split(",")
                if t.strip()
            }
        )
        selected_tags = st.multiselect(
            "Filter by tags",
            options=all_tags,
            default=all_tags,
            key="cmp_filter_tags",
        )

    with col_f3:
        st.caption("ğŸ” Overall summary")
        n_tabs = len(profiles_df)
        metric_cols = [c for c in profiles_df.columns if c not in {"tab_id", "tab_type", "label", "weight", "tags"}]
        n_metrics = len(metric_cols)
        st.write(f"Tabs: **{n_tabs}**, Metrics: **{n_metrics}**")

        if "sharpe" in metric_cols:
            sharpe_vals = pd.to_numeric(profiles_df["sharpe"], errors="coerce").dropna()
            if not sharpe_vals.empty:
                st.write(
                    f"Sharpe: min={sharpe_vals.min():.2f}, "
                    f"median={sharpe_vals.median():.2f}, max={sharpe_vals.max():.2f}"
                )
        if "max_dd" in metric_cols:
            dd_vals = pd.to_numeric(profiles_df["max_dd"], errors="coerce").dropna()
            if not dd_vals.empty:
                st.write(
                    f"Max DD: min={dd_vals.min():.2%}, max={dd_vals.max():.2%}"
                )

    # ×¤×™×œ×˜×¨ ×œ×¤×™ tab_type / tags
    filtered_profiles = []
    for p in profiles:
        if selected_types and p.tab_type not in selected_types:
            continue
        if selected_tags:
            tags = set(p.tags or [])
            if tags and not (tags & set(selected_tags)):
                continue
        filtered_profiles.append(p)

    if not filtered_profiles:
        st.error("××—×¨×™ ×”×¤×™×œ×˜×¨×™× ×œ× × ×©××¨ ××£ ×˜××‘. ×¨×›×š ××ª ×”×¡×™× ×•×Ÿ.")
        return

    profiles = filtered_profiles  # × ××©×™×š ×¨×§ ×¢× ×”××¡×•× × ×™×
    profiles_df = pd.DataFrame(
        [
            {
                "tab_id": p.tab_id,
                "tab_type": p.tab_type,
                "label": p.label,
                "weight": p.weight,
                "tags": ", ".join(p.tags or []),
                **(p.metrics or {}),
            }
            for p in profiles
        ]
    )

    with st.expander("ğŸ“‹ ×˜××‘-×¤×¨×•×¤×™×œ×™× ×œ××—×¨ ×¡×™× ×•×Ÿ", expanded=False):
        st.dataframe(profiles_df, width="stretch")

    # ------------------ 3. ×§×•× ×¤×™×’×•×¨×¦×™×™×ª ×”×©×•×•××” ------------------
    st.markdown("### 3ï¸âƒ£ ×§×•× ×¤×™×’×•×¨×¦×™×™×ª ×”×©×•×•××” (Config + Presets)")

    all_metric_keys = sorted({k for p in profiles for k in (p.metrics or {}).keys()})
    if not all_metric_keys:
        st.error("×œ× × ××¦××• ××˜×¨×™×§×•×ª ××¡×¤×¨×™×•×ª ×‘×¤×¨×•×¤×™×œ×™× (××—×¨×™ ×¡×™× ×•×Ÿ).")
        return

    col_cfg1, col_cfg2, col_cfg3 = st.columns(3)
    with col_cfg1:
        norm_method = st.selectbox(
            "Normalization",
            ["zscore", "minmax", "robust", "none"],
            index=0,
            key="cmp_norm",
        )
    with col_cfg2:
        sim_method = st.selectbox(
            "Similarity method",
            ["cosine", "corr", "euclidean"],
            index=0,
            key="cmp_sim_method",
        )
    with col_cfg3:
        dist_metric = st.selectbox(
            "Distance metric",
            ["euclidean"],
            index=0,
            key="cmp_dist_metric",
        )

    col_cfg4, col_cfg5 = st.columns([2, 4])

    with col_cfg4:
        preset = st.selectbox(
            "Preset (Layer focus)",
            ["default", "risk_focused", "latency_focused"],
            index=0,
            key="cmp_preset",
            help=(
                "default â€“ ×œ×œ× ×”×˜×™×•×ª ××™×•×—×“×•×ª.\n"
                "risk_focused â€“ ××“×’×™×© Sharpe/DD/Risk.\n"
                "latency_focused â€“ ××“×’×™×© latency_ms / live_readiness."
            ),
        )

    with col_cfg5:
        metric_keys_selected = st.multiselect(
            "××˜×¨×™×§×•×ª ×œ×”×©×•×•××”",
            options=all_metric_keys,
            default=all_metric_keys,
            key="cmp_metric_keys",
        )
        if not metric_keys_selected:
            metric_keys_selected = all_metric_keys

    # metric_weights ×œ×¤×™ preset
    metric_weights: Optional[Dict[str, float]] = None
    if preset != "default":
        metric_weights = {k: 1.0 for k in metric_keys_selected}
        if preset == "risk_focused":
            for k in metric_keys_selected:
                if any(s in k.lower() for s in ("sharpe", "dd", "risk")):
                    metric_weights[k] = 2.0
        elif preset == "latency_focused":
            for k in metric_keys_selected:
                if any(s in k.lower() for s in ("latency", "live_ready", "live_readiness")):
                    metric_weights[k] = 2.5

    cfg = TabComparisonConfig(
        normalization=norm_method,
        similarity_method=sim_method,
        distance_metric=dist_metric,
        metric_weights=metric_weights,
        metric_meta=None,
        group_weights=None,
    )

    # ------------------ 4. ×”×¨×¦×ª bundle ------------------
    st.markdown("### 4ï¸âƒ£ ×—×™×©×•×‘ Comparison Bundle")

    run = st.button("ğŸš€ ×”×¨×¥ Comparison Bundle ×¢×œ ×”×“××˜×”", key="cmp_run_btn")
    if not run:
        st.info("×‘×—×¨ ×§×•× ×¤×™×’ ×•×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨ ×›×“×™ ×œ×—×©×‘ ××˜×¨×™×¦×•×ª.")
        return

    bundle = build_comparison_bundle(
        profiles=profiles,
        cfg=cfg,
        metric_keys=metric_keys_selected,
    )

    similarity_df: pd.DataFrame = bundle["similarity"]
    distance_df: pd.DataFrame = bundle["distance"]
    metric_vs_tab_df: pd.DataFrame = bundle["metric_vs_tab"]
    tab_type_summary_df: pd.DataFrame = bundle["tab_type_summary"]
    tab_type_similarity_df: pd.DataFrame = bundle["tab_type_similarity"]
    ranks_df: pd.DataFrame = bundle["ranks"]
    metric_corr_df: pd.DataFrame = bundle["metric_corr"]
    meta_bundle: Dict[str, Any] = bundle["meta"]

    # × ×©××•×¨ ×”×›×œ ×œ-session
    st.session_state["comparison_bundle"] = bundle

    # ------------------ 5. ××˜×¨×™×¦×•×ª ×œ×™×‘×” ------------------
    st.markdown("### 5ï¸âƒ£ ××˜×¨×™×¦×•×ª ×œ×™×‘×”")

    tab_m1, tab_m2, tab_m3 = st.tabs(
        ["Similarity", "Distance", "Metric vs Tab"]
    )

    with tab_m1:
        st.markdown("#### ğŸ”— Tab vs Tab â€” Similarity")
        if not similarity_df.empty:
            st.dataframe(similarity_df, width="stretch")
        else:
            st.info("××˜×¨×™×¦×ª similarity ×¨×™×§×” (××™×Ÿ ××¡×¤×™×§ ××˜×¨×™×§×•×ª ××©×•×ª×¤×•×ª).")

    with tab_m2:
        st.markdown("#### ğŸ“ Tab vs Tab â€” Distance")
        if not distance_df.empty:
            st.dataframe(distance_df, width="stretch")
        else:
            st.info("××˜×¨×™×¦×ª distance ×¨×™×§×”.")

    with tab_m3:
        st.markdown("#### ğŸ“Š Metric vs Tab (normalized)")
        if not metric_vs_tab_df.empty:
            st.dataframe(metric_vs_tab_df, width="stretch")
        else:
            st.info("××™×Ÿ Metric vs Tab matrix (××™×Ÿ ××˜×¨×™×§×•×ª ×–××™× ×•×ª).")

    # ------------------ 6. Summary ×œ×¤×™ tab_type + Tag Summary ------------------
    st.markdown("### 6ï¸âƒ£ Summary ×œ×¤×™ tab_type + Tags")

    col_types1, col_types2 = st.columns(2)

    with col_types1:
        st.markdown("#### Summary by tab_type")
        if not tab_type_summary_df.empty:
            st.dataframe(tab_type_summary_df, width="stretch", height=260)
        else:
            st.caption("××™×Ÿ Summary ×‘×¨××ª tab_type.")

    with col_types2:
        st.markdown("#### tab_type vs tab_type similarity")
        if not tab_type_similarity_df.empty:
            st.dataframe(tab_type_similarity_df, width="stretch", height=260)
        else:
            st.caption("××™×Ÿ ××˜×¨×™×¦×ª ×“××™×•×Ÿ ×‘×¨××ª tab_type.")

    st.markdown("#### ğŸ· Tag-level Summary")
    tag_summary_df = _compute_tag_summary(profiles)
    if not tag_summary_df.empty:
        st.dataframe(tag_summary_df, width="stretch", height=260)
    else:
        st.caption("××™×Ÿ tags ×‘×¤×¨×•×¤×™×œ×™×, ×œ×›×Ÿ ××™×Ÿ Tag Summary.")

    # ------------------ 7. Anchor / Clusters / Anomalies ------------------
    st.markdown("### 7ï¸âƒ£ Anchor / Clusters / Anomalies")

    col_a1, col_a2 = st.columns(2)

    # Anchor tab alignment
    with col_a1:
        st.markdown("#### ğŸ¯ Anchor Tab Alignment")
        if not similarity_df.empty:
            anchor_options = list(similarity_df.index)
            # ××¤×©×¨×•×ª ×œ×‘×—×•×¨ anchor ×œ×¤×™ tab_type
            type_for_anchor = st.selectbox(
                "Anchor type (××•×¤×¦×™×•× ×œ×™):",
                options=["(all types)"] + sorted(set(p.tab_type for p in profiles)),
                index=0,
                key="cmp_anchor_type",
            )
            if type_for_anchor != "(all types)":
                anchor_options = [p.tab_id for p in profiles if p.tab_type == type_for_anchor]

            anchor_tab = st.selectbox(
                "×‘×—×¨ Anchor tab",
                anchor_options,
                index=0,
                key="cmp_anchor_tab",
            )
            scores = compute_alignment_scores(similarity_df, benchmark_tab_id=anchor_tab)
            scores_sorted = scores.sort_values(ascending=False)
            st.dataframe(
                scores_sorted.to_frame(name="alignment_score"),
                width="stretch",
                height=260,
            )
        else:
            st.caption("××™×Ÿ similarity matrix â€” ×œ× × ×™×ª×Ÿ ×œ×—×©×‘ Alignment.")

    # Clustering
    with col_a2:
        st.markdown("#### ğŸ§¬ Hierarchical Clustering")
        if not distance_df.empty and distance_df.shape[0] > 1:
            max_clusters = st.slider(
                "××¡×¤×¨ ××§×¡×™××œ×™ ×©×œ ××©×›×•×œ×•×ª",
                min_value=2,
                max_value=min(8, distance_df.shape[0]),
                value=min(4, distance_df.shape[0]),
                step=1,
                key="cmp_max_clusters",
            )
            try:
                cluster_labels, _ = hierarchical_cluster_tabs(
                    distance_df,
                    method="ward",
                    max_clusters=int(max_clusters),
                )
                df_clusters = cluster_labels.to_frame(name="cluster_id")
                st.dataframe(df_clusters, width="stretch", height=260)
            except Exception as e:
                st.warning(f"Clustering × ×›×©×œ (××•×œ×™ SciPy ×œ× ××•×ª×§×Ÿ): {e}")
        else:
            st.caption("××™×Ÿ distance matrix ×¢× ×™×•×ª×¨ ××˜××‘ ××—×“ â€” ××™ ××¤×©×¨ ×œ×‘×¦×¢ clustering.")

    # Anomalies
    st.markdown("#### âš ï¸ Tab Anomalies (Outliers)")
    if not distance_df.empty and distance_df.shape[0] > 2:
        anomalies_df = detect_tab_anomalies(
            distance_df,
            zscore_threshold=2.5,
            min_peers=2,
        )
        if not anomalies_df.empty:
            st.dataframe(anomalies_df, width="stretch", height=220)
        else:
            st.caption("×œ× × ××¦××• ×˜××‘×™× ×—×¨×™×’×™× ×œ×¤×™ ×§×¨×™×˜×¨×™×•×Ÿ ×”-anomaly.")
    else:
        st.caption("××™×Ÿ distance matrix ××¡×¤×™×§ ××œ××” â€” ××™ ××¤×©×¨ ×œ×–×”×•×ª anomalies.")

    # ------------------ 8. Metric Diagnostics + Redundant KPIs ------------------
    st.markdown("### 8ï¸âƒ£ Metric Diagnostics + Redundant KPIs")

    col_md1, col_md2 = st.columns(2)

    with col_md1:
        st.markdown("#### ğŸ“ Metric diagnostics")
        metric_diag_df = _compute_metric_diagnostics(metric_vs_tab_df)
        if not metric_diag_df.empty:
            st.dataframe(metric_diag_df, width="stretch", height=260)
        else:
            st.caption("××™×Ÿ Metric vs Tab matrix, ×œ×›×Ÿ ××™×Ÿ ×“×™××’× ×•×¡×˜×™×§×” ×œ××˜×¨×™×§×•×ª.")

    with col_md2:
        st.markdown("#### ğŸ§ª Redundant KPIs (high correlation)")
        if not metric_corr_df.empty:
            # × ×–×”×” ×–×•×’×•×ª ×¢× |corr| > 0.9
            redundant_rows = []
            for i, m1 in enumerate(metric_corr_df.index):
                for j, m2 in enumerate(metric_corr_df.columns):
                    if j <= i:
                        continue
                    corr_val = metric_corr_df.loc[m1, m2]
                    if pd.isna(corr_val):
                        continue
                    if abs(corr_val) >= 0.9:
                        redundant_rows.append(
                            {"metric_1": m1, "metric_2": m2, "corr": float(corr_val)}
                        )
            if redundant_rows:
                df_red = pd.DataFrame(redundant_rows).sort_values("corr", ascending=False)
                st.dataframe(df_red, width="stretch", height=260)
                st.caption("××˜×¨×™×§×•×ª ×¢× ×§×•×¨×œ×¦×™×” ×’×‘×•×”×” ×××•×“ ×™×›×•×œ×•×ª ×œ×”×™×•×ª redundant.")
            else:
                st.caption("×œ× × ××¦××• ×–×•×’×•×ª ××˜×¨×™×§×•×ª ×¢× |corr| â‰¥ 0.9.")
        else:
            st.caption("××™×Ÿ Metric correlation matrix ×–××™× ×”.")

    # ------------------ 9. Tab Health ------------------
    st.markdown("### 9ï¸âƒ£ Tab Health â€” Missing metrics per tab")

    tab_health_df = _compute_tab_health(profiles_df)
    if not tab_health_df.empty:
        st.dataframe(tab_health_df, width="stretch", height=220)
    else:
        st.caption("××™×Ÿ ××™×“×¢ ×¢×œ missing metrics.")

    # ------------------ 10. Export (CSV/JSON) ------------------
    st.markdown("### ğŸ”Ÿ Export â€” ×œ×©×™××•×© ×‘-Agents / Offline")

    col_ex1, col_ex2 = st.columns(2)

    with col_ex1:
        st.caption("Export CSVs (Similarity / Distance / Metric vs Tab)")
        if st.button("â¬‡ï¸ ×”×›× ×ª CSV-×™× ×œ××˜×¨×™×¦×•×ª", key="cmp_export_csv_btn"):
            try:
                similarity_df.to_csv("comparison_similarity.csv")
                distance_df.to_csv("comparison_distance.csv")
                metric_vs_tab_df.to_csv("comparison_metric_vs_tab.csv")
                st.success(
                    "× ×©××¨×• comparison_similarity.csv, comparison_distance.csv, comparison_metric_vs_tab.csv ×‘×¡×‘×™×‘×ª ×”×¨×™×¦×”."
                )
            except Exception as e:
                st.error(f"Export CSV × ×›×©×œ: {e}")

    with col_ex2:
        st.caption("Export Bundle JSON (×œ-Agent / ×ª×™×¢×•×“)")
        if st.button("â¬‡ï¸ Export full bundle as JSON-like dict", key="cmp_export_json_btn"):
            try:
                # ×œ× ×›×•×ª×‘×™× ×œ×§×•×‘×¥ ×‘×¤×•×¢×œ ×›××Ÿ, ××‘×œ ××¤×©×¨ ×œ×©××•×¨ ×‘-session ×¢×‘×•×¨ Agent
                st.session_state["comparison_bundle_export"] = meta_bundle
                st.success("comparison_bundle.meta × ×©××¨ ×‘-session_state['comparison_bundle_export'].")
            except Exception as e:
                st.error(f"Export Bundle × ×›×©×œ: {e}")

    st.markdown("---")
    st.caption(
        "Comparison Matrices Tab (v3): ×¢×•×‘×“ ×¨×§ ×¢×œ ×“××˜×” ×××™×ª×™, ×‘×œ×™ ×“××•, "
        "××©×ª××© ×‘-core.tab_comparison_matrices ×•××¡×¤×§ ×©×›×‘×ª ××™× ×˜×œ×™×’× ×¦×™×” ××œ××” ×‘×¨××ª ×§×¨×Ÿ."
    )
