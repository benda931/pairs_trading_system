# -*- coding: utf-8 -*-
"""
root/macro_tab.py â€” ×˜××‘ ×”×ª×××•×ª ×××§×¨×• ×•××¦×‘×™ ×©×•×§ (Tab 8)
========================================================

×˜××‘ ×”×××§×¨×• ×”×•× ×©×›×‘×ª-×¢×œ ×¢×œ ×›×œ ×”××¢×¨×›×ª, ×•××—×‘×¨ ×‘×™×Ÿ:
- ××¦×‘ ×××§×¨×• × ×•×›×—×™ (Snapshot + Regimes)
- ×”×ª×××•×ª ×’×œ×•×‘×œ×™×•×ª ×œ×ª×™×§ (Exposure / Filters / Caps)
- "DNA ×××§×¨×•" ×œ×–×•×’ ×‘×•×“×“
- ×¦×™×¨ ×–××Ÿ ×©×œ ××©×˜×¨×™× ×•×©×•×§×™× (Regime Timeline + Macro Shocks)
- ×›×œ×™ UX ××§×¦×•×¢×™×™× (Presets, Overlays, Backtests)

×©×›×‘×•×ª ×”×œ×•×’×™×§×” (High-Level Design)
----------------------------------
1. Base Layer â€” Global Macro Context
   - ×‘×—×™×¨×ª ×˜×•×•×— ×ª××¨×™×›×™× (Date Range) ×œ×××§×¨×•, ×‘×¨×™×¨×ª ××—×“×œ: ×©× ×” ××—×•×¨×”.
   - ×‘×—×™×¨×ª ×ª×“×™×¨×•×ª ×××§×¨×•: D / W / M (×™×•××™ / ×©×‘×•×¢×™ / ×—×•×“×©×™).
   - ×‘×—×™×¨×ª ×¡×‘×™×‘×ª ×¢×‘×•×“×”: Backtest / Live (×œ×˜×•×‘×ª ×—×™×‘×•×¨ ×œÖ¾IBKR / DuckDB / SQL).
   - ×˜×¢×™× ×ª:
       * MacroBundle (××•×“×œ ×™×©×Ÿ): CPI, Unemployment, Policy Rate, Yield Curve,
         PMI, Credit Spread, Oil, DXY, VIX ×•×›×•'.
       * macro_factors (××•×“×œ ×—×“×©): rate_short / rate_long / slopes / VIX term structure /
         credit_spread / risk_on_proxy / FX ×•×›×•' ×“×¨×š:
             - load_macro_factors(...)
             - add_derived_factors(...)
   - ×‘× ×™×™×ª MacroSnapshot:
       * build_macro_snapshot(macro_df, cfg_factors)
       * summarize_macro_snapshot(snapshot) â†’ ××©×¤×˜ "××¦×‘ ×××§×¨×•" ×§×¦×¨.
       * regimes + group_regimes + summary_label × ×©××¨×™× ×œÖ¾session_state.

2. Portfolio Macro Adjustments â€” ×”×ª×××•×ª ×’×œ×•×‘×œ×™×•×ª ×œ×ª×™×§
   - compute_adjustments(pairs_df, bundle, cfg_macro) â†’ AdjustmentResult:
       * exposure_multiplier â€“ ××§×“× ×’×œ×•×‘×œ×™ ×œ×ª×™×§.
       * pair_adjustments â€“ pair_id â†’ multiplier.
       * filters â€“ pair_id â†’ include True/False.
       * pair_scores â€“ Macro Fit ×œ×›×œ ×–×•×’ (0â€“100).
       * caps_hints â€“ ×¨××–×™ Caps ×œ×¤×™ ×¡×§×˜×•×¨/××–×•×¨/××˜×‘×¢.
       * meta â€“ ×ª××¨×™×š, ××©×˜×¨, mean_score ×•×›×•'.
   - ×”×ª×•×¦××” × ×©××¨×ª ×‘Ö¾session_state (×××¤×©×¨ ×’×™×©×” ××˜××‘×™× ××—×¨×™× ×•××× ×•×¢ ×”××§×–×§×™×•×©×Ÿ).

3. Pair Macro DNA â€” ×¨×’×™×©×•×ª ×××§×¨×• ×œ×–×•×’ ×‘×•×“×“
   - ×‘×—×™×¨×ª ×–×•×’ ×Ö¾pairs_df["pair_id"] + ×‘×—×™×¨×ª ×©×™×˜×ª Spread:
       * log_spread / diff / ratio.
   - ×‘× ×™×™×ª spread_series ××ª×•×š prices_wide (sym_a, sym_b).
   - ×™×™×©×•×¨ macro_df ×œ×¡×“×¨×” ×•×”×¤×§×ª Regime DF:
       * build_macro_regime_series(macro_df) â†’ rates_regime / curve_regime / vol_regime ×•×›×•'.
   - compute_pair_macro_sensitivity(spread_series, macro_df, regime_df, cfg_sens) â†’
       * PairMacroSensitivity:
           - exposures: factor â†’ MacroExposure(beta, tstat, pvalue).
           - regime_perf: regime â†’ RegimePerformance(mean, vol, sharpe, hit_ratio, n_obs).
           - overall_score (0â€“100).
           - summary_text â€“ ×ª×™××•×¨ ×˜×§×¡×˜×•××œ×™ ××™×›×•×ª×™.
       * build_exposures_table(...) / build_regime_performance_table(...) ×œ× ×¨××•×ª.

4. Regime Timeline & Macro Shocks
   - build_macro_regime_series(macro_df) â†’ Regime DF ×œ××•×¨×š ×”×–××Ÿ.
   - Heatmap / Timeline:
       * factorize labels â†’ codes
       * plotly heatmap: X=time, Y=regime_type, color=code.
   - detect_macro_shocks(macro_df) â†’ DataFrame ×¢×:
       * has_shock, shock_factors, severity ×•×›×•'.
   - UX:
       * ×˜×‘×œ××•×ª Tail, ×›×¤×ª×•×¨ ×”×•×¨×“×” CSV, ×•×ª××™×›×” ×œ××—×§×¨ ×•×‘×™×¦×•×¢×™ ×ª×™×§.

5. Advanced UX & Macro Overlays
   - Feature engineering ×œÖ¾macro_factors:
       * Z-window, momentum windows, volatility windows, EWMA, lags, YoY.
   - Presets:
       * Risk-On Friendly / Risk-Off Hedge / Balanced Regime.
       * ×©××™×¨×”/×˜×¢×™× ×” ×©×œ MacroConfig / MacroFactorConfig / PairMacroSensitivityConfig ×›Ö¾JSON.
   - Risk Controls:
       * sizing: invvol / ERC, cov_window, cov_shrink.
       * Sector / Region / Currency caps.
   - Macro Overlay:
       * ×©×™×œ×•×‘ Macro Fit / Sensitivity / Caps ×œ×›×œ ×–×•×’ ×‘×˜×‘×œ×” ××—×ª (â€œOverlay Viewâ€).

6. Integration & State Contract
   - ×¤×•× ×§×¦×™×” ×¦×™×‘×•×¨×™×ª ××—×ª ×‘×œ×‘×“:
       * render(pairs_df: pd.DataFrame, cfg: MacroConfig | None, bundle: MacroBundle | None)
         â†’ AdjustmentResult.
   - ×—×•×–×” state ××•×œ ×©××¨ ×”××¢×¨×›×ª (session_state keys):
       * "macro_adjustments_result" / "macro_tab_result"
       * "macro_meta"
       * "macro_profile"
       * "macro_regimes_prob"
       * "macro_features_df"
       * "macro_shocks_df"
       * "macro_tab_bundle" / "macro_tab_cfg" / "macro_tab_cfg_factors" / "macro_tab_macro_df"

×”×§×•×‘×¥ ×”× ×•×›×—×™ ××—×¨××™ ××š ×•×¨×§ ×¢×œ **UI + ×—×™×‘×•×¨ ×œ×•×’×™×§×”**. ×›×œ ×”×—×™×©×•×‘×™× ×”×¡×˜×˜×™×¡×˜×™×™×/×××§×¨×•
× ×©××¨×™× ×‘××•×“×•×œ×™×: common.macro_adjustments, core.macro_engine, core.macro_data.
"""

from __future__ import annotations

import json
import logging
from dataclasses import dataclass
from typing import (
    Any,
    Dict,
    List,
    Literal,
    Mapping,
    Optional,
    Sequence,
    Tuple,
    TypedDict,
)
from datetime import datetime, timezone

from uuid import uuid4

import pandas as pd
import streamlit as st

# Optional plotting (Heatmaps, timelines, PNG export)
try:
    import plotly.express as px  # type: ignore
    import plotly.io as pio  # type: ignore

    _HAS_PX = True
except Exception:  # noqa: BLE001
    _HAS_PX = False
    pio = None  # type: ignore[assignment]

# Optional YAML export (×ª××™×›×” ×‘×”×•×¨×“×ª ×§×•× ×¤×™×’/×ª×•×¦××” ×›-YAML)
try:
    import yaml  # type: ignore

    _HAS_YAML = True
except Exception:  # noqa: BLE001
    _HAS_YAML = False

# ×× ×•×¢ ×”×××§×¨×• ×”××¨×›×–×™ â€” ×›×œ ×”×—×™×©×•×‘×™× ×”×××™×ª×™×™× (××™×Ÿ ×œ×•×’×™×§×” ×›×¤×•×œ×” ×›××Ÿ)
# ×××§×¨×• ××¢×¨×›×ª×™×ª / ×”×ª×××•×ª ×œ×ª×™×§
from common.macro_adjustments import (
    MacroConfig,
    MacroFactorConfig,
    MacroBundle,
    AdjustmentResult,
    load_macro_bundle,
    compute_adjustments,
    render_streamlit_ui,
)

# ×¤×§×˜×•×¨×™ ×××§×¨×• / Regimes / Snapshot (×× ×™×© ×œ×š common/macro_factors.py)
from common.macro_factors import (
    load_macro_factors,
    add_derived_factors,
    build_macro_snapshot,
    summarize_macro_snapshot,
    build_macro_regime_series,
    detect_macro_shocks,
)

# ×¨×’×™×©×•×ª ×œ×–×•×’ (pair-level macro sensitivity)
from common.macro_sensitivity import (
    PairMacroSensitivityConfig,
    compute_pair_macro_sensitivity,
    build_exposures_table,          # ×˜×‘×œ×ª betas ×œ×¤×§×˜×•×¨×™×
    build_regime_performance_table, # ×‘×™×¦×•×¢×™× ×œ×¤×™ ××©×˜×¨×™× ×œ×–×•×’
)


LOGGER = logging.getLogger("root.macro_tab")

# ××¤×ª×— ×‘×¡×™×¡ ×œ×˜××‘; ××× ×• × ×’×–×¨×™× ×›×œ ×”××¤×ª×—×•×ª ×œ-Streamlit (widgets, flags, state)
TAB_KEY = "macro_root_tab8"


# ---------------------------------------------------------------------------
# ×—×•×–×” state ×•××¤×ª×—×•×ª session_state
# ---------------------------------------------------------------------------


class MacroStateKeys:
    """×§×‘×•×¢×™ ××¤×ª×—×•×ª session_state ×œ×˜××‘ ×”×××§×¨×•.

    ×—×©×•×‘:
    - ××•× ×¢ "magic strings" ××¤×•×–×¨×™× ×‘×§×•×“.
    - ×××¤×©×¨ ×œ×©××¨ ×”×˜××‘×™×/××•×“×•×œ×™× ×œ×“×¢×ª ××” ×‘×“×™×•×§ × ×©××¨ ×ª×—×ª ××™×–×” ××¤×ª×—.
    """

    RESULT: str = "macro_adjustments_result"
    RESULT_ALT: str = "macro_tab_result"

    META: str = "macro_meta"

    PROFILE: str = "macro_profile"
    REGIMES_PROB: str = "macro_regimes_prob"
    FEATURES_DF: str = "macro_features_df"
    SHOCKS_DF: str = "macro_shocks_df"

    BUNDLE: str = "macro_tab_bundle"
    CFG: str = "macro_tab_cfg"
    FACTOR_CFG: str = "macro_tab_cfg_factors"
    MACRO_DF: str = "macro_tab_macro_df"


JSONDict = Dict[str, Any]
MacroFreq = Literal["D", "W", "M"]
MacroEnv = Literal["backtest", "live"]


class MacroMetaPayload(TypedDict, total=False):
    """××‘× ×” ×”××˜×Ö¾×“××˜×” ×©× ×©××¨ ××Ÿ ×”Ö¾AdjustmentResult ×œ×¦×•×¨×š ×“×•×—×•×ª ×•Ö¾UX."""

    ts: str
    apply_mode: str
    exposure_multiplier: float
    pairs: int
    included: int
    regime_label: str
    mean_score: float


def keygen(namespace: str, *parts: object) -> str:
    """×™×•×¦×¨ ××¤×ª×— ×™×™×—×•×“×™ ×¢×§×‘×™ ×œÖ¾Streamlit.

    Parameters
    ----------
    namespace:
        ××¨×—×‘ ×©××•×ª ×‘×¡×™×¡×™ (×œ××©×œ TAB_KEY) ×›×“×™ ×œ×”×™×× ×¢ ××”×ª× ×’×©×•×™×•×ª ×¢× ×˜××‘×™× ××—×¨×™×.
    *parts:
        ×—×œ×§×™× × ×•×¡×¤×™× ×©××–×”×™× ××ª ×”×¨×›×™×‘ (section, widget, sub-key...).

    Returns
    -------
    str
        ××—×¨×•×–×ª ××¤×ª×— ××—×™×“×” ×‘×¡×’× ×•×Ÿ: ``"{namespace}.part1.part2"``.
    """
    tokens = [str(namespace)] + [str(p) for p in parts if p is not None]
    return ".".join(tokens)


def get_flag(name: str, default: bool = False) -> bool:
    """×§×•×¨× ×“×’×œ ×ª×›×•× ×” ×Ö¾session_state (××• ×‘×¨×™×¨×ª ××—×“×œ).

    Notes
    -----
    - ×›×œ ×”×“×’×œ×™× × ×©××¨×™× ×ª×—×ª ×”××¤×ª×—: ``feature_flag.{name}``.
    - ×××¤×©×¨ ×©×œ×™×˜×” ×’×œ×•×‘×œ×™×ª ×¢×œ UX (×”×•×¨×“×•×ª, YAML, × ×™×¡×•×™×™×, debug ×•×›×•').
    """
    key = f"feature_flag.{name}"
    val = st.session_state.get(key, default)
    return bool(val)


def set_flag(name: str, value: bool) -> None:
    """××¢×“×›×Ÿ ×“×’×œ ×ª×›×•× ×” ×‘Ö¾session_state."""
    st.session_state[f"feature_flag.{name}"] = bool(value)


def get_session_uid() -> str:
    """××—×–×™×¨ ××–×”×” ×™×™×—×•×“×™ ×œ×¨×™×¦×” ×”× ×•×›×—×™×ª ×©×œ ×”×˜××‘.

    ××©××© ×œ:
    - ×™×¦×™×¨×ª ××¤×ª×—×•×ª ×™×¦×™×‘×™× ×¢×‘×•×¨ render_streamlit_ui ×•××•×“×•×œ×™× ××—×¨×™×.
    - ×× ×™×¢×ª StreamlitDuplicateElementKey ×›×©×™×© ××¡×¤×¨ ×˜××‘×™×/××¤×œ×™×§×¦×™×•×ª.
    """
    uid = st.session_state.get("session_uid")
    if not isinstance(uid, str) or not uid:
        uid = str(uuid4())
        st.session_state["session_uid"] = uid
    return uid


def state_get(key: str, default: Any = None) -> Any:
    """Wrapper ×§×˜×Ÿ ×œÖ¾session_state.get â€” ×œ×©×™×¤×•×¨ ×§×¨×™××•×ª ×”×§×•×“."""
    return st.session_state.get(key, default)


def state_set(key: str, value: Any) -> None:
    """Wrapper ×§×˜×Ÿ ×œÖ¾session_state[key] = value â€” ××—×™×“ ×‘×›×œ ×”×˜××‘."""
    st.session_state[key] = value


@dataclass
class MacroWorkspace:
    """×ª×¦×•×¨×ª ×¡×‘×™×‘×ª ×”×¢×‘×•×“×” (×©×›×‘×ª ×‘×¡×™×¡) ×©×œ ×˜××‘ ×”×××§×¨×•.

    Attributes
    ----------
    start_date:
        ×ª×—×™×œ×ª ×˜×•×•×— ×”×ª××¨×™×›×™× ×œ×××§×¨×• (××•×¤×¦×™×•× ×œ×™, ×œ×¤×™ ×‘×—×™×¨×ª ×”××©×ª××©).
    end_date:
        ×¡×•×£ ×˜×•×•×— ×”×ª××¨×™×›×™× ×œ×××§×¨×•.
    freq:
        ×ª×“×™×¨×•×ª ×××§×¨×•: "D" / "W" / "M".
    env:
        ×¡×‘×™×‘×ª ×¢×‘×•×“×”: "backtest" / "live".
    """

    start_date: Optional[pd.Timestamp] = None
    end_date: Optional[pd.Timestamp] = None
    freq: MacroFreq = "D"
    env: MacroEnv = "backtest"


@dataclass
class MacroTabState:
    """State ×œ×•×’×™ ××¨×•×›×– ×œ×˜××‘ ×”×××§×¨×• (×œ×œ× ××•×‘×“×Ÿ ×ª××™××•×ª ×œ-session_state).

    ×©×™××•×© ××•×¤×™×™× ×™ (×‘×—×œ×§×™× ×”×‘××™×):
    -------------------------------
    1. ×™×¦×™×¨×ª State ×‘×ª×—×™×œ×ª render():
           ws = MacroWorkspace(...)
           state = MacroTabState(workspace=ws, macro_cfg=cfg, ...)

    2. ××™×œ×•×™ ×©×“×•×ª ××—×•×©×‘×™× ×‘×”××©×š:
           state.macro_df = macro_df
           state.adjustment_result = result
           state.macro_snapshot = snapshot

    3. ×¡× ×›×¨×•×Ÿ ×¢× session_state (×©×§×•×£ ×œ×©××¨ ×”×˜××‘×™×):
           state_set(MacroStateKeys.RESULT, state.adjustment_result)
           state_set(MacroStateKeys.MACRO_DF, state.macro_df)
    """

    workspace: MacroWorkspace
    macro_cfg: MacroConfig
    factor_cfg: Optional[MacroFactorConfig] = None
    pair_sens_cfg: Optional[PairMacroSensitivityConfig] = None
    bundle: Optional[MacroBundle] = None

    # ×ª×•×¦×¨×™× ××—×•×©×‘×™× (×™××•×œ××• ×‘×—×œ×§×™× 2â€“5)
    adjustment_result: Optional[AdjustmentResult] = None
    macro_snapshot: Optional[JSONDict] = None
    macro_df: Optional[pd.DataFrame] = None
    macro_factors_df: Optional[pd.DataFrame] = None
    macro_regime_df: Optional[pd.DataFrame] = None
    macro_regimes_prob: Optional[pd.DataFrame] = None
    macro_features_df: Optional[pd.DataFrame] = None
    macro_shocks_df: Optional[pd.DataFrame] = None
    macro_profile: Optional[Dict[str, JSONDict]] = None

# ---------------------------------------------------------------------------
# Feature Flags, Debug Tools, ×•×œ×™×“×¦×™×”, Meta & KPIs, Live Health
# ---------------------------------------------------------------------------

class MacroDebugPayload(TypedDict, total=False):
    """Payload ×œÖ¾Debug Panels (×œ×©×™××•×© ×¤× ×™××™ ×‘×˜××‘ ×”×××§×¨×•)."""

    snapshot: JSONDict
    meta: MacroMetaPayload
    overlay: Dict[str, JSONDict]


# ===========================================================================
# Feature Flags / × ×™×¡×•×™×™× / Debug
# ===========================================================================


def feature_toggles_ui(namespace: str = TAB_KEY) -> None:
    """UI ×œ× ×™×”×•×œ ×“×’×œ×™ ×ª×›×•× ×” (Feature Flags) ×¨×œ×•×•× ×˜×™×™× ×œ×˜××‘ ×”×××§×¨×•.

    ×“×’×œ×™× ×§×™×™××™×
    -------------
    - macro_download:
        ×××¤×©×¨ ×›×¤×ª×•×¨ ×”×•×¨×“×ª ×ª×•×¦××ª ×”×××§×¨×• (AdjustmentResult + meta) ×›-JSON.
    - export_yaml:
        ×××¤×©×¨ ×”×•×¨×“×ª ×ª×•×¦××” ×’× ×‘×¤×•×¨××˜ YAML (×× PyYAML ××•×ª×§×Ÿ).
    - macro_debug:
        ××¦×™×’ ×ª×™×‘×•×ª Debug ×¢× JSON ×’×•×œ××™ (snapshot / meta / overlay).
    - macro_show_regimes_table:
        ×›××©×¨ ×¤×¢×™×œ, ×™×•×¤×™×¢×• ×’× ×˜×‘×œ××•×ª Regimes ××¤×•×¨×˜×•×ª ×‘× ×•×¡×£ ×œ-Heatmap.
    - macro_warn_pairs_quality:
        ×›××©×¨ ×¤×¢×™×œ, ×™×•×¦×’×• ××–×”×¨×•×ª ××™×›×•×ª ×¢×œ pairs_df (×¢××•×“×•×ª ×—×¡×¨×•×ª ×•×›×•').
    - macro_show_source_summary:
        ×›××©×¨ ×¤×¢×™×œ, ××•×¦×’×ª ×˜×‘×œ×ª ×¡×™×›×•× ×©×œ ××§×•×¨×•×ª ×”×“××˜×” (IBKR / YF / DuckDB / SQL).
    """
    with st.expander("âš™ï¸ ×××¤×™×™× ×™ ×˜××‘ (Feature Flags)", expanded=False):
        dl = st.checkbox(
            "××¤×©×¨ ×”×•×¨×“×ª ×ª×•×¦××” (JSON)",
            value=get_flag("macro_download", False),
            key=keygen(namespace, "ff", "download"),
            help="×›××©×¨ ×¤×¢×™×œ, ×™×•×¦×’ ×›×¤×ª×•×¨ ×”×•×¨×“×” ×©×œ ×ª×•×¦××ª ×”×××§×¨×• ×‘×¡×•×£ ×”×˜××‘.",
        )
        set_flag("macro_download", dl)

        yml = st.checkbox(
            "××¤×©×¨ ×”×•×¨×“×ª YAML",
            value=get_flag("export_yaml", False),
            key=keygen(namespace, "ff", "yaml"),
            help="×“×•×¨×© ××ª ×”×¡×¤×¨×™×™×” 'pyyaml'. ×™×•×¡×™×£ ×›×¤×ª×•×¨ ×”×•×¨×“×ª YAML.",
        )
        set_flag("export_yaml", yml)

        dbg = st.checkbox(
            "××¦×‘ Debug (×”×¦×’ JSON ×’×•×œ××™)",
            value=get_flag("macro_debug", False),
            key=keygen(namespace, "ff", "debug"),
            help="×™×•×¡×™×£ ×ª×™×‘×•×ª ××™×“×¢ ×¢× JSON ×’×•×œ××™ (snapshot/meta/overlay) ×œ××¤×ª×—×™×.",
        )
        set_flag("macro_debug", dbg)

        show_reg_tbl = st.checkbox(
            "×”×¦×’ ×’× ×˜×‘×œ×ª Regimes ××¤×•×¨×˜×ª",
            value=get_flag("macro_show_regimes_table", True),
            key=keygen(namespace, "ff", "reg_tbl"),
            help="×›××©×¨ ×¤×¢×™×œ â€” ×‘× ×•×¡×£ ×œ-Heatmap ×™×•×¦×’×• ×’× ×˜×‘×œ××•×ª Regime DF.",
        )
        set_flag("macro_show_regimes_table", show_reg_tbl)

        warn_pairs = st.checkbox(
            "×”×¦×’ ××–×”×¨×•×ª ××™×›×•×ª ×¢×œ pairs_df",
            value=get_flag("macro_warn_pairs_quality", True),
            key=keygen(namespace, "ff", "warn_pairs"),
            help="××ª×¨×™×¢ ×›××©×¨ ×—×¡×¨×•×ª ×¢××•×“×•×ª ×××§×¨×• ×—×©×•×‘×•×ª ×‘×™×§×•× ×”×–×•×’×•×ª.",
        )
        set_flag("macro_warn_pairs_quality", warn_pairs)

        show_source_summary = st.checkbox(
            "×”×¦×’ ×¡×™×›×•× ××§×•×¨×•×ª ×“××˜×” (IBKR/YF/DuckDB/SQL)",
            value=get_flag("macro_show_source_summary", True),
            key=keygen(namespace, "ff", "src_summary"),
            help="××¦×™×’ ×˜×‘×œ×ª Summary ×¢×œ ××§×•×¨×•×ª ×”×××§×¨×• ×”×¤×¢×™×œ×™×.",
        )
        set_flag("macro_show_source_summary", show_source_summary)

    _render_flags_badge_row()


def _render_flags_badge_row() -> None:
    """×©×•×¨×ª Badges ×§×˜× ×” ×©××¨××” ×‘×–×¨×™×–×•×ª ××™×œ×• ×“×’×œ×™× ×¤×¢×™×œ×™×."""
    flags = {
        "JSON": get_flag("macro_download", False),
        "YAML": get_flag("export_yaml", False) and _HAS_YAML,
        "Debug": get_flag("macro_debug", False),
        "Regimes Tbl": get_flag("macro_show_regimes_table", False),
    }
    parts: List[str] = []
    for name, active in flags.items():
        color = "#16a34a" if active else "#4b5563"
        parts.append(
            "<span style='display:inline-block;margin-right:4px;"
            f"padding:2px 8px;border-radius:999px;background:{color};"
            "color:white;font-size:11px;'>"
            f"{name}"
            "</span>",
        )
    if parts:
        st.markdown(
            "<div style='margin-bottom:6px;'>" + "".join(parts) + "</div>",
            unsafe_allow_html=True,
        )


# ===========================================================================
# ×•×œ×™×“×¦×™×” ×©×œ pairs_df + ×¢×–×¨×™ DataFrame
# ===========================================================================


def _validate_pairs_df(pairs_df: pd.DataFrame) -> List[str]:
    """×‘×•×“×§ ×©×¢××•×“×•×ª ×‘×¡×™×¡ ×§×™×™××•×ª ×•××—×–×™×¨ ×¨×©×™××ª ××–×”×¨×•×ª (×× ×™×©).

    ×‘×“×™×§×•×ª
    -------
    1. pair_id (×—×•×‘×”) â€” ××–×”×” ×™×™×—×•×“×™ ×œ×–×•×’, ××©××© ×›-key ×œ×›×œ ×”××¢×¨×›×•×ª.
    2. ×¢××•×“×•×ª ×××§×¨×• ××•××œ×¦×•×ª (×œ× ×—×•×‘×”, ××š ××—×–×§×•×ª ××ª ×©×›×‘×ª ×”×××§×¨×•):
       - sector / industry
       - region / country
       - currency
       - macro_bucket (×œ××©×œ: Growth, Value, Duration, Cyclical)
       - macro_sensitivity (××™×“×¢ ×§×•×“× ×¢×œ ×¨×’×™×©×•×ª ×××§×¨×•, ×× ×§×™×™×).
    3. ×‘×“×™×§×ª ×›×¤×™×œ×•×™×•×ª:
       - pair_id ×›×¤×•×œ×™×.
    4. ×‘×“×™×§×ª ×›×™×¡×•×™:
       - ×›××” ××—×•×– ××”×–×•×’×•×ª ×—×¡×¨×™× ×œ×”× ×©×“×•×ª ×××§×¨×• "×˜×•×‘×™× ×©×™×”×™×•".
    """
    warnings: List[str] = []

    if pairs_df is None or pairs_df.empty:
        warnings.append("pairs_df ×¨×™×§ â€” ×”×˜××‘ ×™×¤×¢×œ ×‘××¦×‘ ×ª×¦×•×’×” ×‘×œ×‘×“.")
        return warnings

    cols = set(pairs_df.columns)

    # 1. ×—×•×‘×”: pair_id
    required = {"pair_id"}
    missing = required - cols
    if missing:
        warnings.append(f"×—×¡×¨×•×ª ×¢××•×“×•×ª × ×“×¨×©×•×ª ×‘-pairs_df: {sorted(missing)}")

    # 2. ×¢××•×“×•×ª ×××§×¨×• ××•××œ×¦×•×ª
    recommended_sets = [
        {"sector"},
        {"region", "country"},
        {"currency"},
        {"macro_bucket"},
        {"macro_sensitivity"},
    ]
    for rec in recommended_sets:
        if not rec.issubset(cols):
            warnings.append(
                f"×¢××•×“×•×ª ×××§×¨×• ××•××œ×¦×•×ª ×—×¡×¨×•×ª (×œ× ×—×•×‘×” ××‘×œ ×¢×“×™×£): {sorted(rec)}",
            )

    # 3. ×›×¤×™×œ×•×™×•×ª pair_id
    if "pair_id" in cols:
        dup_mask = pairs_df["pair_id"].duplicated(keep=False)
        if bool(dup_mask.any()):
            n_dup = int(dup_mask.sum())
            warnings.append(
                f"× ××¦××• {n_dup} ×¨×©×•××•×ª ×¢× pair_id ×›×¤×•×œ×™× â€” ×›×“××™ ×œ× ×§×•×ª ×œ×¤× ×™ ×©×™××•×© ×××™×ª×™.",
            )

    # 4. ×›×™×¡×•×™ ×©×“×•×ª ×××§×¨×• "×˜×•×‘×™× ×©×™×”×™×•"
    coverage_checks = [
        ("sector", "×›×™×¡×•×™ ×¡×§×˜×•×¨"),
        ("region", "×›×™×¡×•×™ region"),
        ("currency", "×›×™×¡×•×™ ××˜×‘×¢"),
        ("macro_sensitivity", "×›×™×¡×•×™ macro_sensitivity"),
    ]
    for col_name, label in coverage_checks:
        if col_name in cols:
            non_null = pairs_df[col_name].notnull().sum()
            total = len(pairs_df)
            if total > 0:
                coverage = 100.0 * non_null / total
                if coverage < 60.0:
                    warnings.append(
                        f"{label} × ××•×š ({coverage:.1f}%) â€” ××•××œ×¥ ×œ×”×©×œ×™× × ×ª×•× ×™× ×œ× ×™×ª×•×— ×××§×¨×• ××™×›×•×ª×™.",
                    )

    return warnings


def _ensure_pairs_df(pairs_df: Optional[pd.DataFrame]) -> pd.DataFrame:
    """×“×•××’ ×©×ª××™×“ ×™×”×™×” DataFrame '×—×•×§×™' ×œ×˜××‘.

    - ×× pairs_df None ××• ×¨×™×§ â†’ ×™×•×—×–×¨ DF ×¨×™×§ ×¢× pair_id (×œ×™×¦×™×‘×•×ª ×”-UI).
    - ×× ×—×¡×¨×” ×¢××•×“×ª pair_id â†’ × ×™×™×¦×¨ ××•×ª×” ××ª×•×š index.
    """
    if pairs_df is None or pairs_df.empty:
        return pd.DataFrame({"pair_id": pd.Index([], name="pair_id")})
    if "pair_id" not in pairs_df.columns:
        df = pairs_df.copy()
        df["pair_id"] = df.index.astype(str)
        return df
    return pairs_df

def _pairs_list_to_df_for_tab(pairs: List[Any]) -> pd.DataFrame:
    """
    ×××™×¨ ××ª ×”-list ×©××’×™×¢ ××”-dashboard.get_pairs(...)
    ×œ-DataFrame ×¢× pair_id ×•×¢××•×“×•×ª sym_x/sym_y ×‘×¡×™×¡×™×•×ª.

    ×–×” ×××¤×©×¨ ×œ×˜××‘ ×”×××§×¨×• ×œ×¢×‘×•×“ ×¢× ×”-API ×”×—×“×© ×©×œ ×”×“×©×‘×•×¨×“,
    ×©×‘×• ×”××¢×‘×¨ ×”×•× pairs ×‘×ª×•×¨ list (str/dict/tuple), ×•×œ× DataFrame.
    """
    # ×× ×›×‘×¨ ×§×™×‘×œ× ×• DataFrame â€“ ×¨×§ × ×“××’ ×©×”×•× ×ª×§×™×Ÿ
    if isinstance(pairs, pd.DataFrame):
        return _ensure_pairs_df(pairs)

    rows: List[Dict[str, Any]] = []
    for p in pairs:
        pair_id: str
        sym_x: Optional[str] = None
        sym_y: Optional[str] = None

        if isinstance(p, dict):
            sym_x = p.get("sym_x") or p.get("a") or p.get("symbol_a")
            sym_y = p.get("sym_y") or p.get("b") or p.get("symbol_b")
            pair_id = (
                p.get("pair_id")
                or p.get("pair")
                or (f"{sym_x}-{sym_y}" if sym_x and sym_y else str(p))
            )
        elif isinstance(p, (list, tuple)) and len(p) == 2:
            sym_x, sym_y = str(p[0]), str(p[1])
            pair_id = f"{sym_x}-{sym_y}"
        elif isinstance(p, str):
            s = p.strip()
            # ××¤×¨×™×“×™× × ×¤×•×¦×™× ×‘×™×Ÿ ×–×•×’×•×ª
            for sep in ("-", "/", "|", ":", ","):
                if sep in s:
                    a, b = s.split(sep, 1)
                    sym_x, sym_y = a.strip(), b.strip()
                    break
            if sym_x is None or sym_y is None:
                # ×× ×œ× ×–×™×”×™× ×• ××¤×¨×™×“ â€“ × × ×™×— ×¡×™××‘×•×œ ×‘×•×“×“
                sym_x = sym_y = s
            pair_id = f"{sym_x}-{sym_y}"
        else:
            sym_x = sym_y = str(p)
            pair_id = sym_x

        rows.append(
            {
                "pair_id": str(pair_id),
                "sym_x": sym_x,
                "sym_y": sym_y,
            },
        )

    df = pd.DataFrame(rows)
    return _ensure_pairs_df(df)

def _render_pairs_warnings(pairs_df: pd.DataFrame) -> None:
    """××¦×™×’ ××–×”×¨×•×ª ××™×›×•×ª ×¢×œ pairs_df ×× feature-flag ×¨×œ×•×•× ×˜×™ ×¤×¢×™×œ."""
    if not get_flag("macro_warn_pairs_quality", True):
        return
    msgs = _validate_pairs_df(pairs_df)
    for msg in msgs:
        st.info(f"â„¹ï¸ {msg}")


# ===========================================================================
# Meta stamping (macro_meta) + KPIs ×¢×œ×™×•× ×™× + ×¢×–×¨×™ ×–××Ÿ/×”×¡×‘×¨
# ===========================================================================


def _stamp_result(result: AdjustmentResult, cfg: MacroConfig) -> None:
    """×©×•××¨ Meta ××¨×•×›×– ×¢×œ ×ª×•×¦××ª ×”×××§×¨×• ×‘-session_state.

    × ×©××¨×™×:
    --------
    - ts:        ×—×•×ª××ª ×–××Ÿ UTC ISO.
    - apply_mode:××¦×‘ ×™×™×©×•× (×œ××©×œ 'hybrid' / 'caps_only' ... ××ª×•×š MacroConfig).
    - exposure_multiplier:××§×“× ×—×©×™×¤×” ×’×œ×•×‘×œ×™.
    - pairs:     ××¡×¤×¨ ×–×•×’×•×ª ×©×™×© ×œ×”× pair_adjustments.
    - included:  ×›××” ×–×•×’×•×ª ××¡×•×× ×™× ×›-include=True.
    - regime_label: ×ª×’ ××©×˜×¨ ×××§×¨×• ××—×•×©×‘ (risk_on / risk_off / stagflation ×•×›×•').
    - mean_score: ×¦×™×•×Ÿ ×××•×¦×¢ (×× ×§×™×™× ×‘-result.meta).

    × ×©××¨ ×ª×—×ª:
    - MacroStateKeys.META  (modern)
    - "macro_meta"         (×ª××™××•×ª ×œ××—×•×¨)
    """
    try:
        from datetime import datetime as _dt

        # × ×™×¡×™×•×Ÿ ×¨××©×•×Ÿ: ×× ×›×‘×¨ ×™×© label ×‘× ×•×™
        regime_label: Optional[str] = getattr(result, "regime_label", None)

        # × ×™×¡×™×•×Ÿ ×©× ×™: × ×‘× ×” label ××ª×•×š regime_snapshot (risk_on / growth / inflation)
        if not regime_label and getattr(result, "regime_snapshot", None) is not None:
            snap = getattr(result, "regime_snapshot") or {}
            try:
                r = float(snap.get("risk_on", 0.0))
                g = float(snap.get("growth", 0.0))
                i = float(snap.get("inflation", 0.0))
            except Exception:  # noqa: BLE001
                r, g, i = 0.0, 0.0, 0.0

            if r < -0.5 or (g < -0.4 and i < 0):
                regime_label = "risk_off"
            elif i > 0.4 and g < 0:
                regime_label = "stagflation"
            elif i > 0 and g > 0.2:
                regime_label = "reflation"
            elif g < -0.2 and r <= 0.2:
                regime_label = "slowdown"
            else:
                regime_label = "risk_on" if r > 0 else "neutral"

        meta: MacroMetaPayload = {
            "ts": _dt.utcnow().isoformat(timespec="seconds") + "Z",
            "apply_mode": str(getattr(cfg, "apply_mode", "hybrid")),
            "exposure_multiplier": float(getattr(result, "exposure_multiplier", 1.0)),
            "pairs": int(len(getattr(result, "pair_adjustments", {}) or {})),
            "included": int(
                sum(1 for v in (getattr(result, "filters", {}) or {}).values() if v),
            ),
        }
        if regime_label is not None:
            meta["regime_label"] = str(regime_label)

        meta_from_result = getattr(result, "meta", {}) or {}
        if "mean_score" in meta_from_result:
            try:
                meta["mean_score"] = float(meta_from_result["mean_score"])
            except Exception:  # noqa: BLE001
                pass

        # ×©××™×¨×” ×‘-session_state ×œ×¤×™ ×”×—×•×–×”
        state_set(MacroStateKeys.META, meta)
        # ×ª××™××•×ª ×œ××—×•×¨ ×œ×©××¨ ×”×§×•×“ ×‘××¢×¨×›×ª
        st.session_state["macro_meta"] = dict(meta)
    except Exception:  # noqa: BLE001
        LOGGER.debug("_stamp_result: skip meta save", exc_info=True)


def _explain_regime_label(label: str) -> str:
    """×”×¡×‘×¨ ×˜×§×¡×˜×•××œ×™ ×§×¦×¨ ×œ-regime_label (×œ×”×¦×’×” ××ª×—×ª ×œ-KPIs)."""
    mapping = {
        "risk_on": "×¡×‘×™×‘×” ×ª×•××›×ª ×¡×™×›×•×Ÿ â€” ×× ×™×•×ª ×•××¡×˜×¨×˜×’×™×•×ª ×¤×¨×•-×¡×™×›×•×Ÿ ×‘×“\"×› × ×”× ×•×ª.",
        "risk_off": "×¡×‘×™×‘×ª Risk-off â€” ×‘×¨×™×—×” ××¡×™×›×•×Ÿ, ×”×¢×“×¤×ª ××§×œ×˜×™× ×‘×˜×•×—×™×.",
        "stagflation": "××™× ×¤×œ×¦×™×” ×’×‘×•×”×” + ×¦××™×—×” ×—×œ×©×” â€” ×¡×‘×™×‘×ª ×××§×¨×• ×§×©×” ×œ× ×›×¡×™ ×¡×™×›×•×Ÿ.",
        "reflation": "×—×–×¨×” ×œ×¦××™×—×” ×¢× ××™× ×¤×œ×¦×™×” ××ª×•× ×” â€” ×˜×•×‘ ×œ×¨×•×‘ ×”× ×›×¡×™× ×”×¨×™××œ×™×™×.",
        "slowdown": "×”××˜×” ×‘×¦××™×—×”, ×¢×“×™×™×Ÿ ×œ× ××©×‘×¨ â€” ×›×“××™ ×œ×”×™×–×”×¨ ×‘××™× ×•×£ ×•×—×©×™×¤×” ×¡×§×˜×•×¨×™××œ×™×ª.",
        "neutral": "×¡×‘×™×‘×” × ×™×™×˜×¨×œ×™×ª â€” ×œ×œ× ×”×˜×™×” ×—×–×§×” ×œ×›×™×•×•×Ÿ Risk-on/Risk-off.",
    }
    return mapping.get(
        label,
        "×¡×‘×™×‘×ª ××©×˜×¨ ×××§×¨×• ×›×œ×œ×™×ª ×œ×œ× ×ª×™×•×’ ×¡×¤×¦×™×¤×™.",
    )


def _warn_if_meta_stale(meta: Mapping[str, Any], max_age_minutes: int = 15) -> None:
    """××–×”×™×¨ ×× ×”-meta ×™×©×Ÿ ××“×™ (×œ××©×œ ×˜××‘ ×¤×ª×•×— ×©×¢×•×ª ×‘×œ×™ ×¨×¢× ×•×Ÿ)."""
    try:
        from datetime import datetime as _dt

        ts_str = str(meta.get("ts", ""))
        if not ts_str:
            return
        ts = _dt.fromisoformat(ts_str.replace("Z", ""))
        age_min = (_dt.utcnow() - ts).total_seconds() / 60.0
        if age_min > max_age_minutes:
            st.warning(
                f"×”×ª×•×¦××” ×—×™×©×•×‘×™×ª ×™×©× ×” ×™×—×¡×™×ª ({age_min:.1f} ×“×§×•×ª) â€” "
                "×©×§×•×œ ×œ×¨×¢× ×Ÿ ××ª ×—×™×©×•×‘×™ ×”×××§×¨×•.",
            )
    except Exception:  # noqa: BLE001
        return


def _render_top_kpis(meta: Mapping[str, Any]) -> None:
    """××¦×™×’ KPIs ×¢×œ×™×•× ×™× ×¢×œ ×‘×¡×™×¡ meta ×©× ×©××¨ ×-_stamp_result.

    KPIs:
    -----
    1. ×–××Ÿ ×¨×™×¦×” (ts)
    2. apply_mode (××¦×‘ ×™×™×©×•×)
    3. exposure_multiplier (Ã— ×—×©×™×¤×”)
    4. ×–×•×’×•×ª ×›×œ×•×œ×™× ××ª×•×š ×›×œ×œ ×”×–×•×’×•×ª (included / pairs)
    5. mean_score + Badge ××™×›×•×ª ×¦×™×•×Ÿ (×’×‘×•×” / ×‘×™× ×•× ×™ / × ××•×š)
    """
    if not meta:
        st.info("×¢×“×™×™×Ÿ ×œ× ×—×•×©×‘ Macro Adjustment â€” ×”×¨×¥ ×—×™×©×•×‘ ×›×“×™ ×œ×§×‘×œ KPIs.")
        return

    ts = str(meta.get("ts", "N/A"))
    apply_mode = str(meta.get("apply_mode", "hybrid"))
    exposure = float(meta.get("exposure_multiplier", 1.0))
    included = int(meta.get("included", 0))
    pairs = int(meta.get("pairs", 0))
    mean_score = meta.get("mean_score", None)

    c1, c2, c3, c4, c5 = st.columns(5)
    with c1:
        st.metric("ğŸ•’ ×–××Ÿ ×¨×™×¦×”", ts)
    with c2:
        st.metric("××¦×‘ ×™×™×©×•×", apply_mode)
    with c3:
        st.metric("××§×“× ×—×©×™×¤×”", f"Ã— {exposure:.2f}")
    with c4:
        st.metric("×–×•×’×•×ª ×›×œ×•×œ×™×", f"{included}/{pairs}")
    with c5:
        if mean_score is not None:
            try:
                msf = float(mean_score)
                st.metric("×¦×™×•×Ÿ ×××•×¦×¢", f"{msf:.1f}")
                if msf >= 60:
                    color, label = "#16a34a", "×’×‘×•×”"
                elif msf >= 40:
                    color, label = "#f59e0b", "×‘×™× ×•× ×™"
                else:
                    color, label = "#dc2626", "× ××•×š"
                st.markdown(
                    "<span style='display:inline-block;padding:4px 10px;"
                    "border-radius:999px;background:{};color:white;font-weight:600;'>"
                    "××™×›×•×ª ×¦×™×•×Ÿ: {}</span>".format(color, label),
                    unsafe_allow_html=True,
                )
            except Exception:  # noqa: BLE001
                st.metric("×¦×™×•×Ÿ ×××•×¦×¢", "N/A")
        else:
            st.metric("×¦×™×•×Ÿ ×××•×¦×¢", "N/A")

    regime_label = meta.get("regime_label")
    if regime_label:
        st.caption(f"××©×˜×¨ × ×•×›×—×™: **{regime_label}** â€” {_explain_regime_label(str(regime_label))}")

    _warn_if_meta_stale(meta)

    # ---- ×“×—×™×¤×ª ××“×“×™ ×××§×¨×• ×œ-Tab Comparison (macro_metrics) ----
    try:
        macro_meta = meta or {}
        mean_score = _safe_float_or_none(macro_meta.get("mean_score"))
        regime_label = str(macro_meta.get("regime_label", "") or "")

        # ×”×•×¤×›×™× regime_label ×œ××¢×™×Ÿ ×¨×’×™×©×•×ª 0..1
        regime_map = {
            "risk_off": 0.1,
            "stagflation": 0.2,
            "slowdown": 0.3,
            "neutral": 0.5,
            "reflation": 0.7,
            "risk_on": 0.9,
        }
        macro_sensitivity = regime_map.get(regime_label, 0.5)

        macro_score = mean_score if mean_score is not None else 50.0

        push_macro_metrics_to_ctx(
            macro_sensitivity=macro_sensitivity,
            macro_score=macro_score,
            # ××™×Ÿ ×œ×š ×›×¨×’×¢ max_dd_60d/vol_60d ×’×œ×•×‘×œ×™×™×, ××– × ×©××™×¨ None
            max_dd_60d=None,
            vol_60d=None,
        )
    except Exception:
        # ×œ× ××¤×™×œ×™× ××ª ×”×˜××‘ ×× ××©×”×• ×§×˜×Ÿ × ×›×©×œ â€” ×¤×©×•×˜ ×œ× × ×¢×“×›×Ÿ macro_metrics
        LOGGER.debug("push_macro_metrics_to_ctx failed (non-fatal)", exc_info=True)

def _render_risk_profile_banner() -> None:
    """
    ××¦×™×’ Banner ×§×˜×Ÿ ×©×œ '××¦×‘ ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™' (risk_profile_from_macro)
    ×©×”×’×™×¢ ××”-dashboard / render_macro_tab (risk_mode).

    ×–×” ×××¤×©×¨ ×œ×¨××•×ª ×‘××‘×˜ ××—×“:
      - defensive / stress â†’ ××¦×‘ ×”×’× ×ª×™ / ××©×‘×¨×™
      - normal            â†’ ×¨×’×™×œ
      - offensive         â†’ ××’×¨×¡×™×‘×™
    """
    risk_profile = state_get("risk_profile_from_macro", None)
    if not risk_profile:
        return

    rp = str(risk_profile).lower()
    if rp in {"defensive", "stress"}:
        msg = f"××¦×‘ ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™: **{risk_profile}** â€” ×¤×¨×•×¤×™×œ ×”×’× ×ª×™ / ××©×‘×¨×™, ×¨×¦×•×™ ×œ×”×™×–×”×¨ ×‘××™× ×•×£ ×•×—×©×™×¤×”."
        try:
            st.error(msg)
        except Exception:
            st.write(msg)
    elif rp in {"offensive", "aggressive"}:
        msg = f"××¦×‘ ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™: **{risk_profile}** â€” ×¤×¨×•×¤×™×œ ×”×ª×§×¤×™, ××ª××™× ×œ×ª× ××™× × ×•×—×™× ××š ×¢× ×¡×™×›×•×Ÿ ××•×’×‘×¨."
        try:
            st.warning(msg)
        except Exception:
            st.write(msg)
    else:
        msg = f"××¦×‘ ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™: **{risk_profile}** â€” ×¤×¨×•×¤×™×œ ×¨×’×™×œ/× ×™×™×˜×¨×œ×™."
        try:
            st.info(msg)
        except Exception:
            st.write(msg)

# ===========================================================================
# Live Health: ×—×™×•×•×™ ×¢×œ ××§×•×¨×•×ª ×“××˜×” ×•××¦×‘ Client
# ===========================================================================


def _render_live_health(cfg: MacroConfig) -> None:
    """××¦×™×’ Badges ×©×œ ×‘×¨×™××•×ª ×©×›×‘×•×ª Live ×œ×¤×™ ×”××§×•×¨×•×ª/×”×¨×©××•×ª ×”× ×•×›×—×™×™×.

    ×‘×“×™×§×•×ª:
    --------
    - Client:ON    â†’ cfg.use_data_client
    - Live        â†’ cfg.data_client_live
    - IBKR        â†’ ×”×× ×™×© token ×‘-session_state + ××§×•×¨ ibkr: ×›×œ×©×”×•.
    - YF          â†’ ×”×× ×™×© ××§×•×¨ ×©××ª×—×™×œ ×‘-yf:
    - DuckDB      â†’ ×”×× ×™×© ××§×•×¨ ×©××ª×—×™×œ ×‘-duckdb:
    - SQL         â†’ ×”×× ×™×© ××§×•×¨ ×©××ª×—×™×œ ×‘-sql:

    ×”××§×•×¨×•×ª × ×œ×§×—×™× ×:
    - cfg.sources (×× ×§×™×™× ×©×“×” ×›×–×” ×‘-MacroConfig).
    - session_state["macro_sources_overrides"] (×©× ×•×¡×¤×• ××ª×•×š ×”×˜××‘).
    """
    try:
        overrides = state_get("macro_sources_overrides", {}) or {}
        cfg_sources = getattr(cfg, "sources", {}) or {}
        vals: List[str] = []
        vals.extend(str(v) for v in cfg_sources.values())
        vals.extend(str(v) for v in overrides.values())

        def has_prefix(prefix: str) -> bool:
            return any(isinstance(v, str) and v.startswith(prefix) for v in vals)

        ibkr_ok = bool(state_get(keygen(TAB_KEY, "ibkr", "token"))) and has_prefix("ibkr:")
        yf_ok = has_prefix("yf:")
        duck_ok = has_prefix("duckdb:")
        sql_ok = has_prefix("sql:")

        client_on = bool(getattr(cfg, "use_data_client", False))
        client_live = bool(getattr(cfg, "data_client_live", False))

        def badge(txt: str, ok: bool) -> str:
            color = "#16a34a" if ok else "#dc2626"
            suffix = " âœ“" if ok else " âœ•"
            return (
                "<span style='display:inline-block;margin-right:6px;"
                "padding:2px 8px;border-radius:999px;background:{};"
                "color:white;font-size:12px'>".format(color)
                + txt
                + suffix
                + "</span>"
            )

        html = (
            badge("Client:ON", client_on)
            + badge("Live", client_live)
            + badge("IBKR", ibkr_ok)
            + badge("YF", yf_ok)
            + badge("DuckDB", duck_ok)
            + badge("SQL", sql_ok)
        )
        st.markdown(html, unsafe_allow_html=True)

        if get_flag("macro_show_source_summary", True):
            _render_source_summary(cfg, overrides)
    except Exception:  # noqa: BLE001
        # ×¢×“×™×£ ×œ× ×œ×”×¤×™×œ ××ª ×”×˜××‘ ×‘×’×œ×œ ××™× ×“×™×§×˜×•×¨ ×•×™×–×•××œ×™
        LOGGER.debug("_render_live_health failed", exc_info=True)


def _render_source_summary(
    cfg: MacroConfig,
    overrides: Optional[Mapping[str, str]] = None,
) -> None:
    """×˜×‘×œ×ª Summary ×§×˜× ×” ×©×œ ××§×•×¨×•×ª ×“××˜×” ×××§×¨×• (IBKR / YF / DuckDB / SQL)."""
    try:
        sources = getattr(cfg, "sources", {}) or {}
        overrides = overrides or {}
        all_sources: Dict[str, str] = {}
        all_sources.update({str(k): str(v) for k, v in sources.items()})
        all_sources.update({str(k): str(v) for k, v in overrides.items()})

        rows: List[Dict[str, Any]] = []
        for name, uri in all_sources.items():
            if ":" in uri:
                prefix, rest = uri.split(":", 1)
            else:
                prefix, rest = "unknown", uri
            rows.append(
                {
                    "logical_name": name,
                    "kind": prefix,
                    "uri": uri,
                    "detail": rest,
                },
            )
        if not rows:
            st.caption("××™×Ÿ ××§×•×¨×•×ª ×××§×¨×• ××•×’×“×¨×™× ×›×¨×’×¢ (cfg.sources ×•Ö¾overrides ×¨×™×§×™×).")
            return
        df = pd.DataFrame(rows)
        df_summary = (
            df.groupby("kind", as_index=False)["logical_name"]
            .count()
            .rename(columns={"logical_name": "count"})
        )
        with st.expander("ğŸ” ×¡×™×›×•× ××§×•×¨×•×ª ×××§×¨×• (by kind)", expanded=False):
            st.dataframe(df_summary, use_container_width=True)
            show_full = st.toggle(
                "×”×¦×’ ×˜×‘×œ×ª ××§×•×¨×•×ª ××œ××”",
                value=False,
                key=keygen(TAB_KEY, "src", "full"),
            )
            if show_full:
                st.dataframe(df, use_container_width=True)
    except Exception:  # noqa: BLE001
        LOGGER.debug("_render_source_summary failed", exc_info=True)


# ===========================================================================
# Debug Panels (× ×©×ª××© ×‘×”× ×‘×—×œ×§ render ×× macro_debug=True)
# ===========================================================================


def _render_debug_panels(
    snapshot: Optional[JSONDict] = None,
    overlay: Optional[Dict[str, JSONDict]] = None,
) -> None:
    """××¦×™×’ Debug Panels ×× ×“×’×œ macro_debug ×¤×¢×™×œ.

    Parameters
    ----------
    snapshot:
        ×”-MacroSnapshot ×”××—×¨×•×Ÿ (×× ×–××™×Ÿ).
    overlay:
        macro_profile / overlay ×©×œ ××©×§×•×œ×•×ª ×•×¤×¢×•×œ×•×ª ×œ×¤×™ ×–×•×’ (×× ×–××™×Ÿ).
    """
    if not get_flag("macro_debug", False):
        return

    meta = state_get(MacroStateKeys.META, {})
    with st.expander("ğŸ Macro Debug â€” Meta & Snapshot", expanded=False):
        st.markdown("**Meta (macro_meta):**")
        st.json(meta or {}, expanded=False)

        if snapshot is not None:
            st.markdown("**Macro Snapshot (last computation):**")
            st.json(snapshot, expanded=False)

    if overlay:
        with st.expander("ğŸ Macro Debug â€” Overlay / Profile", expanded=False):
            st.json(overlay, expanded=False)
# ===========================================================================
# ×¡×™×•× ×—×œ×§ 2: ×¢×–×¨×™ State, Feature Flags, ×•×œ×™×“×¦×™×”, Meta & KPIs, Live Health
# ===========================================================================

# ---------------------------------------------------------------------------
# Base Layer â€” Workspace controls, Macro data loading, Snapshot
# ---------------------------------------------------------------------------


def _default_workspace_dates() -> Tuple[pd.Timestamp, pd.Timestamp]:
    """×˜×•×•×— ×‘×¨×™×¨×ª ××—×“×œ ×œ×©×›×‘×ª ×”×××§×¨×•: ×©× ×” ××—×•×¨×” ××”×™×•× (normalized)."""
    today = pd.Timestamp.today().normalize()
    start = today - pd.Timedelta(days=365)
    return start, today


def _workspace_sidebar(namespace: str = TAB_KEY) -> MacroWorkspace:
    """Sidebar ×’×œ×•×‘×œ×™ ×œ×©×›×‘×ª ×”×××§×¨×• (Date Range / Freq / Env).

    ×–×”×• ×”-"×§×•× ×˜×¨×•×œ ×˜××•×•×¨" ×©×œ ×›×œ ×”×˜××‘:
    - ×›×œ ××” ×©×§×©×•×¨ ×œ×ª×§×•×¤×”, ×ª×“×™×¨×•×ª ×•×¡×‘×™×‘×ª ×¢×‘×•×“×” â€” ××•×’×“×¨ ×›××Ÿ.
    - ×›×œ ×©××¨ ×”×©×›×‘×•×ª (Adjustments / DNA / Regimes / Shocks) × ×©×¢× ×•×ª ×¢×œ×™×•.
    """
    with st.sidebar:
        st.subheader("ğŸŒ ×©×›×‘×ª ×‘×¡×™×¡ ×××§×¨×• â€” ×˜×•×•×— ×•×ª×¦×•×¨×”")

        # ×‘×¨×™×¨×ª ××—×“×œ: ×©× ×” ××—×•×¨×”
        default_start, default_end = _default_workspace_dates()
        date_key = keygen(namespace, "ws", "date_range")

        date_val = st.date_input(
            "×˜×•×•×— ×ª××¨×™×›×™× ×œ×××§×¨×•",
            value=(default_start.date(), default_end.date()),
            key=date_key,
            help="×”×˜×•×•×— ×©×‘×• ×™× ×•×ª×—×• ×”×¤×§×˜×•×¨×™× ×”×××§×¨×• (Snapshot / Regimes / Backtest).",
        )

        if isinstance(date_val, (list, tuple)) and len(date_val) == 2:
            start_d, end_d = date_val
        else:
            start_d, end_d = default_start.date(), default_end.date()

        start_ts = pd.to_datetime(start_d)
        end_ts = pd.to_datetime(end_d)

        freq = st.selectbox(
            "×ª×“×™×¨×•×ª ×××§×¨×•",
            options=["D", "W", "M"],
            index=0,
            key=keygen(namespace, "ws", "freq"),
            format_func=lambda x: {
                "D": "×™×•××™ (D)",
                "W": "×©×‘×•×¢×™ (W)",
                "M": "×—×•×“×©×™ (M)",
            }.get(x, str(x)),
            help="×§×•×‘×¢ ×›×™×¦×“ macro_df ×™×™×¨×¡××¤×œ (D/W/M).",
        )

        env = st.radio(
            "×¡×‘×™×‘×ª ×¢×‘×•×“×”",
            options=["backtest", "live"],
            index=0,
            key=keygen(namespace, "ws", "env"),
            format_func=lambda x: "Backtest" if x == "backtest" else "Live (Data Client / IBKR)",
            help="×›×¨×’×¢ ××™× ×¤×•×¨××˜×™×‘×™; ×‘×”××©×š ×™×©×¤×™×¢ ×¢×œ ××§×•×¨×•×ª/×¤×¨××˜×¨×™× ×‘×× ×•×¢ ×”×××§×¨×•.",
        )

        st.caption(
            "ğŸ“ ×”×”×’×“×¨×•×ª ×›××Ÿ ××©×¤×™×¢×•×ª ×¢×œ ×›×œ ×©×›×‘×•×ª ×”×˜××‘: Snapshot, Regimes, ×”×ª×××•×ª ×œ×ª×™×§ ×•-DNA ×œ×–×•×’.",
        )

    ws = MacroWorkspace(
        start_date=start_ts,
        end_date=end_ts,
        freq=freq,  # type: ignore[arg-type]
        env=env,    # type: ignore[arg-type]
    )

    # ×©××™×¨×” ×œ-session_state ×œ××•×“×•×œ×™× ××—×¨×™× (×œ××©×œ tabs ××—×¨×™× ××• ×”-Executor)
    state_set("macro_workspace", {
        "start": str(ws.start_date),
        "end": str(ws.end_date),
        "freq": ws.freq,
        "env": ws.env,
    })
    return ws


def _init_macro_configs(
    cfg: Optional[MacroConfig],
    factor_cfg: Optional[MacroFactorConfig],
    pair_sens_cfg: Optional[PairMacroSensitivityConfig],
) -> Tuple[MacroConfig, Optional[MacroFactorConfig], Optional[PairMacroSensitivityConfig]]:
    """×××ª×—×œ MacroConfig / MacroFactorConfig / PairMacroSensitivityConfig.

    ×¡×“×¨ ×”×¢×“×™×¤×•×™×•×ª:
    1. ×× ×”×•×¢×‘×¨ ××•×‘×™×™×§×˜ ×‘×¤×•×¢×œ ×œ×¤×•× ×§×¦×™×” â€” ××©×ª××©×™× ×‘×•.
    2. ××—×¨×ª, ×× ×§×™×™× ××•×‘×™×™×§×˜ ×‘-session_state (×œ××©×œ ××”-Config Tab) â€” × ×˜×¢×Ÿ ××× ×•.
    3. ××—×¨×ª, × ×™×™×¦×¨ ×§×•× ×¤×™×’ ×—×“×© (×‘×¨×™×¨×ª ××—×“×œ).

    ×›×š ×”×˜××‘ "××ª×—×‘×¨" ××•×˜×•××˜×™×ª ×œ×”×’×“×¨×•×ª ×§×™×™××•×ª ×‘××¢×¨×›×ª, ××‘×œ ×’× ×¢×•×‘×“ standalone.
    """
    # MacroConfig
    if cfg is None:
        cfg_from_state = state_get(MacroStateKeys.CFG)
        if isinstance(cfg_from_state, MacroConfig):
            cfg = cfg_from_state
        else:
            cfg = MacroConfig()  # type: ignore[call-arg]

    # MacroFactorConfig
    if factor_cfg is None:
        cfg_f_from_state = state_get(MacroStateKeys.FACTOR_CFG)
        if isinstance(cfg_f_from_state, MacroFactorConfig):
            factor_cfg = cfg_f_from_state
        else:
            try:
                factor_cfg = MacroFactorConfig()  # type: ignore[call-arg]
            except Exception:  # noqa: BLE001
                factor_cfg = None

    # PairMacroSensitivityConfig
    if pair_sens_cfg is None:
        cfg_sens_state = state_get("macro_pair_sens_cfg")
        if isinstance(cfg_sens_state, PairMacroSensitivityConfig):
            pair_sens_cfg = cfg_sens_state
        else:
            try:
                pair_sens_cfg = PairMacroSensitivityConfig()  # type: ignore[call-arg]
            except Exception:  # noqa: BLE001
                pair_sens_cfg = None

    # × ×©××•×¨ ××ª ×”×§×•× ×¤×™×’×™× ×’× ×‘-session_state ×œ×˜×•×‘×ª ×˜××‘/××•×“×•×œ×™× ××—×¨×™×
    state_set(MacroStateKeys.CFG, cfg)
    if factor_cfg is not None:
        state_set(MacroStateKeys.FACTOR_CFG, factor_cfg)
    if pair_sens_cfg is not None:
        state_set("macro_pair_sens_cfg", pair_sens_cfg)

    return cfg, factor_cfg, pair_sens_cfg


def _normalize_datetime_index(df: pd.DataFrame) -> pd.DataFrame:
    """××•×•×“× ×©×”-index ×©×œ df ×”×•× DatetimeIndex ×××•×™×Ÿ (×œ-resample × ×§×™)."""
    if df.empty:
        return df
    if not isinstance(df.index, pd.DatetimeIndex):
        df = df.copy()
        df.index = pd.to_datetime(df.index)
    return df.sort_index()


def _slice_to_workspace(df: pd.DataFrame, ws: MacroWorkspace) -> pd.DataFrame:
    """×’×•×–×¨ ××ª macro_df ×œ×˜×•×•×— ×”-Workspace (start/end)."""
    if df.empty:
        return df
    df = _normalize_datetime_index(df)
    if ws.start_date is not None:
        df = df[df.index >= ws.start_date]
    if ws.end_date is not None:
        df = df[df.index <= ws.end_date]
    return df


def _resample_macro_df(df: pd.DataFrame, freq: MacroFreq) -> pd.DataFrame:
    """×¨×™×¡××¤×œ ×©×œ macro_df ×œ×¤×™ ×ª×“×™×¨×•×ª ×”×××§×¨×• ×©× ×‘×—×¨×” (D/W/M)."""
    df = _normalize_datetime_index(df)
    if df.empty:
        return df

    if freq == "D":
        return df

    rule = "W-FRI" if freq == "W" else "M"
    try:
        df_res = df.resample(rule).last()
    except Exception:  # noqa: BLE001
        # fallback ×¤×©×•×˜ ×× resample ×œ× ×–××™×Ÿ (×œ××©×œ index ×œ× ×¨×¦×™×£)
        return df
    return df_res.dropna(how="all")


def _maybe_align_macro_to_universe(
    macro_df: pd.DataFrame,
    *,
    prices_df: Optional[pd.DataFrame] = None,
) -> pd.DataFrame:
    """×× ×¡×” ×œ×™×™×©×¨ ××ª macro_df ×œ×™×§×•× ×”××—×™×¨×™×/×–×× ×™× ×©×œ ×”××¢×¨×›×ª.

    ×œ×•×’×™×§×”:
    -------
    1. ×× × ×©×œ×— prices_df â†’ × ×©×ª××© ×‘-index ×©×œ×•.
    2. ××—×¨×ª, × × ×¡×” ×œ××¦×•× prices_wide / returns_wide ×‘-session_state.
    3. ×× ××™×Ÿ ×›×œ×•× â€” ××—×–×™×¨×™× ××ª macro_df ×›××• ×©×”×•×.

    ×”××˜×¨×”: macro_df ××™×•×©×¨ ×œ×—×•×ª××ª ×”×–××Ÿ ×©×œ ×”××¢×¨×›×ª (×œ××©×œ trading days ×××™×ª×™×™×).
    """
    if macro_df is None or macro_df.empty:
        return macro_df

    macro_df = _normalize_datetime_index(macro_df)

    if prices_df is None:
        prices_df = state_get("prices_wide")
        if not isinstance(prices_df, pd.DataFrame) or prices_df.empty:
            prices_df = state_get("returns_wide")
            if not isinstance(prices_df, pd.DataFrame) or prices_df.empty:
                return macro_df

    prices_df = _normalize_datetime_index(prices_df)
    common_index = macro_df.index.intersection(prices_df.index)
    if len(common_index) == 0:
        # ×× ××™×Ÿ ×—×™×ª×•×š â€” ×¢×“×™×£ ×œ× "×œ×©×‘×•×¨" ××ª ×”×××§×¨×•, ×¨×§ × ×ª×¨×™×¢ ×‘×¨××ª ×œ×•×’
        LOGGER.debug("no common index between macro_df and prices universe â€” using macro_df as-is")
        return macro_df
    return macro_df.loc[common_index]


def _describe_macro_df(macro_df: Optional[pd.DataFrame]) -> None:
    """×ª×¦×•×’×ª ××™×“×¢ ××”×™×¨×” ×¢×œ macro_df ×œ×¦×¨×›×™ UX/Debug."""
    if macro_df is None or macro_df.empty:
        st.caption("macro_df: (×¨×™×§) â€” ××™×Ÿ × ×ª×•× ×™ ×××§×¨×• ×ª×§×™× ×™× ×œ×ª×§×•×¤×”/×ª×“×™×¨×•×ª ×©× ×‘×—×¨×”.")
        return

    n_rows, n_cols = macro_df.shape
    start, end = macro_df.index.min(), macro_df.index.max()
    st.caption(
        f"macro_df: **{n_rows:,}** ×ª×¦×¤×™×•×ª Ã— **{n_cols:,}** ×¤×§×˜×•×¨×™× | "
        f"×˜×•×•×—: **{start.date()} â†’ {end.date()}**",
    )


def _load_macro_data_for_workspace(
    state: MacroTabState,
    *,
    pairs_df: Optional[pd.DataFrame] = None,
) -> MacroTabState:
    """×˜×•×¢×Ÿ ××ª ××§×•×¨×•×ª ×”×××§×¨×• (Bundle ×™×©×Ÿ + ×¤×§×˜×•×¨×™× ×—×“×©×™×) ×œ×¤×™ ×”-Workspace.

    ×œ×•×’×™×§×”:
    -------
    1. MacroBundle (×™×©×Ÿ):
        - load_macro_bundle(cfg) â†’ MacroBundle
        - × ×©××¨ ×‘-session_state ×ª×—×ª MacroStateKeys.BUNDLE.
    2. macro_factors (×—×“×©):
        - × × ×¡×” ×§×¨×™××•×ª ×©×•× ×•×ª ×œ-load_macro_factors:
            * load_macro_factors(cfg, factor_cfg=factor_cfg)
            * load_macro_factors(cfg)
            * load_macro_factors()
        - add_derived_factors(df, factor_cfg) â†’ ×”×¢×©×¨×ª ×¤×§×˜×•×¨×™× (×× factor_cfg ×§×™×™×).
        - slice_to_workspace ×œ×¤×™ start/end.
        - ×™×™×©×•×¨ ×œ××™× ×“×§×¡ ×©×œ prices_wide (×× ×§×™×™×).
        - resample ×œ×¤×™ state.workspace.freq.
        - × ×©××¨ ×›-state.macro_df + state.macro_factors_df + MacroStateKeys.MACRO_DF.
    """
    cfg = state.macro_cfg
    ws = state.workspace

    # 1) Bundle ×™×©×Ÿ â€” ×ª××™×“ × × ×¡×” ×œ×˜×¢×•×Ÿ (×¢× fallback ×œ-Bundle ×¨×™×§)
    bundle = state.bundle
    if bundle is None:
        try:
            bundle = load_macro_bundle(cfg)
        except Exception as e:  # noqa: BLE001
            LOGGER.error("×›×©×œ ×‘×˜×¢×™× ×ª MacroBundle: %s", e)
            try:
                bundle = MacroBundle({})  # type: ignore[call-arg]
            except Exception:
                bundle = None
    state.bundle = bundle
    state_set(MacroStateKeys.BUNDLE, bundle)

    # 2) macro_factors ×”×—×“×©
    macro_df: Optional[pd.DataFrame] = None
    # × × ×¡×” ×›××” ×—×ª×™××•×ª × ×¤×•×¦×•×ª ×›×“×™ ×œ×”×™×•×ª ×¢××™×“×™× ×œ×©×™× ×•×™×™× ×‘××•×“×•×œ ×”×××§×¨×•
    if macro_df is None:
        try:
            macro_df = load_macro_factors(cfg, state.factor_cfg)  # type: ignore[call-arg]
        except TypeError:
            try:
                macro_df = load_macro_factors(cfg)  # type: ignore[call-arg]
            except Exception:  # noqa: BLE001
                macro_df = None
        except Exception:
            macro_df = None

    if macro_df is None:
        try:
            macro_df = load_macro_factors()  # type: ignore[call-arg]
        except Exception:  # noqa: BLE001
            macro_df = None

    if macro_df is not None:
        # enrich / derived factors
        try:
            if state.factor_cfg is not None:
                macro_df = add_derived_factors(macro_df, state.factor_cfg)  # type: ignore[arg-type]
            else:
                macro_df = add_derived_factors(macro_df)  # type: ignore[call-arg]
        except TypeError:
            # ×™×™×ª×›×Ÿ ×©×”×¤×•× ×§×¦×™×” ×œ× ××§×‘×œ×ª factor_cfg â€” × ×ª×¢×œ× ×‘×©×§×˜
            LOGGER.debug("add_derived_factors called without factor_cfg")
        except Exception as e:  # noqa: BLE001
            LOGGER.debug("add_derived_factors failed (non-fatal): %s", e)

        macro_df = _slice_to_workspace(macro_df, ws)
        macro_df = _maybe_align_macro_to_universe(
            macro_df,
            prices_df=state_get("prices_wide") if pairs_df is None else state_get("prices_wide"),
        )
        macro_df = _resample_macro_df(macro_df, ws.freq)

        state.macro_df = macro_df
        state.macro_factors_df = macro_df
        state_set(MacroStateKeys.MACRO_DF, macro_df)
    else:
        state.macro_df = None
        state.macro_factors_df = None

    return state


def _extract_macro_key_metrics(snapshot: JSONDict) -> List[Dict[str, Any]]:
    """××•×¦×™× 'Key Metrics' ××ª×•×š snapshot ×œ×¤×™ ×©××•×ª ×¤×§×˜×•×¨×™× ××§×•×‘×œ×™×.

    ××—×¤×© ×¢×¨×›×™× ×‘:
    -------------
    - last_values
    - zscores

    ×•××—×–×™×¨ ×¨×©×™××” ×©×œ:
    { "label": ..., "value": ..., "z": ..., "key": ... }
    """
    if not snapshot:
        return []

    last_vals = snapshot.get("last_values", {}) or {}
    zscores = snapshot.get("zscores", {}) or {}

    # ×¤×§×˜×•×¨×™× ×˜×™×¤×•×¡×™×™× â€” ××¤×©×¨ ×œ×”×¨×—×™×‘ ×‘×”××©×š
    canonical_order = [
        ("policy_rate", "×¨×™×‘×™×ª ××“×™× ×™×•×ª"),
        ("rate_short", "×¨×™×‘×™×ª ×§×¦×¨×”"),
        ("rate_long", "×¨×™×‘×™×ª ××¨×•×›×”"),
        ("slope_10y_3m", "×¢×§×•× 10Y-3M"),
        ("slope_10y_2y", "×¢×§×•× 10Y-2Y"),
        ("vix", "VIX (×©×•×§ ××•×¤×¦×™×•×ª)"),
        ("vix_term_1_0", "VIX Term (1-0)"),
        ("credit_spread", "Credit Spread"),
        ("dxy", "××“×“ ×“×•×œ×¨ (DXY)"),
        ("risk_on_proxy", "Risk-On Proxy"),
    ]

    key_metrics: List[Dict[str, Any]] = []
    for key, label in canonical_order:
        if key in last_vals or key in zscores:
            val = last_vals.get(key, None)
            z = zscores.get(key, None)
            try:
                val_f = float(val) if val is not None else None
            except Exception:
                val_f = None
            try:
                z_f = float(z) if z is not None else None
            except Exception:
                z_f = None
            key_metrics.append(
                {
                    "key": key,
                    "label": label,
                    "value": val_f,
                    "z": z_f,
                },
            )
    return key_metrics


def _render_macro_snapshot_section(state: MacroTabState) -> None:
    """××¦×™×’ ××ª '××¦×‘ ×”×××§×¨×• ×”× ×•×›×—×™' (Snapshot) + ×›×¤×ª×•×¨ ×”×•×¨×“×” + Key Metrics.

    ××©×ª××© ×‘:
    --------
    - build_macro_snapshot(macro_df, factor_cfg/ cfg)
    - summarize_macro_snapshot(snapshot)

    ××¦×™×’:
    -----
    - ××©×¤×˜ ×¡×™×›×•× ×§×¦×¨.
    - KPIs ×œ×¤×™ ×§×‘×•×¦×•×ª ××©×˜×¨ (rates / curve / vol / credit / fx / risk).
    - "Key Macro Metrics" ×¢× ×¢×¨×›×™× ××—×¨×•× ×™× ×•-Z-score.
    - Expander ×¢× snapshot ××œ×.
    - ×›×¤×ª×•×¨ ×”×•×¨×“×” ×›-JSON.
    - Debug Panels ×× macro_debug=True.
    """
    st.subheader("ğŸ“Š ××¦×‘ ×××§×¨×• × ×•×›×—×™")

    ws = state.workspace
    macro_df = state.macro_df

    if ws.start_date is not None and ws.end_date is not None:
        st.caption(
            f"×˜×•×•×— × ×™×ª×•×— ×××§×¨×•: **{ws.start_date.date()} â†’ {ws.end_date.date()}** | "
            f"×ª×“×™×¨×•×ª: **{ws.freq}** | ×¡×‘×™×‘×ª ×¢×‘×•×“×”: **{ws.env}**",
        )

    _describe_macro_df(macro_df)

    if macro_df is None or macro_df.empty:
        st.info(
            "×œ× × ××¦××• × ×ª×•× ×™ ×××§×¨×• ××”××•×“×•×œ ×”×—×“×© (macro_factors) ×œ×ª×§×•×¤×” ×”× ×‘×—×¨×ª.\n"
            "×¢×“×™×™×Ÿ × ×™×ª×Ÿ ×œ×”×©×ª××© ×‘-MacroBundle ×”×™×©×Ÿ ×œ×ª×™×§×•×Ÿ ×—×©×™×¤×” ×“×¨×š ×× ×•×¢ ×”×××§×¨×•.",
        )
        return

    # ×‘× ×™×™×ª snapshot
    snapshot: Optional[JSONDict] = None
    try:
        try:
            snapshot = build_macro_snapshot(macro_df, state.factor_cfg)  # type: ignore[arg-type]
        except TypeError:
            # ×—×ª×™××” ×—×œ×•×¤×™×ª: ××•×œ×™ × ×“×¨×© ×¨×§ macro_df
            snapshot = build_macro_snapshot(macro_df)  # type: ignore[call-arg]
    except Exception as e:  # noqa: BLE001
        LOGGER.error("build_macro_snapshot failed: %s", e)
        st.warning("×›×©×œ ×‘×‘× ×™×™×ª Macro Snapshot â€” ××•×¦×’ ×¨×§ ××™×“×¢ ×‘×¡×™×¡×™ ×¢×œ ×”×××§×¨×•.")
        snapshot = None

    state.macro_snapshot = snapshot
    if snapshot is not None:
        state_set("macro_snapshot", snapshot)

    # ×¡×™×›×•× ×˜×§×¡×˜×•××œ×™
    summary_text = ""
    if snapshot is not None:
        try:
            summary_text = summarize_macro_snapshot(snapshot)
        except Exception as e:  # noqa: BLE001
            LOGGER.debug("summarize_macro_snapshot failed: %s", e)

    if summary_text:
        st.markdown(f"**×¡×™×›×•× ××¦×‘ ×××§×¨×•:** {summary_text}")
    else:
        st.markdown("**×¡×™×›×•× ××¦×‘ ×××§×¨×•:** (×œ× ×–××™×Ÿ â€” ×™×™×ª×›×Ÿ ×©×—×¡×¨×™× ×¤×§×˜×•×¨×™× ××• snapshot ×—×œ×§×™)")

    # KPIs ×œ×¤×™ ×§×‘×•×¦×•×ª (rates / curve / vol / credit / fx / risk)
    group_regimes = (snapshot or {}).get("group_regimes", {}) if snapshot else {}
    if isinstance(group_regimes, dict) and group_regimes:
        # × × ×¡×” ×œ×”×¦×™×’ ×‘×¡×“×¨ ×§×‘×•×¢, ×•×× ×™×© ×¢×•×“ ×§×‘×•×¦×•×ª × ×•×¡×¤×•×ª â€” × ×•×¡×™×£ ×‘×¡×•×£
        preferred_order = ["rates", "curve", "vol", "credit", "fx", "risk"]
        items_ordered: List[Tuple[str, Any]] = []
        seen = set()
        for k in preferred_order:
            if k in group_regimes:
                items_ordered.append((k, group_regimes[k]))
                seen.add(k)
        for k, v in group_regimes.items():
            if k not in seen:
                items_ordered.append((k, v))

        n_cols = min(len(items_ordered), 6) or 1
        cols = st.columns(n_cols)
        for idx, (group_name, label) in enumerate(items_ordered):
            col = cols[idx % n_cols]
            with col:
                st.metric(str(group_name), str(label))

    # Key Macro Metrics (last_values + z-scores) â€” 2 ×©×•×¨×•×ª ×©×œ KPIs
    if snapshot is not None:
        metrics = _extract_macro_key_metrics(snapshot)
        if metrics:
            st.markdown("**Key Macro Metrics (Last Value + Z):**")
            # × ×—×œ×§ ×œ×‘×œ×•×§×™× ×©×œ ×¢×“ 3 KPIs ×‘×©×•×¨×”
            chunk_size = 3
            for i in range(0, len(metrics), chunk_size):
                row = metrics[i : i + chunk_size]
                cols = st.columns(len(row))
                for c, m in zip(cols, row):
                    val_str = "N/A" if m["value"] is None else f"{m['value']:.2f}"
                    z_str = "" if m["z"] is None else f" (Z={m['z']:.2f})"
                    with c:
                        st.metric(m["label"], f"{val_str}{z_str}")

    # ×¢×¨×›×™× ××—×¨×•× ×™× + Z-scores ×‘-expander
    with st.expander("ğŸ” ×¤×™×¨×•×˜ Snapshot (last values / z-scores / regimes)", expanded=False):
        if snapshot is not None:
            last_vals = snapshot.get("last_values", {})
            zscores = snapshot.get("zscores", {})
            regimes = snapshot.get("regimes", {})

            if last_vals or zscores or regimes:
                c1, c2, c3 = st.columns(3)
                with c1:
                    st.markdown("**Last Values**")
                    st.json(last_vals or {}, expanded=False)
                with c2:
                    st.markdown("**Z-scores**")
                    st.json(zscores or {}, expanded=False)
                with c3:
                    st.markdown("**Regimes (by factor)**")
                    st.json(regimes or {}, expanded=False)
                st.markdown("---")

            st.markdown("**Snapshot ××œ× (JSON):**")
            st.json(snapshot, expanded=False)
        else:
            st.info("××™×Ÿ Snapshot ×ª×§×™×Ÿ ×œ×”×¦×’×”.")

        # ×›×¤×ª×•×¨ ×”×•×¨×“×” ×›-JSON
        if snapshot is not None:
            snap_payload = {
                "workspace": {
                    "start": str(ws.start_date) if ws.start_date is not None else None,
                    "end": str(ws.end_date) if ws.end_date is not None else None,
                    "freq": ws.freq,
                    "env": ws.env,
                },
                "snapshot": snapshot,
            }
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ Macro Snapshot (JSON)",
                data=json.dumps(snap_payload, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="macro_snapshot.json",
                mime="application/json",
                key=keygen(TAB_KEY, "snapshot", "dl"),
            )

    # Debug Panels ×× ×”×“×’×œ ×¤×¢×™×œ
    _render_debug_panels(snapshot=snapshot, overlay=state.macro_profile or {})

# ---------------------------------------------------------------------------
# Sidebar Controls â€” Presets, Feature Engineering, Risk, Regime Model, IBKR
# ---------------------------------------------------------------------------


# ===========================
# Presets â€” ×©××™×¨×”/×˜×¢×™× ×”
# ===========================


def _collect_ui_cfg_from_state(namespace: str = TAB_KEY) -> Dict[str, Any]:
    """××•×¡×£ ××ª ×¢×¨×›×™ ×”Ö¾UI ××ª×•×š session_state ×›×“×™ ×œ×©××•×¨ Preset.

    ×œ× ×›×•×œ×œ ××ª ×”-Workspace (×˜×•×•×— ×ª××¨×™×›×™×/×ª×“×™×¨×•×ª/×¡×‘×™×‘×”) â€” ×–×” × ×©××¨ ×‘× ×¤×¨×“.
    ××” ×›×Ÿ × ××¡×£:
    - ×¤×¨××˜×¨×™ ×ª××™××•×ª/××•×“×œ:
        macro_model, lookback, ewma_lambda, min_regime
    - ×©×œ×™×˜×ª ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™×ª:
        target_vol, max_pair_weight, sector_cap
    - ×¦×™×•×Ÿ Macro Fit:
        score_filter_threshold, score_gain_floor, score_weight_gain, caps_mode
    - Paper mode:
        paper_mode
    """
    keys = {
        "model": keygen(namespace, "macro_model"),
        "lookback": keygen(namespace, "lookback"),
        "ewma_lambda": keygen(namespace, "ewma"),
        "min_regime": keygen(namespace, "min_regime"),
        "target_vol": keygen(namespace, "target_vol"),
        "max_pair_weight": keygen(namespace, "max_pair_w"),
        "sector_cap": keygen(namespace, "sector_cap"),
        "score_filter_threshold": keygen(namespace, "score_thr"),
        "score_gain_floor": keygen(namespace, "score_floor"),
        "score_weight_gain": keygen(namespace, "score_gain"),
        "caps_mode": keygen(namespace, "caps_mode"),
        "paper_mode": keygen(namespace, "paper"),
    }
    out: Dict[str, Any] = {}
    for name, k in keys.items():
        out[name] = state_get(k)
    return out

def _get_builtin_macro_presets() -> Dict[str, Dict[str, Any]]:
    """
    Presets ××•×‘× ×™× ×œ×˜××‘ ×”×××§×¨×•.

    ×”××¤×ª×—×•×ª ×ª×•×××™× ×œ-UI cfg ×©× ××¡×£ ×‘-_collect_ui_cfg_from_state /
    ×•××™×•×©× ×“×¨×š _apply_ui_preset:
        - model
        - lookback
        - ewma_lambda
        - min_regime
        - target_vol
        - max_pair_weight
        - sector_cap
        - score_filter_threshold
        - score_gain_floor
        - score_weight_gain
        - caps_mode
        - paper_mode
    """
    return {
        "base": {
            "model": "HMM",
            "lookback": 365,
            "ewma_lambda": 0.94,
            "min_regime": 15,
            "target_vol": 15.0,
            "max_pair_weight": 5.0,
            "sector_cap": 20.0,
            "score_filter_threshold": 30.0,
            "score_gain_floor": 60.0,
            "score_weight_gain": 0.15,
            "caps_mode": "hint",
            "paper_mode": True,
        },
        "risk_off_defensive": {
            "model": "HMM",
            "lookback": 365,
            "ewma_lambda": 0.97,
            "min_regime": 20,
            "target_vol": 10.0,
            "max_pair_weight": 3.0,
            "sector_cap": 15.0,
            "score_filter_threshold": 40.0,
            "score_gain_floor": 55.0,
            "score_weight_gain": 0.10,
            "caps_mode": "clip",
            "paper_mode": True,
        },
        "risk_on_aggressive": {
            "model": "k-means",
            "lookback": 240,
            "ewma_lambda": 0.90,
            "min_regime": 10,
            "target_vol": 25.0,
            "max_pair_weight": 8.0,
            "sector_cap": 30.0,
            "score_filter_threshold": 20.0,
            "score_gain_floor": 70.0,
            "score_weight_gain": 0.20,
            "caps_mode": "hint",
            "paper_mode": False,
        },
        "balanced_regime": {
            "model": "HSMM",
            "lookback": 360,
            "ewma_lambda": 0.95,
            "min_regime": 15,
            "target_vol": 17.0,
            "max_pair_weight": 6.0,
            "sector_cap": 25.0,
            "score_filter_threshold": 30.0,
            "score_gain_floor": 65.0,
            "score_weight_gain": 0.15,
            "caps_mode": "clip",
            "paper_mode": True,
        },
        "macro_research_deep": {
            "model": "XGBoost",
            "lookback": 720,
            "ewma_lambda": 0.97,
            "min_regime": 20,
            "target_vol": 12.0,
            "max_pair_weight": 4.0,
            "sector_cap": 20.0,
            "score_filter_threshold": 25.0,
            "score_gain_floor": 60.0,
            "score_weight_gain": 0.12,
            "caps_mode": "hint",
            "paper_mode": True,
        },
    }

def _apply_ui_preset(preset: Dict[str, Any], namespace: str = TAB_KEY) -> None:
    """××™×™×©× Preset ×¢×¨×›×™× ×œÖ¾session_state ×›×š ×©×”×•×•×™×“×’'×˜×™× ×™×ª×¢×“×›× ×•.

    Notes
    -----
    - ×œ× ××‘×¦×¢ ×©×•× ×—×™×©×•×‘ â€” ×¨×§ ××¢×“×›×Ÿ session_state.
    - render() ××—×¨×™ ×–×” ××¤×¢×™×œ ××ª ×”×—×™×©×•×‘ ××—×“×© (st.rerun).
    """
    mapping = {
        "model": keygen(namespace, "macro_model"),
        "lookback": keygen(namespace, "lookback"),
        "ewma_lambda": keygen(namespace, "ewma"),
        "min_regime": keygen(namespace, "min_regime"),
        "target_vol": keygen(namespace, "target_vol"),
        "max_pair_weight": keygen(namespace, "max_pair_w"),
        "sector_cap": keygen(namespace, "sector_cap"),
        "score_filter_threshold": keygen(namespace, "score_thr"),
        "score_gain_floor": keygen(namespace, "score_floor"),
        "score_weight_gain": keygen(namespace, "score_gain"),
        "caps_mode": keygen(namespace, "caps_mode"),
        "paper_mode": keygen(namespace, "paper"),
    }
    for name, val in preset.items():
        if name in mapping:
            state_set(mapping[name], val)


def preset_ui_controls(namespace: str = TAB_KEY) -> None:
    """UI ×œ×˜×¢×™× ×ª/×©××™×¨×ª ×¤×¨×•×¤×™×œ ×¤×¨××˜×¨×™× ×©×œ ×”×˜××‘ (Preset).

    ×¢×›×©×™×• ×›×•×œ×œ ×’×:
    ---------------
    - ×˜×¢×™× ×” ××•×˜×•××˜×™×ª ×©×œ Preset ××•×‘× ×” ×œ×¤×™ macro_preset_selected
      ×©××’×™×¢ ××”-dashboard / render_macro_tab.
    - ×¨×©×™××ª Presets ××•×‘× ×™× (base / risk_off_defensive / risk_on_aggressive /
      balanced_regime / macro_research_deep) ×¢× ×›×¤×ª×•×¨ ×˜×¢×™× ×” ××”-UI.
    - ×¢×“×™×™×Ÿ ×ª×•××š ×‘×©××™×¨×”/×˜×¢×™× ×” ×©×œ Preset ×›-JSON ×›××• ×§×•×“×.
    """
    builtin_presets = _get_builtin_macro_presets()

    with st.sidebar.expander("ğŸ’¾ Presets (×©××™×¨×”/×˜×¢×™× ×”)", expanded=False):
        # --- 1) ×˜×¢×™× ×” ××•×˜×•××˜×™×ª ×œ×¤×™ macro_preset_selected ××”-router/dashboard ---
        macro_preset_selected = state_get("macro_preset_selected", None)
        applied_name_key = keygen(namespace, "preset", "applied_name")
        applied_name = state_get(applied_name_key, None)

        if (
            isinstance(macro_preset_selected, str)
            and macro_preset_selected in builtin_presets
            and applied_name != macro_preset_selected
        ):
            # × ×˜×¢×Ÿ Preset ××•×‘× ×” ×©× ×©×œ×— ××”-dashboard (nav_payload.macro_preset)
            preset_data = builtin_presets[macro_preset_selected]
            _apply_ui_preset(preset_data, namespace)
            state_set(applied_name_key, macro_preset_selected)
            st.info(
                f"× ×˜×¢×Ÿ Preset ×××§×¨×• ××”×“×©×‘×•×¨×“: **{macro_preset_selected}**",
                icon="âœ…" if hasattr(st, "info") else None,
            )

        # --- 2) Presets ××•×‘× ×™× ×œ×‘×—×™×¨×” ×™×“× ×™×ª ××”-UI ---
        if builtin_presets:
            st.markdown("**Presets ××•×‘× ×™× (Macro):**")
            preset_names = list(builtin_presets.keys())
            select_label = "×‘×—×¨ Preset ××•×‘× ×”"
            chosen = st.selectbox(
                select_label,
                options=["<None>"] + preset_names,
                index=0,
                key=keygen(namespace, "preset", "builtin_select"),
            )
            if chosen != "<None>":
                if st.button(
                    "×˜×¢×Ÿ Preset ××•×‘× ×”",
                    key=keygen(namespace, "preset", "load_builtin"),
                ):
                    _apply_ui_preset(builtin_presets[chosen], namespace)
                    state_set("macro_preset_selected", chosen)
                    state_set(applied_name_key, chosen)
                    st.success(f"Preset ××•×‘× ×” **{chosen}** × ×˜×¢×Ÿ ×•×”×•×—×œ ×¢×œ ×”-UI.")

        st.markdown("---")

        # --- 3) ×©××™×¨×ª ×”×¤×¨×•×¤×™×œ ×”× ×•×›×—×™ ×›-JSON (×›××• ×§×•×“×) ---
        if st.button("×©××•×¨ ×¤×¨×•×¤×™×œ × ×•×›×—×™", key=keygen(namespace, "preset", "save")):
            cfg = _collect_ui_cfg_from_state(namespace)
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ Preset (JSON)",
                data=json.dumps(cfg, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="macro_preset.json",
                mime="application/json",
                key=keygen(namespace, "preset", "dl"),
            )

        # --- 4) ×˜×¢×™× ×ª Preset ×—×™×¦×•× ×™ ×-JSON (×›××• ×§×•×“×) ---
        up = st.file_uploader(
            "×˜×¢×Ÿ Preset (JSON)",
            type=["json"],
            key=keygen(namespace, "preset", "upl"),
        )
        if up is not None:
            try:
                data = json.loads(up.read().decode("utf-8"))
                if isinstance(data, dict):
                    _apply_ui_preset(data, namespace)
                    st.success("Preset × ×˜×¢×Ÿ ××§×•×‘×¥ JSON â€” ××¨×¢× ×Ÿ ××ª ×”×˜××‘â€¦")
                    # × ×¢×“×›×Ÿ ×’× ××ª applied_name ×›×“×™ ×©×œ× ×™×“×¨×¡ ×¢"×™ macro_preset_selected
                    state_set(applied_name_key, "custom_from_file")
                    st.rerun()
                else:
                    st.warning("×§×•×‘×¥ Preset ×œ× ×ª×§×™×Ÿ (×œ× ××•×‘×™×™×§×˜ JSON).")
            except Exception as e:  # noqa: BLE001
                st.error(f"×˜×¢×™× ×ª Preset × ×›×©×œ×”: {e}")

# ===========================
# Feature Engineering ×œ×¤×§×˜×•×¨×™ ×××§×¨×•
# ===========================


def _parse_int_csv(s: str) -> List[int]:
    s = (s or "").strip()
    return [int(x.strip()) for x in s.split(",") if x.strip()] if s else []


def _feature_params_ui(namespace: str = TAB_KEY) -> Dict[str, Any]:
    """UI ××ª×§×“× ×œ×¤×™×¦'×¨×™× ×¢×œ ×¤×§×˜×•×¨×™ ×××§×¨×•; ××•×—×–×¨ ×œ×× ×•×¢ ×“×¨×š cfg['feature_params'].

    ×¤×™×¦'×¨×™× × ×ª××›×™×:
    ----------------
    - Z-scores (×—×œ×•×Ÿ + winsorization)
    - Momentum windows (×¢×œ ×¨××•×ª / ×ª×©×•××•×ª)
    - Volatility windows
    - Rolling means
    - EWMA spans
    - Rank windows
    - Lags
    - YoY (×©×™× ×•×™ ×©× ×” ××—×•×¨×”)
    - Seasonal dummies (×—×•×“×©×™×/×¨×‘×¢×•× ×™×)
    - Standardization (z-score ×›×•×œ×œ)
    - Prefix ×œ×©××•×ª ×¤×™×¦'×¨×™×
    - NaN policy (ffill / bfill / zero / drop)

    ×‘× ×•×¡×£:
    - include_raw_factors: ×”×× ×œ×”×©××™×¨ ×’× ××ª ×”×¤×§×˜×•×¨×™× ×”××§×•×¨×™×™×.
    - drop_low_quality: ××¤×©×¨×•×ª ×œ× ×§×•×ª ×¤×§×˜×•×¨×™× ×¢× ××™×›×•×ª ×¡×˜×˜×™×¡×˜×™×ª × ××•×›×” (×œ×©×™××•×© ×¤× ×™××™ ×‘×× ×•×¢).
    """
    with st.sidebar.expander("ğŸ§ª Feature engineering (×××§×¨×•)", expanded=False):
        st.caption("×¤×™×¦'×¨×™× ××—×•×©×‘×™× ×¢×œ ××™× ×“×™×§×˜×•×¨×™ ×××§×¨×• (×•×œ× ×¢×œ ×¡×¤×¨×“×™ ×–×•×’×•×ª).")

        z_window = st.number_input(
            "Z window (×™××™×)",
            min_value=5,
            max_value=730,
            value=int(state_get(keygen(namespace, "feat", "zwin"), 60) or 60),
            step=5,
            key=keygen(namespace, "feat", "zwin"),
        )
        z_winsor = st.number_input(
            "Z winsor (×¡×˜×™×•×ª ×ª×§×Ÿ)",
            min_value=0.5,
            max_value=10.0,
            value=float(state_get(keygen(namespace, "feat", "zw"), 3.0) or 3.0),
            step=0.5,
            key=keygen(namespace, "feat", "zw"),
        )

        mom_windows = st.text_input(
            "Momentum windows (csv)",
            value=str(state_get(keygen(namespace, "feat", "mom"), "20,60")),
            key=keygen(namespace, "feat", "mom"),
            help="×œ××©×œ: 20,60,120",
        )
        vol_windows = st.text_input(
            "Vol windows (csv)",
            value=str(state_get(keygen(namespace, "feat", "vol"), "20")),
            key=keygen(namespace, "feat", "vol"),
        )
        mean_windows = st.text_input(
            "Rolling mean windows (csv)",
            value=str(state_get(keygen(namespace, "feat", "mean"), "")),
            key=keygen(namespace, "feat", "mean"),
        )
        ewma_spans = st.text_input(
            "EWMA spans (csv)",
            value=str(state_get(keygen(namespace, "feat", "ewma"), "")),
            key=keygen(namespace, "feat", "ewma"),
        )
        rank_windows = st.text_input(
            "Rank windows (csv)",
            value=str(state_get(keygen(namespace, "feat", "rank"), "")),
            key=keygen(namespace, "feat", "rank"),
        )
        lags = st.text_input(
            "Lags (csv)",
            value=str(state_get(keygen(namespace, "feat", "lags"), "1,5,20")),
            key=keygen(namespace, "feat", "lags"),
        )

        yoy_window = st.number_input(
            "YoY window (×™××™×)",
            min_value=60,
            max_value=1260,
            value=int(state_get(keygen(namespace, "feat", "yoy"), 252) or 252),
            step=12,
            key=keygen(namespace, "feat", "yoy"),
        )

        vol_on = st.selectbox(
            "Vol on",
            options=["returns", "levels"],
            index=0,
            key=keygen(namespace, "feat", "volon"),
        )
        mean_on = st.selectbox(
            "Mean on",
            options=["levels", "returns"],
            index=0,
            key=keygen(namespace, "feat", "meanon"),
        )
        ewma_on = st.selectbox(
            "EWMA on",
            options=["levels", "returns"],
            index=0,
            key=keygen(namespace, "feat", "ewmaon"),
        )

        seasonal_dummies = st.checkbox(
            "Seasonal dummies (×—×•×“×©×™×/×¨×‘×¢×•× ×™×)",
            value=bool(state_get(keygen(namespace, "feat", "season"), False)),
            key=keygen(namespace, "feat", "season"),
        )
        quality_window = st.number_input(
            "Quality window (××•×¤×¦×™×•× ×œ×™)",
            min_value=0,
            max_value=365,
            value=int(state_get(keygen(namespace, "feat", "qual"), 60) or 60),
            step=5,
            key=keygen(namespace, "feat", "qual"),
            help="0=×›×‘×•×™; >0 ×™××¤×©×¨ ××“×™×“×ª ××™×›×•×ª ×œ×¤×§×˜×•×¨×™× ×œ××•×¨×š ×—×œ×•×Ÿ ×–×”.",
        )
        standardize = st.checkbox(
            "Standardize features (z-score ×›×•×œ×œ)",
            value=bool(state_get(keygen(namespace, "feat", "std"), False)),
            key=keygen(namespace, "feat", "std"),
        )
        include_raw = st.checkbox(
            "×”×©××¨ ×’× ×¤×§×˜×•×¨×™× ××§×•×¨×™×™× (raw)",
            value=bool(state_get(keygen(namespace, "feat", "raw"), True)),
            key=keygen(namespace, "feat", "raw"),
        )
        drop_low_quality = st.checkbox(
            "× ×§×” ×¤×§×˜×•×¨×™× ×¢× ××™×›×•×ª ×¡×˜×˜×™×¡×˜×™×ª × ××•×›×”",
            value=bool(state_get(keygen(namespace, "feat", "drop_lowq"), False)),
            key=keygen(namespace, "feat", "drop_lowq"),
        )

        prefix = st.text_input(
            "Prefix ×œ×©××•×ª ×¤×™×¦'×¨×™×",
            value=str(state_get(keygen(namespace, "feat", "prefix"), "macro_")),
            key=keygen(namespace, "feat", "prefix"),
        )
        dropna_strategy = st.selectbox(
            "NaN policy",
            options=["ffill", "bfill", "zero", "drop"],
            index=0,
            key=keygen(namespace, "feat", "nan"),
        )

    params = {
        "z_window": int(z_window),
        "z_winsor": float(z_winsor),
        "mom_windows": _parse_int_csv(mom_windows),
        "vol_windows": _parse_int_csv(vol_windows),
        "rolling_mean_windows": _parse_int_csv(mean_windows),
        "ewma_spans": _parse_int_csv(ewma_spans),
        "rank_windows": _parse_int_csv(rank_windows),
        "lags": _parse_int_csv(lags),
        "yoy_window": int(yoy_window),
        "vol_on": vol_on,
        "mean_on": mean_on,
        "ewma_on": ewma_on,
        "seasonal_dummies": bool(seasonal_dummies),
        "quality_window": int(quality_window),
        "standardize": bool(standardize),
        "include_raw_factors": bool(include_raw),
        "drop_low_quality": bool(drop_low_quality),
        "prefix": prefix,
        "dropna_strategy": dropna_strategy,
    }
    # × ×©××•×¨ ×’× ×¢×•×ª×§ ××—×¨×•×Ÿ ×œ×¦×¨×›×™ Debug / ×”×©×•×•××”
    state_set(keygen(namespace, "feat", "last_params"), dict(params))
    return params


# ===========================
# Risk Controls (sizing & caps)
# ===========================


def _parse_caps_text(s: str) -> Dict[str, float]:
    """×××™×¨ ×˜×§×¡×˜ ×‘×¡×’× ×•×Ÿ 'Tech:0.25, Energy:0.2' ×œ××™×œ×•×Ÿ {×©×: cap}."""
    out: Dict[str, float] = {}
    s = (s or "").strip()
    if not s:
        return out
    for part in s.split(","):
        if ":" in part:
            k, v = part.split(":", 1)
            try:
                out[str(k).strip()] = float(v.strip())
            except Exception:  # noqa: BLE001
                continue
    return out


def _macro_risk_controls_ui(namespace: str = TAB_KEY) -> Dict[str, Any]:
    """UI ×œ×©×›×‘×ª ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™×ª: sizing / covariance / caps + Risk Presets."""
    with st.sidebar.expander("ğŸ›¡ï¸ Risk Controls (sizing & caps)", expanded=False):
        risk_sizing = st.selectbox(
            "Sizing method",
            ["invvol", "erc"],
            index=0,
            key=keygen(namespace, "risk", "sizing"),
            help="invvol = 1/Ïƒ; erc = Equal Risk Contribution.",
        )
        cov_window = st.number_input(
            "Cov window (×™××™×)",
            min_value=20,
            max_value=252,
            value=int(state_get(keygen(namespace, "risk", "covwin"), 60) or 60),
            step=5,
            key=keygen(namespace, "risk", "covwin"),
        )
        cov_shrink = st.number_input(
            "Cov shrink (0..1)",
            min_value=0.0,
            max_value=1.0,
            value=float(state_get(keygen(namespace, "risk", "shrink"), 0.1) or 0.1),
            step=0.05,
            key=keygen(namespace, "risk", "shrink"),
        )

        st.caption("Caps ×‘×¤×•×¨××˜: Tech:0.25, Energy:0.2 â€¦ (×¢×¨×›×™× ×‘×™×Ÿ 0 ×œ-1)")

        sector_caps_txt = st.text_input(
            "Sector caps",
            value=str(state_get(keygen(namespace, "risk", "sectorcaps"), "")),
            key=keygen(namespace, "risk", "sectorcaps"),
        )
        region_caps_txt = st.text_input(
            "Region caps",
            value=str(state_get(keygen(namespace, "risk", "regioncaps"), "")),
            key=keygen(namespace, "risk", "regioncaps"),
        )
        currency_caps_txt = st.text_input(
            "Currency caps",
            value=str(state_get(keygen(namespace, "risk", "currencycaps"), "")),
            key=keygen(namespace, "risk", "currencycaps"),
        )

        # ×©××™×¨×ª ×§×¤×¡ ×“×™×§×˜×™×™× ×‘-session_state (×›××• ×‘×’×¨×¡×” ×”×™×©× ×”)
        sector_caps_dict = _parse_caps_text(sector_caps_txt)
        region_caps_dict = _parse_caps_text(region_caps_txt)
        currency_caps_dict = _parse_caps_text(currency_caps_txt)

        state_set(keygen(namespace, "risk", "sectorcaps_dict"), sector_caps_dict)
        state_set(keygen(namespace, "risk", "regioncaps_dict"), region_caps_dict)
        state_set(keygen(namespace, "risk", "currencycaps_dict"), currency_caps_dict)

        st.divider()
        # Risk Presets (save/load)
        risk_preset = {
            "risk_sizing": risk_sizing,
            "cov_window": int(cov_window),
            "cov_shrink": float(cov_shrink),
            "sector_caps": sector_caps_txt,
            "region_caps": region_caps_txt,
            "currency_caps": currency_caps_txt,
        }
        colp1, colp2 = st.columns(2)
        with colp1:
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ Risk Preset (JSON)",
                data=json.dumps(risk_preset, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="macro_risk_preset.json",
                mime="application/json",
                key=keygen(namespace, "risk", "dl"),
            )
        with colp2:
            f_risk = st.file_uploader(
                "×˜×¢×Ÿ Risk Preset (JSON)",
                type=["json"],
                key=keygen(namespace, "risk", "upl"),
            )
            if f_risk is not None:
                try:
                    data = json.loads(f_risk.read().decode("utf-8"))
                    if isinstance(data, dict):
                        if "risk_sizing" in data:
                            state_set(keygen(namespace, "risk", "sizing"), str(data["risk_sizing"]))
                        if "cov_window" in data:
                            state_set(keygen(namespace, "risk", "covwin"), int(data["cov_window"]))
                        if "cov_shrink" in data:
                            state_set(keygen(namespace, "risk", "shrink"), float(data["cov_shrink"]))
                        if "sector_caps" in data:
                            state_set(keygen(namespace, "risk", "sectorcaps"), str(data["sector_caps"]))
                        if "region_caps" in data:
                            state_set(keygen(namespace, "risk", "regioncaps"), str(data["region_caps"]))
                        if "currency_caps" in data:
                            state_set(keygen(namespace, "risk", "currencycaps"), str(data["currency_caps"]))
                        st.success("Risk Preset × ×˜×¢×Ÿ â€” ××¨×¢× ×Ÿ ××ª ×”×˜××‘â€¦")
                        st.rerun()
                    else:
                        st.warning("×§×•×‘×¥ Risk Preset ×œ× ×ª×§×™×Ÿ.")
                except Exception as e:  # noqa: BLE001
                    st.error(f"×˜×¢×™× ×ª Risk Preset × ×›×©×œ×”: {e}")

    return {
        "risk_sizing": risk_sizing,
        "cov_window": int(cov_window),
        "cov_shrink": float(cov_shrink),
        "sector_caps_dict": sector_caps_dict,
        "region_caps_dict": region_caps_dict,
        "currency_caps_dict": currency_caps_dict,
    }


# ===========================
# Regime Model UI (HMM / KMeans / XGB)
# ===========================


def _macro_regime_model_ui(namespace: str = TAB_KEY) -> Dict[str, Any]:
    """UI ×œ×”×’×“×¨×ª ××•×“×œ ××©×˜×¨×™× (Regime model) ×œ-Profile/Backtest."""
    with st.sidebar.expander("ğŸ§  Regime model (HMM / KMeans / XGB)", expanded=False):
        rm_mode = st.selectbox(
            "Mode",
            ["none", "hmm", "kmeans", "xgb"],
            index=0,
            key=keygen(namespace, "rm", "mode"),
        )
        rm_states = st.number_input(
            "States (k)",
            min_value=2,
            max_value=6,
            value=int(state_get(keygen(namespace, "rm", "k"), 3) or 3),
            step=1,
            key=keygen(namespace, "rm", "k"),
        )
        rm_pca = st.number_input(
            "PCA components (0=off)",
            min_value=0,
            max_value=16,
            value=int(state_get(keygen(namespace, "rm", "pca"), 3) or 3),
            step=1,
            key=keygen(namespace, "rm", "pca"),
        )
        rm_smooth = st.number_input(
            "Smooth window",
            min_value=0,
            max_value=50,
            value=int(state_get(keygen(namespace, "rm", "smooth"), 5) or 5),
            step=1,
            key=keygen(namespace, "rm", "smooth"),
        )
        rm_hyst = st.number_input(
            "Hysteresis (ticks)",
            min_value=0,
            max_value=50,
            value=int(state_get(keygen(namespace, "rm", "hyst"), 3) or 3),
            step=1,
            key=keygen(namespace, "rm", "hyst"),
        )
        rm_temp = st.number_input(
            "Temp scale (<=1=sharp)",
            min_value=0.1,
            max_value=5.0,
            value=float(state_get(keygen(namespace, "rm", "temp"), 1.0) or 1.0),
            step=0.1,
            key=keygen(namespace, "rm", "temp"),
        )
        rm_prior = st.text_input(
            "Class prior (csv, optional)",
            value=str(state_get(keygen(namespace, "rm", "prior"), "")),
            key=keygen(namespace, "rm", "prior"),
            help="×œ×“×•×’××”: 0.2,0.5,0.3 ×›××©×¨ ×”×¡×›×•× â‰ˆ 1.",
        )

    # × ×‘× ×” ××‘× ×” cfg ×§×˜×Ÿ ×œ×©×™××•×© ×‘-compute_profile / backtest
    prior_list: Optional[List[float]] = None
    if rm_prior.strip():
        try:
            prior_list = [float(x.strip()) for x in rm_prior.split(",") if x.strip()]
        except Exception:  # noqa: BLE001
            prior_list = None

    return {
        "mode": rm_mode,
        "n_states": int(rm_states),
        "pca_components": int(rm_pca),
        "smooth_window": int(rm_smooth),
        "hysteresis": int(rm_hyst),
        "temp_scale": float(rm_temp),
        "class_prior": prior_list,
    }


# ===========================
# IBKR Client Portal â€” ××§×•×¨×•×ª Live
# ===========================


def _macro_ibkr_portal_ui(namespace: str = TAB_KEY) -> None:
    """UI ×œ× ×™×”×•×œ ×—×™×‘×•×¨ IBKR Client Portal ×•×”×’×“×¨×ª ××§×•×¨×•×ª live ×œ× ×ª×•× ×™ ×××§×¨×•."""
    with st.sidebar.expander("ğŸ” IBKR Client Portal", expanded=False):
        ibkr_token = st.text_input(
            "Portal access token",
            type="password",
            value=str(state_get(keygen(namespace, "ibkr", "token"), "")),
            key=keygen(namespace, "ibkr", "token_input"),
            help="×”×“×‘×§ ×›××Ÿ ×˜×•×§×Ÿ ×’×™×©×” ×-Client Portal. × ×©××¨ ×‘×–×™×›×¨×•×Ÿ ×¨×™×¦×” ×‘×œ×‘×“.",
        )
        if ibkr_token:
            state_set(keygen(namespace, "ibkr", "token"), ibkr_token)

        ibkr_base = st.text_input(
            "Base URL",
            value=str(state_get(keygen(namespace, "ibkr", "base"), "https://localhost:5000")),
            key=keygen(namespace, "ibkr", "base_input"),
            help="×œ××©×œ: https://localhost:5000 (Client Portal)",
        )
        if ibkr_base:
            state_set(keygen(namespace, "ibkr", "base"), ibkr_base)

        auto_live = st.toggle(
            "×”×¤×¢×œ Live ××•×˜×•××˜×™×ª ×× ×™×© ×˜×•×§×Ÿ",
            value=bool(state_get(keygen(namespace, "ibkr", "autolive"), True)),
            key=keygen(namespace, "ibkr", "autolive"),
        )

        st.divider()
        st.markdown("**××§×•×¨×•×ª ×××§×¨×• ×œ×“×•×’××” (×“×¨×š IBKR):**")
        col1, col2, col3 = st.columns([1.2, 1, 1])
        with col1:
            src_key = st.text_input(
                "×©× ××§×•×¨ (×œ×•×’×™)",
                value=str(state_get(keygen(namespace, "ibkr", "src_key"), "vix_live")),
                key=keygen(namespace, "ibkr", "src_key"),
            )
        with col2:
            conid = st.text_input(
                "CONID",
                value=str(state_get(keygen(namespace, "ibkr", "conid"), "12222083")),
                key=keygen(namespace, "ibkr", "conid"),
            )
        with col3:
            field = st.text_input(
                "FIELD",
                value=str(state_get(keygen(namespace, "ibkr", "field"), "31")),
                key=keygen(namespace, "ibkr", "field"),
            )

        if st.button("â• ×”×•×¡×£ ××§×•×¨ IBKR", key=keygen(namespace, "ibkr", "add_src")):
            uri = f"ibkr:conid={conid}?field={field}"
            overrides = state_get("macro_sources_overrides", {}) or {}
            overrides[str(src_key)] = uri
            state_set("macro_sources_overrides", overrides)
            st.success(f"× ×•×¡×£ ××§×•×¨: {src_key} â†’ {uri}")

        overrides = state_get("macro_sources_overrides", {})
        if overrides:
            st.caption("××§×•×¨×•×ª ×©× ×•×¡×¤×• ×‘×˜××‘ ×–×”")
            st.json(overrides)
            if st.button("× ×§×” Overrides", key=keygen(namespace, "ibkr", "clr")):
                state_set("macro_sources_overrides", {})
                st.success("×”Ö¾Overrides × ×•×§×•.")

        st.divider()
        # Ping ×—×™×‘×•×¨ IBKR
        if st.button("ğŸ” ×‘×“×•×§ ×—×™×‘×•×¨ IBKR", key=keygen(namespace, "ibkr", "ping")):
            try:
                from core.macro_data import MacroDataClient  # type: ignore

                token_val = state_get(keygen(namespace, "ibkr", "token"))
                base_val = state_get(keygen(namespace, "ibkr", "base"), "https://localhost:5000")
                if not token_val:
                    st.error("×—×¡×¨ Portal access token â€” ×”×“×‘×§ ×˜×•×§×Ÿ ×œ×¤× ×™ ×‘×“×™×§×”.")
                else:
                    client = MacroDataClient(
                        sources={"ping": f"ibkr:conid={conid}?field={field}"},
                        allow_ibkr=True,
                        ibkr_token=token_val,
                        ibkr_base_url=base_val,
                        allow_yf=False,
                        allow_duckdb=False,
                        allow_sql=False,
                    )
                    with st.spinner("×‘×•×“×§ ×—×™×‘×•×¨ ×œ-IBKRâ€¦"):
                        df_ping = client.get("ping", live=True)
                    if isinstance(df_ping, pd.DataFrame) and not df_ping.empty:
                        val = df_ping.get("value")
                        if val is not None and not val.empty:
                            _ = float(val.iloc[-1])
                            st.success("âœ… ×—×™×‘×•×¨ ×ª×§×™×Ÿ ×•×§×™×‘×œ× ×• ×¢×¨×š.")
                            st.dataframe(df_ping.tail(1), use_container_width=True)
                        else:
                            st.warning("×”×ª×§×‘×œ×” ×ª×©×•×‘×” ××š ×œ×œ× ×¢×¨×š ×ª×§×™×Ÿ.")
                    else:
                        st.warning("×œ× ×”×ª×§×‘×œ×” ×ª×©×•×‘×ª DataFrame ×ª×§×¤×” ×-IBKR.")
            except Exception as e:  # noqa: BLE001
                LOGGER.exception("IBKR ping failed: %s", e)
                st.error(f"âŒ ×›×©×œ ×‘×‘×“×™×§×ª ×—×™×‘×•×¨: {e}")

        # Auto-live ××™× ×¤×•×¨××˜×™×‘×™ (×”×¢×“×¤×•×ª) â€” ××ª ×”×¢×“×›×•×Ÿ ×œ-MacroConfig × ×¢×©×” ×‘-render()
        state_set(keygen(namespace, "ibkr", "auto_live_flag"), bool(auto_live))


# ===========================
# Sidebar ××¨×›×–×™ ×œ×¤×¨××˜×¨×™ MacroConfig
# ===========================


def _render_sidebar(namespace: str = TAB_KEY) -> Dict[str, Any]:
    """Sidebar ×œ×¤×¨××˜×¨×™× ×”××¨×›×–×™×™× ×©×œ MacroConfig (×œ×œ× Workspace).

    ××” ××•×’×“×¨ ×›××Ÿ:
    --------------
    - macro_model: ×¡×•×’ ××•×“×œ ×”××©×˜×¨ (HMM/HSMM/k-means/XGBoost) â€” ××™× ×¤×•×¨××˜×™×‘×™ ×œ×× ×•×¢.
    - lookback: ×—×œ×•×Ÿ ×¨×’×™×©×•×ª ×œ×–×•×’ (×™××™×).
    - ewma_lambda: ×¤×¨××˜×¨ ×”×—×œ×§×”.
    - min_regime: ××•×¨×š ××™× ×™××œ×™ ×œ××©×˜×¨ (×™××™×).
    - target_vol: ×™×¢×“ ×ª× ×•×“×ª×™×•×ª ×œ×ª×™×§ (%).
    - max_pair_weight: ××©×§×œ ××§×¡×™××œ×™ ×œ×–×•×’ (%).
    - sector_cap: ×ª×§×¨×ª ×¡×§×˜×•×¨ ×›×œ×œ×™×ª (%).
    - score_filter_threshold: ×¡×£ ×¡×™× ×•×Ÿ ×œ×¤×™ Macro Fit (0â€“100).
    - score_gain_floor: ×¨×¦×¤×ª ×¦×™×•×Ÿ ×©××¢×œ×™×” ××’×‘×™×¨×™× ××©×§×œ (0â€“100).
    - score_weight_gain: ×¢×•×¦××ª ×ª×’×‘×•×¨ ××©×§×œ (0.00â€“0.50).
    - caps_mode: hint / clip (×¨×§ ×¨××–×™× ××• ×—×™×ª×•×š ×‘×¤×•×¢×œ).
    - paper_mode: ×”×× ×”×˜××‘ ×¤×•×¢×œ ×‘-Paper Mode ×‘×œ×‘×“.

    ×”×—×–×¨×ª ×”×¢×¨×›×™×:
    --------------
    ×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ××™×œ×•×Ÿ ui_cfg; Workspace (date_range/freq/env) × ×œ×§×—
    ××”×¤×•× ×§×¦×™×” _workspace_sidebar ×•×©××•×¨ ×‘-session_state.
    """
    with st.sidebar:
        st.subheader("âš™ï¸ ×”×ª×××•×ª ×××§×¨×• ×›×œ×›×œ×™×•×ª â€” ×ª×¦×•×¨×”")

        model = st.selectbox(
            "×‘×—×™×¨×ª ××•×“×œ ××©×˜×¨×™×",
            options=["HMM", "HSMM", "k-means", "XGBoost"],
            index=0,
            key=keygen(namespace, "macro_model"),
        )

        lookback = st.slider(
            "Lookback ×œ×¨×’×™×©×•×ª/×¤×¨×•×¤×™×œ (×™××™×)",
            min_value=60,
            max_value=720,
            value=int(state_get(keygen(namespace, "lookback"), 365) or 365),
            step=15,
            key=keygen(namespace, "lookback"),
        )
        ewma_lambda = st.slider(
            "EWMA Î»",
            min_value=0.80,
            max_value=0.995,
            value=float(state_get(keygen(namespace, "ewma"), 0.94) or 0.94),
            step=0.005,
            key=keygen(namespace, "ewma"),
        )
        min_regime = st.slider(
            "××©×š ××™× ×™××œ×™ ×œ××©×˜×¨ (×™××™×)",
            min_value=5,
            max_value=60,
            value=int(state_get(keygen(namespace, "min_regime"), 15) or 15),
            step=1,
            key=keygen(namespace, "min_regime"),
        )

        target_vol = st.slider(
            "×™×¢×“ ×ª× ×•×“×ª×™×•×ª (%)",
            min_value=5.0,
            max_value=40.0,
            value=float(state_get(keygen(namespace, "target_vol"), 15.0) or 15.0),
            step=0.5,
            key=keygen(namespace, "target_vol"),
        )
        max_pair_weight = st.slider(
            "××§×¡' ××©×§×œ ×œ×–×•×’ (%)",
            min_value=1.0,
            max_value=20.0,
            value=float(state_get(keygen(namespace, "max_pair_w"), 5.0) or 5.0),
            step=0.5,
            key=keygen(namespace, "max_pair_w"),
        )
        sector_cap = st.slider(
            "×ª×§×¨×ª ×¡×§×˜×•×¨ ×›×œ×œ×™×ª (%)",
            min_value=5.0,
            max_value=50.0,
            value=float(state_get(keygen(namespace, "sector_cap"), 20.0) or 20.0),
            step=1.0,
            key=keygen(namespace, "sector_cap"),
        )

        st.markdown("**×¡×™× ×•×Ÿ/×ª×’×‘×•×¨ ×œ×¤×™ Macro Fit**")
        score_filter_threshold = st.slider(
            "×¡×£ ×¡×™× ×•×Ÿ ×œ×¤×™ ×¦×™×•×Ÿ (0â€“100)",
            min_value=0.0,
            max_value=100.0,
            value=float(state_get(keygen(namespace, "score_thr"), 30.0) or 30.0),
            step=1.0,
            key=keygen(namespace, "score_thr"),
        )
        score_gain_floor = st.slider(
            "×¨×¦×¤×ª ×ª×’×‘×•×¨ ××©×§×œ (0â€“100)",
            min_value=0.0,
            max_value=100.0,
            value=float(state_get(keygen(namespace, "score_floor"), 60.0) or 60.0),
            step=1.0,
            key=keygen(namespace, "score_floor"),
        )
        score_weight_gain = st.slider(
            "×¢×•×¦××ª ×ª×’×‘×•×¨ ××©×§×œ (0.00â€“0.50)",
            min_value=0.0,
            max_value=0.5,
            value=float(state_get(keygen(namespace, "score_gain"), 0.15) or 0.15),
            step=0.01,
            key=keygen(namespace, "score_gain"),
        )
        caps_mode = st.selectbox(
            "××¦×‘ Caps (×¨××–/×—×™×ª×•×š)",
            options=["hint", "clip"],
            index=0,
            key=keygen(namespace, "caps_mode"),
        )

        paper_mode = st.toggle(
            "Paper Mode (×œ×œ× ×©×œ×™×—×” ×œ-Executor)",
            value=bool(state_get(keygen(namespace, "paper"), True)),
            key=keygen(namespace, "paper"),
        )

        st.divider()
        if st.button("××™×¤×•×¡ ×˜××‘ (×××§×¨×• ×‘×œ×‘×“)", key=keygen(namespace, "reset")):
            for k in list(st.session_state.keys()):
                if str(k).startswith("macro_") or str(k).startswith("feature_flag.") or str(k).startswith("risk."):
                    del st.session_state[k]
            st.success("×˜××‘ ×”×××§×¨×• ××•×¤×¡ â€” ××¨×¢× ×Ÿâ€¦")
            st.rerun()

    # Workspace (×ª××¨×™×›×™×/×ª×“×™×¨×•×ª/×¡×‘×™×‘×”) ×›×‘×¨ ×©××•×¨ ×‘-session_state ×¢"×™ _workspace_sidebar
    ws_state = state_get("macro_workspace", {})
    date_range_val: Optional[Tuple[Any, Any]] = None
    try:
        start = ws_state.get("start")
        end = ws_state.get("end")
        if start and end:
            date_range_val = (pd.to_datetime(start), pd.to_datetime(end))
    except Exception:  # noqa: BLE001
        date_range_val = None

    return {
        "date_range": date_range_val,
        "model": model,
        "lookback": lookback,
        "ewma_lambda": ewma_lambda,
        "min_regime": min_regime,
        "target_vol": target_vol,
        "max_pair_weight": max_pair_weight,
        "sector_cap": sector_cap,
        "score_filter_threshold": score_filter_threshold,
        "score_gain_floor": score_gain_floor,
        "score_weight_gain": score_weight_gain,
        "caps_mode": caps_mode,
        "paper_mode": paper_mode,
    }

# ---------------------------------------------------------------------------
# Visuals & Analytics â€” Regime Timeline, Features Heatmap, Overlay, Shocks, DNA
# ---------------------------------------------------------------------------


# ===========================
# Regime Timeline (probabilities)
# ===========================


def _render_regime_timeline(regimes_prob: Optional[pd.DataFrame]) -> None:
    """×ª×¨×©×™× ×”×¡×ª×‘×¨×•×™×•×ª ××©×˜×¨×™× (×× plotly ×–××™×Ÿ)."""
    if regimes_prob is None or regimes_prob.empty:
        st.info("××™×Ÿ × ×ª×•× ×™ ×”×¡×ª×‘×¨×•×™×•×ª ××©×˜×¨ ×œ×”×¦×’×”.")
        return
    if not _HAS_PX:
        st.info("Plotly ×œ× ××•×ª×§×Ÿ â€” ×“×œ×’ ×¢×œ ×”×ª×¨×©×™×.")
        return

    df = regimes_prob.copy()
    df = _normalize_datetime_index(df)
    df_reset = df.reset_index()
    x_col = df.index.name or "date"

    fig = px.area(
        df_reset,
        x=x_col,
        y=df.columns,
        title="Regime Probabilities Over Time",
    )
    st.plotly_chart(fig, use_container_width=True)

def _regimes_tools(regimes_prob: Optional[pd.DataFrame]) -> None:
    """×›×œ×™ ×¢×–×¨ ×œ×”×¡×ª×‘×¨×•×™×•×ª ××©×˜×¨×™×: ×”×•×¨×“×” ×•×¡×˜×˜×™×¡×˜×™×§×” ×§×¦×¨×”."""
    if regimes_prob is None or regimes_prob.empty:
        return

    st.caption(f"×“×’×™××•×ª: {len(regimes_prob):,}")
    c1, c2 = st.columns(2)
    with c1:
        st.download_button(
            label="â¬‡ï¸ ×”×•×¨×“ Regimes (CSV)",
            data=regimes_prob.to_csv(index=True).encode("utf-8"),
            file_name="macro_regimes_prob.csv",
            mime="text/csv",
            key=keygen(TAB_KEY, "reg", "dl_csv"),
        )
    with c2:
        cols_payload = {"columns": list(regimes_prob.columns)}
        st.download_button(
            label="â¬‡ï¸ ×”×•×¨×“ ×¨×©×™××ª ×¢××•×“×•×ª (JSON)",
            data=json.dumps(cols_payload, ensure_ascii=False, indent=2).encode("utf-8"),
            file_name="macro_regimes_columns.json",
            mime="application/json",
            key=keygen(TAB_KEY, "reg", "dl_cols"),
        )

    if get_flag("macro_show_regimes_table", True):
        show_tbl = st.toggle(
            "×”×¦×’ ×˜×‘×œ×ª Regimes (×ª×¦×•×’×”)",
            value=False,
            key=keygen(TAB_KEY, "reg", "show_tbl"),
        )
        if show_tbl:
            n = st.number_input(
                "×©×•×¨×•×ª ××—×¨×•× ×•×ª ×œ×ª×¦×•×’×”",
                min_value=50,
                max_value=2000,
                value=300,
                step=50,
                key=keygen(TAB_KEY, "reg", "nsample"),
            )
            st.dataframe(regimes_prob.tail(int(n)), use_container_width=True)


# ===========================
# Macro Features Heatmap
# ===========================


def _render_macro_heatmap(features_df: Optional[pd.DataFrame]) -> Optional[object]:
    """Heatmap ×œ×¤×™×¦'×¨×™ ×××§×¨×• (z-score) ×× ××¤×©×¨. ××—×–×™×¨ ××ª ×”-Figure ×× ×–××™×Ÿ."""
    if features_df is None or features_df.empty:
        st.info("××™×Ÿ ×¤×™×¦'×¨×™× ×œ×”×¦×’×”.")
        return None
    if not _HAS_PX:
        st.info("Plotly ×œ× ××•×ª×§×Ÿ â€” ×“×œ×’ ×¢×œ ×”×”×™×˜×××¤.")
        return None

    df = features_df.copy()
    df = _normalize_datetime_index(df)
    df = df.tail(200)

    fig = px.imshow(
        df.T,
        aspect="auto",
        origin="lower",
        labels=dict(x="×–××Ÿ", y="×¤×™×¦'×¨×™×", color="value"),
        title="Macro Features Heatmap (Tail 200)",
    )
    st.plotly_chart(fig, use_container_width=True)
    return fig


def _features_tools(
    features_df: Optional[pd.DataFrame],
    params: Optional[Dict[str, Any]] = None,
    fig: Optional[object] = None,
) -> None:
    """×›×œ×™ ×¢×–×¨ ×œ×¤×™×¦'×¨×™×: ×”×•×¨×“×•×ª, ×¢××•×“×•×ª, PNG ×œ×”×™×˜×××¤, ×•×ª×¦×•×’×ª ×˜×‘×œ×”."""
    if features_df is None or features_df.empty:
        return

    n_rows, n_cols = features_df.shape
    st.caption(
        f"×¡×”\"×› ×¤×™×¦'×¨×™×: {n_cols} ×¢××•×“×•×ª Ã— {n_rows} ×©×•×¨×•×ª "
        "(××•×¦×’×•×ª 200 ××—×¨×•× ×•×ª ×‘×”×™×˜×××¤).",
    )

    c1, c2, c3 = st.columns(3)
    with c1:
        st.download_button(
            label="â¬‡ï¸ ×”×•×¨×“ Features (CSV)",
            data=features_df.to_csv(index=True).encode("utf-8"),
            file_name="macro_features_summary.csv",
            mime="text/csv",
            key=keygen(TAB_KEY, "feat", "dl_csv"),
        )
    with c2:
        cols_payload = {"columns": list(features_df.columns)}
        st.download_button(
            label="â¬‡ï¸ ×”×•×¨×“ ×¨×©×™××ª ×¢××•×“×•×ª (JSON)",
            data=json.dumps(cols_payload, ensure_ascii=False, indent=2).encode("utf-8"),
            file_name="macro_features_columns.json",
            mime="application/json",
            key=keygen(TAB_KEY, "feat", "dl_cols"),
        )
    with c3:
        if fig is not None and pio is not None:
            export_png = st.toggle(
                "×™×™×¦× Heatmap ×›-PNG",
                value=False,
                key=keygen(TAB_KEY, "feat", "pngtg"),
            )
            if export_png:
                try:
                    png_bytes = pio.to_image(fig, format="png", scale=2)
                    st.download_button(
                        label="â¬‡ï¸ ×”×•×¨×“ Heatmap (PNG)",
                        data=png_bytes,
                        file_name="macro_features_heatmap.png",
                        mime="image/png",
                        key=keygen(TAB_KEY, "feat", "dl_png"),
                    )
                except Exception:
                    st.info("×›×“×™ ×œ×™×™×¦× PNG ×™×© ×œ×”×ª×§×™×Ÿ ××ª 'kaleido'.")

    show_tbl = st.toggle(
        "×”×¦×’ ×˜×‘×œ×ª Features (×ª×¦×•×’×”)",
        value=False,
        key=keygen(TAB_KEY, "feat", "show_tbl"),
    )
    if show_tbl:
        sample = st.number_input(
            "×©×•×¨×•×ª ××—×¨×•× ×•×ª ×œ×ª×¦×•×’×”",
            min_value=10,
            max_value=2000,
            value=200,
            step=10,
            key=keygen(TAB_KEY, "feat", "nsample"),
        )
        st.dataframe(features_df.tail(int(sample)), use_container_width=True)

    if params is not None and get_flag("macro_debug", False):
        with st.expander("ğŸ Feature Params (Debug)", expanded=False):
            st.json(params, expanded=False)


# ===========================
# Pair Macro Fit & Overlay Tables
# ===========================


def _render_pair_fit_table(profile: Optional[Dict[str, Any]]) -> None:
    """×˜×‘×œ×ª ×“×™×¨×•×’ ×–×•×’×™× ×œ×¤×™ Macro Fit (×× ×§×™×™× ×¤×¨×•×¤×™×œ)."""
    if not profile:
        st.info("×˜×¨× ×—×•×©×‘ Macro Profile â€” ×œ×—×¥ '×—×©×‘ Macro Profile'.")
        return

    rows: List[Dict[str, Any]] = []
    for pid, row in profile.items():
        rows.append(
            {
                "pair_id": pid,
                "macro_fit_score": row.get("macro_fit_score"),
                "weight_adj": row.get("weight_adj"),
                "action": row.get("action"),
                "reason": row.get("reason"),
            },
        )

    if not rows:
        st.info("××™×Ÿ × ×ª×•× ×™× ×œ×”×¦×’×” ×‘-Macro Profile.")
        return

    df = pd.DataFrame(rows).sort_values(
        ["macro_fit_score"],
        ascending=False,
        na_position="last",
    )
    st.dataframe(df.head(50), use_container_width=True)


def _render_overlay_table(profile: Optional[Dict[str, Any]]) -> None:
    """×˜×‘×œ×ª Overlay ××œ××”: include / caps / weight_adj / score / action."""
    if not profile:
        st.info("××™×Ÿ Overlay ×œ×”×¦×’×”. ×œ×—×¥ '×—×©×‘ Macro Profile'.")
        return

    rows: List[Dict[str, Any]] = []
    for pid, row in profile.items():
        rows.append(
            {
                "pair_id": pid,
                "include": row.get("include", True),
                "weight_adj": row.get("weight_adj"),
                "macro_fit_score": row.get("macro_fit_score"),
                "cap_applied": row.get("cap_applied", False),
                "cap_value": row.get("cap_value"),
                "action": row.get("action"),
            },
        )

    df = pd.DataFrame(rows).sort_values(
        ["include", "macro_fit_score"],
        ascending=[False, False],
        na_position="last",
    )
    st.dataframe(df, use_container_width=True)


def _overlay_downloads(profile: Optional[Dict[str, Any]]) -> None:
    """×›×¤×ª×•×¨×™ ×”×•×¨×“×” ×œ-Overlay (JSON/CSV) ×× ×§×™×™×."""
    if not isinstance(profile, dict) or not profile:
        return

    st.download_button(
        label="â¬‡ï¸ ×”×•×¨×“ Overlay (JSON)",
        data=json.dumps(profile, ensure_ascii=False, indent=2).encode("utf-8"),
        file_name="macro_overlay.json",
        mime="application/json",
        key=keygen(TAB_KEY, "overlay", "json"),
    )
    df = pd.DataFrame(
        [
            {"pair_id": k, **(v or {})}
            for k, v in profile.items()
        ],
    )
    st.download_button(
        label="â¬‡ï¸ ×”×•×¨×“ Overlay (CSV)",
        data=df.to_csv(index=False).encode("utf-8"),
        file_name="macro_overlay.csv",
        mime="text/csv",
        key=keygen(TAB_KEY, "overlay", "csv"),
    )


# ===========================
# Macro Shocks Section
# ===========================


def _render_macro_shocks_section(state: MacroTabState) -> None:
    """××—×©×‘ ×•××¦×™×’ Macro Shocks (×× ×”×¤×•× ×§×¦×™×” ×–××™× ×”)."""
    st.subheader("âš¡ Macro Shocks")

    macro_df = state.macro_df or state_get(MacroStateKeys.MACRO_DF)
    if macro_df is None or not isinstance(macro_df, pd.DataFrame) or macro_df.empty:
        st.info("××™×Ÿ macro_df ×–××™×Ÿ ×œ×—×™×©×•×‘ ×©×•×§×™×.")
        return

    shocks_df: Optional[pd.DataFrame] = None
    try:
        shocks_df = detect_macro_shocks(macro_df)  # type: ignore[call-arg]
    except TypeError:
        # ×™×™×ª×›×Ÿ ×©×”×¤×•× ×§×¦×™×” ×“×•×¨×©×ª ×¤×¨××˜×¨×™× × ×•×¡×¤×™× â€” ×‘××§×¨×” ×›×–×” ×”××©×ª××© ×™×¢×“×›×Ÿ ×‘××•×“×•×œ ×”×××§×¨×•.
        LOGGER.debug("detect_macro_shocks signature mismatch (TypeError)", exc_info=True)
    except Exception as e:  # noqa: BLE001
        LOGGER.debug("detect_macro_shocks failed (non-fatal): %s", e)
        shocks_df = None

    if shocks_df is None or shocks_df.empty:
        st.info("×œ× ×–×•×”×• ×©×•×§×™× ××©××¢×•×ª×™×™× ×‘×¤×§×˜×•×¨×™ ×”×××§×¨×• (××• ×©×”×¤×•× ×§×¦×™×” ××—×–×™×¨×” ×¨×™×§).")
        return

    shocks_df = _normalize_datetime_index(shocks_df)
    state.macro_shocks_df = shocks_df
    state_set(MacroStateKeys.SHOCKS_DF, shocks_df)

    st.caption(f"××¡×¤×¨ ×©×•×§×™× ××–×•×”×™×: {len(shocks_df):,}")
    st.dataframe(shocks_df.tail(50), use_container_width=True)

    st.download_button(
        label="â¬‡ï¸ ×”×•×¨×“ Macro Shocks (CSV)",
        data=shocks_df.to_csv(index=True).encode("utf-8"),
        file_name="macro_shocks.csv",
        mime="text/csv",
        key=keygen(TAB_KEY, "shocks", "dl"),
    )


# ===========================
# Pair Macro DNA (×¨×’×™×©×•×ª ×œ×–×•×’ × ×‘×—×¨)
# ===========================


def _infer_pair_symbols(row: pd.Series) -> Optional[Tuple[str, str]]:
    """×× ×¡×” ×œ×”×¡×™×§ ××ª ×¡×™××‘×•×œ×™ ×”×–×•×’ (A/B) ××ª×•×š ×©×“×”×™ pairs_df ×©×•× ×™×."""
    candidates = [
        ("sym_a", "sym_b"),
        ("sym_x", "sym_y"),
        ("a", "b"),
        ("leg_a", "leg_b"),
    ]
    for c1, c2 in candidates:
        if c1 in row.index and c2 in row.index:
            sym1 = str(row[c1])
            sym2 = str(row[c2])
            if sym1 and sym2:
                return sym1, sym2
    return None


def _build_spread_series(
    pair_row: pd.Series,
    prices_wide: pd.DataFrame,
    method: str,
) -> Optional[pd.Series]:
    """×‘×•× ×” ×¡×“×¨×ª spread ×œ×–×•×’ ×œ×¤×™ ×©×™×˜×ª ×”×—×™×©×•×‘ ×©× ×‘×—×¨×”."""
    syms = _infer_pair_symbols(pair_row)
    if syms is None:
        return None

    a, b = syms
    if a not in prices_wide.columns or b not in prices_wide.columns:
        return None

    pa = prices_wide[a].astype(float)
    pb = prices_wide[b].astype(float)
    if method == "log_spread":
        spread = (pa.apply(lambda x: float("nan") if x <= 0 else x)).pipe(lambda s: s.apply(pd.np.log)) - (
            pb.apply(lambda x: float("nan") if x <= 0 else x)
        ).pipe(lambda s: s.apply(pd.np.log))
    elif method == "ratio":
        spread = pa / pb
    else:  # diff
        spread = pa - pb

    spread = spread.dropna()
    spread.name = f"{a}_{b}_{method}"
    return spread


def _render_pair_macro_dna_section(state: MacroTabState, pairs_df: pd.DataFrame) -> None:
    """××¦×™×’ ××ª ×¨×’×™×©×•×ª ×”×××§×¨×• ('DNA ×××§×¨×•') ×œ×–×•×’ × ×‘×—×¨."""
    st.subheader("ğŸ§¬ DNA ×××§×¨×• ×œ×–×•×’ × ×‘×—×¨")

    if pairs_df is None or pairs_df.empty:
        st.info("××™×Ÿ pairs_df ×–××™×Ÿ â€” ×œ× × ×™×ª×Ÿ ×œ×—×©×‘ DNA ×œ×–×•×’.")
        return

    # ×‘×—×™×¨×ª ×–×•×’
    pair_ids = list(pairs_df["pair_id"].astype(str).unique()) if "pair_id" in pairs_df.columns else []
    if not pair_ids:
        st.info("×œ× × ××¦××” ×¢××•×“×ª pair_id ×‘-pairs_df.")
        return

    selected_pair = st.selectbox(
        "×‘×—×¨ ×–×•×’ ×œ× ×™×ª×•×— ×××§×¨×•",
        options=pair_ids,
        index=0,
        key=keygen(TAB_KEY, "dna", "pair"),
    )

    spread_method = st.selectbox(
        "×©×™×˜×ª ×¡×¤×¨×“",
        options=["log_spread", "diff", "ratio"],
        index=0,
        key=keygen(TAB_KEY, "dna", "method"),
    )

    run_dna = st.button(
        "×—×©×‘ DNA ×××§×¨×• ×œ×–×•×’",
        key=keygen(TAB_KEY, "dna", "run"),
    )

    if not run_dna:
        st.caption("×‘×—×¨ ×–×•×’ ×•×œ×—×¥ ×¢×œ '×—×©×‘ DNA ×××§×¨×• ×œ×–×•×’' ×›×“×™ ×œ×§×‘×œ ×¨×’×™×©×•×ª ××¤×•×¨×˜×ª.")
        return

    prices_wide = state_get("prices_wide")
    if not isinstance(prices_wide, pd.DataFrame) or prices_wide.empty:
        st.error("prices_wide ×œ× ×–××™×Ÿ ×‘-session_state â€” ×”×˜××‘ ×”×××§×¨×• ×¦×¨×™×š ×’×™×©×” ×œ××—×™×¨×™ ×”×–×•×’×•×ª.")
        return

    try:
        idx = pairs_df["pair_id"].astype(str) == str(selected_pair)
        row = pairs_df.loc[idx].iloc[0]
    except Exception:  # noqa: BLE001
        st.error("×œ× ×”×¦×œ×—×ª×™ ×œ××¦×•× ××ª ×”×–×•×’ ×”××ª××™× ×‘-pairs_df.")
        return

    spread = _build_spread_series(row, prices_wide, spread_method)
    if spread is None or spread.empty:
        st.error("×œ× ×”×¦×œ×—×ª×™ ×œ×‘× ×•×ª ×¡×“×¨×ª spread ×œ×–×•×’ (×‘×“×•×§ ×¢××•×“×•×ª ×¡×™××‘×•×œ×™× ×•-prices_wide).")
        return

    macro_df = state.macro_df or state_get(MacroStateKeys.MACRO_DF)
    if macro_df is None or not isinstance(macro_df, pd.DataFrame) or macro_df.empty:
        st.error("macro_df ×œ× ×–××™×Ÿ â€” ×œ× × ×™×ª×Ÿ ×œ×—×©×‘ ×¨×’×™×©×•×ª ×××§×¨×• ×œ×–×•×’.")
        return

    try:
        regime_df = build_macro_regime_series(macro_df)  # type: ignore[call-arg]
    except Exception as e:  # noqa: BLE001
        LOGGER.debug("build_macro_regime_series failed: %s", e)
        st.error("×›×©×œ ×‘×‘× ×™×™×ª Regime DF â€” ×œ× × ×™×ª×Ÿ ×œ×”×©×œ×™× ××ª × ×™×ª×•×— ×”-DNA.")
        return

    try:
        cfg_sens = state.pair_sens_cfg
        if cfg_sens is not None:
            sens = compute_pair_macro_sensitivity(
                spread_series=spread,
                macro_df=macro_df,
                regime_df=regime_df,
                cfg=cfg_sens,  # type: ignore[arg-type]
            )
        else:
            sens = compute_pair_macro_sensitivity(
                spread_series=spread,
                macro_df=macro_df,
                regime_df=regime_df,
            )
    except TypeError:
        # ×—×ª×™××ª ×¤×•× ×§×¦×™×” ×©×•× ×” â€” × × ×¡×” ×§×¨×™××” ×¤×©×•×˜×”
        sens = compute_pair_macro_sensitivity(spread, macro_df, regime_df)  # type: ignore[call-arg]
    except Exception as e:  # noqa: BLE001
        LOGGER.exception("compute_pair_macro_sensitivity failed: %s", e)
        st.error("×›×©×œ ×‘×—×™×©×•×‘ DNA ×××§×¨×• ×œ×–×•×’ â€” ×‘×“×•×§ ××ª ××•×“×•×œ ×”××§×¨×•.")
        return

    # ×”×¦×’×”
    summary_text = getattr(sens, "summary_text", "")
    overall_score = getattr(sens, "overall_score", None)

    top_cols = st.columns(2)
    with top_cols[0]:
        st.markdown(f"**×–×•×’:** `{selected_pair}` â€” ×©×™×˜×ª Spread: `{spread_method}`")
        if summary_text:
            st.markdown(f"**×¡×™×›×•× ××™×›×•×ª×™:** {summary_text}")
    with top_cols[1]:
        if overall_score is not None:
            try:
                score_f = float(overall_score)
                st.metric("Overall Macro Sensitivity Score", f"{score_f:.1f}/100")
            except Exception:  # noqa: BLE001
                pass

    # ×˜×‘×œ×ª exposures
    exposures = getattr(sens, "exposures", None)
    if exposures:
        try:
            exp_df = build_exposures_table(exposures)  # type: ignore[call-arg]
        except Exception:
            # × × ×¡×” ×œ×‘× ×•×ª ×™×“× ×™×ª
            rows: List[Dict[str, Any]] = []
            for fac, obj in exposures.items():
                rows.append(
                    {
                        "factor": fac,
                        "beta": getattr(obj, "beta", None),
                        "tstat": getattr(obj, "tstat", None),
                        "pvalue": getattr(obj, "pvalue", None),
                    },
                )
            exp_df = pd.DataFrame(rows)
        st.markdown("**×¨×’×™×©×•×ª ×œ×¤×§×˜×•×¨×™ ×××§×¨×• (Betas / t-stat / p-value):**")
        st.dataframe(exp_df, use_container_width=True)
    else:
        st.info("×œ× × ××¦××” ×˜×‘×œ×ª exposures ×‘-PairMacroSensitivity.")

    # ×˜×‘×œ×ª ×‘×™×¦×•×¢×™× ×œ×¤×™ ××©×˜×¨×™×
    regime_perf = getattr(sens, "regime_perf", None)
    if regime_perf:
        try:
            reg_df = build_regime_performance_table(regime_perf)  # type: ignore[call-arg]
        except Exception:
            rows = []
            for rkey, obj in regime_perf.items():
                rows.append(
                    {
                        "regime_key": rkey,
                        "label": getattr(obj, "label", rkey),
                        "n_obs": getattr(obj, "n_obs", None),
                        "mean": getattr(obj, "mean", None),
                        "vol": getattr(obj, "vol", None),
                        "sharpe": getattr(obj, "sharpe", None),
                        "hit_ratio": getattr(obj, "hit_ratio", None),
                    },
                )
            reg_df = pd.DataFrame(rows)
        st.markdown("**×‘×™×¦×•×¢×™× ×œ×¤×™ ××©×˜×¨×™× (mean/vol/sharpe/hit_ratio):**")
        st.dataframe(reg_df, use_container_width=True)
    else:
        st.info("×œ× × ××¦××” ×˜×‘×œ×ª ×‘×™×¦×•×¢×™× ×œ×¤×™ ××©×˜×¨ ×‘-PairMacroSensitivity.")

    # ×”×•×¨×“×” ×›-JSON
    try:
        if hasattr(sens, "to_dict"):
            payload = sens.to_dict()  # type: ignore[call-arg]
        else:
            payload = {
                "overall_score": overall_score,
                "summary_text": summary_text,
                "exposures": getattr(sens, "exposures", {}),
                "regime_perf": getattr(sens, "regime_perf", {}),
            }
        st.download_button(
            label="â¬‡ï¸ ×”×•×¨×“ Pair Macro DNA (JSON)",
            data=json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8"),
            file_name=f"pair_macro_dna_{selected_pair}.json",
            mime="application/json",
            key=keygen(TAB_KEY, "dna", "dl"),
        )
    except Exception:  # noqa: BLE001
        pass
# ---------------------------------------------------------------------------
# Orchestration â€” ×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª render()
# ---------------------------------------------------------------------------


def _sync_cfg_with_ui(
    cfg: MacroConfig,
    ui_cfg: Dict[str, Any],
    risk_cfg: Dict[str, Any],
) -> MacroConfig:
    """××¢×‘×™×¨ ×¢×¨×›×™ UI ××œ MacroConfig (score thresholds, caps, risk, sources, IBKR)."""
    try:
        # ×¡×¤×™ Macro Fit
        cfg.score_filter_threshold = float(
            ui_cfg.get("score_filter_threshold", getattr(cfg, "score_filter_threshold", 30.0)),
        )
        cfg.score_gain_floor = float(
            ui_cfg.get("score_gain_floor", getattr(cfg, "score_gain_floor", 60.0)),
        )
        cfg.score_weight_gain = float(
            ui_cfg.get("score_weight_gain", getattr(cfg, "score_weight_gain", 0.15)),
        )
        cfg.caps_mode = str(ui_cfg.get("caps_mode", getattr(cfg, "caps_mode", "hint")))

        # Risk sizing / covariance
        try:
            cfg.risk_sizing = str(
                risk_cfg.get("risk_sizing", getattr(cfg, "risk_sizing", "invvol")),
            )  # type: ignore[attr-defined]
            cfg.cov_window = int(
                risk_cfg.get("cov_window", getattr(cfg, "cov_window", 60)),
            )  # type: ignore[attr-defined]
            cfg.cov_shrink = float(
                risk_cfg.get("cov_shrink", getattr(cfg, "cov_shrink", 0.1)),
            )  # type: ignore[attr-defined]
        except Exception:  # noqa: BLE001
            LOGGER.debug("risk sizing sync skipped", exc_info=True)

        # Caps ×œ×¤×™ ×¡×§×˜×•×¨/××–×•×¨/××˜×‘×¢
        sc = risk_cfg.get("sector_caps_dict", {}) or {}
        rc = risk_cfg.get("region_caps_dict", {}) or {}
        cc = risk_cfg.get("currency_caps_dict", {}) or {}
        try:
            if sc:
                cfg.sector_caps = dict(sc)  # type: ignore[attr-defined]
            if rc:
                cfg.region_caps = dict(rc)  # type: ignore[attr-defined]
            if cc:
                cfg.currency_caps = dict(cc)  # type: ignore[attr-defined]
        except Exception:  # noqa: BLE001
            LOGGER.debug("caps sync skipped", exc_info=True)

        # IBKR auto-live
        token_val = state_get(keygen(TAB_KEY, "ibkr", "token"))
        base_val = state_get(
            keygen(TAB_KEY, "ibkr", "base"),
            "https://localhost:5000",
        )
        auto_live_flag = bool(state_get(keygen(TAB_KEY, "ibkr", "auto_live_flag"), True))
        if token_val and auto_live_flag:
            cfg.use_data_client = True
            cfg.data_client_live = True
            cfg.data_client_allow_ibkr = True  # type: ignore[attr-defined]
            cfg.ibkr_token = token_val  # type: ignore[attr-defined]
            cfg.ibkr_base_url = base_val  # type: ignore[attr-defined]

        # ××§×•×¨×•×ª ×©× ×•×¡×¤×• ××ª×•×š ×”×˜××‘
        overrides = state_get("macro_sources_overrides", {})
        if isinstance(overrides, dict) and overrides:
            try:
                if not hasattr(cfg, "sources") or getattr(cfg, "sources") is None:
                    cfg.sources = {}  # type: ignore[attr-defined]
                cfg.sources.update({str(k): str(v) for k, v in overrides.items()})  # type: ignore[attr-defined]
            except Exception:  # noqa: BLE001
                LOGGER.debug("cfg.sources sync failed", exc_info=True)
    except Exception:  # noqa: BLE001
        LOGGER.debug("cfg sync skipped", exc_info=True)

    return cfg


def render(
    pairs_df: Optional[pd.DataFrame] = None,
    cfg: Optional[MacroConfig] = None,
    bundle: Optional[MacroBundle] = None,
) -> AdjustmentResult:
    """×××©×§ ×”×§×¨×™××” ×œ×“×©×‘×•×¨×“. ××—×–×™×¨ AdjustmentResult ×œ×©××¨ ×”××¢×¨×›×ª.

    Parameters
    ----------
    pairs_df : Optional[pd.DataFrame]
        ×˜×‘×œ×ª ×”×–×•×’×•×ª ×©×œ ×”××¢×¨×›×ª. ×× ×¨×™×§×”, ×™×•×¦×’ UI ×œ×œ× × ×ª×•× ×™×, ××š ×¢×“×™×™×Ÿ × ×™×ª×Ÿ
        ×œ×¨××•×ª Snapshot, Regimes, Shocks ×•×›×•'.
    cfg : Optional[MacroConfig]
        ××•×‘×™×™×§×˜ ×§×•× ×¤×™×’×•×¨×¦×™×” ×œ×”×ª×××•×ª ×××§×¨×•. ×× None, ×™×™×•×•×¦×¨ ×—×“×© ×¢× ×‘×¨×™×¨×•×ª ××—×“×œ
        (××• ×™×™×˜×¢×Ÿ ××”-session_state ×× ×§×™×™×).
    bundle : Optional[MacroBundle]
        ×—×‘×™×œ×ª × ×ª×•× ×™ ×××§×¨×• ×˜×¢×•× ×” ××¨××©. ×× None, ×ª×™×˜×¢×Ÿ ×œ×¤×™ cfg ×“×¨×š load_macro_bundle.

    Returns
    -------
    AdjustmentResult
        ×ª×•×¦××ª ×”×ª×××•×ª ×”×××§×¨×• (exposure_multiplier / pair_adjustments / filters / ...).
    """

    # --- Macro context & panels ××”-router / dashboard ----------------------
    macro_ctx_from_nav = state_get("macro_ctx_from_nav", {}) or {}
    if not isinstance(macro_ctx_from_nav, Mapping):
        macro_ctx_from_nav = {}

    macro_panels_flags = _get_macro_panels_flags()
    read_only_flag = bool(state_get("macro_read_only", False))

    risk_profile_from_macro = (
        state_get("risk_profile_from_macro", None)
        or macro_ctx_from_nav.get("risk_mode")
    )
    macro_preset_selected = (
        state_get("macro_preset_selected", None)
        or macro_ctx_from_nav.get("macro_preset")
    )

    # focus_pair_id ×œ-DNA (×”-router ×›×‘×¨ ××›× ×™×¡ ×œ-key ×”××ª××™×)
    focus_pair_id = state_get(keygen(TAB_KEY, "dna", "pair"), None)

    # ×¤×•× ×§×¦×™×” ×§×˜× ×” ×©× ×•×ª× ×ª flag ×œ×›×œ ×¡×§×©×Ÿ ×œ×¤×™ macro_panels_flags
    def _panel_flag(name: str, default: bool = True) -> bool:
        if not macro_panels_flags:
            return default
        try:
            return bool(macro_panels_flags.get(name, default))
        except Exception:  # noqa: BLE001
            return default

    # ××” ×œ×”×¦×™×’ ×‘×¤×•×¢×œ (××¤×©×¨ ×œ×›×•×•×Ÿ ××”-dashboard ×“×¨×š macro_panels)
    show_regimes_section = _panel_flag("regimes", True)
    show_features_section = _panel_flag("macro_surprises", True)
    show_overlay_section = _panel_flag("fair_value", True)
    show_shocks_section = _panel_flag("liquidity", True)
    show_dna_section = True  # ×›×¨×’×¢ ×ª××™×“ ××¦×™×’×™× DNA; ××¤×©×¨ ×œ×§×©×•×¨ ×œ×¤×× ×œ ×× ×ª×¨×¦×”
    show_profile_section = not read_only_flag
    show_backtest_section = not read_only_flag

    # × ×©××•×¨ ×§×¦×ª info ×œ-debug (×œ× ×—×•×‘×”)
    try:
        LOGGER.debug(
            "macro_tab.render | read_only=%s, risk_profile_from_macro=%s, "
            "preset=%s, focus_pair_id=%s, panels=%s",
            read_only_flag,
            risk_profile_from_macro,
            macro_preset_selected,
            focus_pair_id,
            list(macro_panels_flags.keys()),
        )
    except Exception:  # noqa: BLE001
        pass

    # --- ×‘×¡×™×¡: pairs_df + ×•×œ×™×“×¦×™×” -----------------------------------------
    pairs_df = _ensure_pairs_df(pairs_df)
    _render_pairs_warnings(pairs_df)

    # --- Feature Flags + Workspace + Presets + IBKR + Feature Params + Risk + Regime Model + Sidebar ---
    feature_toggles_ui(TAB_KEY)
    preset_ui_controls(TAB_KEY)

    workspace = _workspace_sidebar(TAB_KEY)

    # ××ª×—×•×œ ×§×•× ×¤×™×’×™× (MacroConfig + FactorConfig + SensitivityConfig)
    cfg, factor_cfg, pair_sens_cfg = _init_macro_configs(cfg, None, None)

    # IBKR + ××§×•×¨×•×ª live
    _macro_ibkr_portal_ui(TAB_KEY)

    # Feature engineering ×¢×œ ×¤×§×˜×•×¨×™ ×××§×¨×•
    feature_params = _feature_params_ui(TAB_KEY)

    # ×©×›×‘×ª ×¡×™×›×•×Ÿ (sizing & caps)
    risk_cfg = _macro_risk_controls_ui(TAB_KEY)

    # ××•×“×œ ××©×˜×¨×™× (HMM/KMeans/XGB)
    regime_model_cfg = _macro_regime_model_ui(TAB_KEY)

    # Sidebar ××¨×›×–×™ â€“ ×¤×¨××˜×¨×™ MacroConfig
    ui_cfg = _render_sidebar(TAB_KEY)

    # ×¡× ×›×¨×•×Ÿ ×”×¤×¨××˜×¨×™× ××œ cfg
    cfg = _sync_cfg_with_ui(cfg, ui_cfg, risk_cfg)

    # --- ×™×¦×™×¨×ª State ×•×˜×¢× ×ª ×“××˜×” ×××§×¨×• -------------------------------------
    state = MacroTabState(
        workspace=workspace,
        macro_cfg=cfg,
        factor_cfg=factor_cfg,
        pair_sens_cfg=pair_sens_cfg,
        bundle=bundle,
    )

    # × ×¢×‘×™×¨ ×œ×ª×•×š state ×’× ××” ×©×›×‘×¨ ×§×™×™× ×‘-session (×œ××©×›×™×•×ª ×‘×™×Ÿ ×¨×™×¦×•×ª)
    state.macro_profile = state_get(MacroStateKeys.PROFILE, None)
    state.macro_regimes_prob = state_get(MacroStateKeys.REGIMES_PROB, None)
    state.macro_features_df = state_get(MacroStateKeys.FEATURES_DF, None)
    state.macro_shocks_df = state_get(MacroStateKeys.SHOCKS_DF, None)

    state = _load_macro_data_for_workspace(state, pairs_df=pairs_df)

    # --- ×©×›×‘×ª Snapshot ×¢×œ ×”×××§×¨×• ------------------------------------------
    _render_macro_snapshot_section(state)

    # --- ×—×™×©×•×‘ ×”×ª×××•×ª ×××§×¨×• ×œ×ª×™×§ (AdjustmentResult) -----------------------
    session_uid = get_session_uid()
    key = keygen(TAB_KEY, session_uid)

    if state.bundle is None:
        # ×× ××¡×™×‘×” ×›×œ×©×”×™ bundle ×¢×“×™×™×Ÿ None, × × ×¡×” ×©×•×‘ ×œ×˜×¢×•×Ÿ
        try:
            state.bundle = load_macro_bundle(cfg)
            state_set(MacroStateKeys.BUNDLE, state.bundle)
        except Exception as e:  # noqa: BLE001
            LOGGER.error("×˜×¢×™× ×ª MacroBundle × ×›×©×œ×” ×¤×¢× ×©× ×™×™×”: %s", e)

    try:
        with st.spinner("××—×©×‘ ×”×ª×××•×ª ×××§×¨×• ×œ×ª×™×§â€¦"):
            # ×ª××™××•×ª ××œ××” ×œ×× ×•×¢ ×”×™×©×Ÿ: render_streamlit_ui ×¢×•×©×” ××ª ×›×œ ×”×¢×‘×•×“×” ×”×›×‘×“×”
            result = render_streamlit_ui(
                pairs_df=pairs_df,
                cfg=cfg,
                bundle=state.bundle,
                key=key,
            )
    except Exception as e:  # noqa: BLE001
        LOGGER.exception("×©×’×™××” ×‘×ª×•×š render_streamlit_ui: %s", e)
        st.error("âŒ ×©×’×™××” ×‘×”×¦×’×ª ×˜××‘ ×”×××§×¨×•. ××•×¦×’ ××¦×‘ × ×™×™×˜×¨×œ×™.")
        # ××¦×‘ × ×™×˜×¨×œ×™ ×›×ª×•×¦××” ×—×œ×•×¤×™×ª ×× ×”-UI ×§×¨×¡
        result = AdjustmentResult(
            exposure_multiplier=1.0,
            pair_adjustments={},
            filters={},
            regime_snapshot=None,
        )

    # ×©××™×¨×ª ×”×ª×•×¦××” ×‘-session_state ×•×‘-state
    state.adjustment_result = result
    state_set(MacroStateKeys.RESULT, result)
    st.session_state["macro_tab_result"] = result  # ×ª××™××•×ª ×œ×©× ×”×™×©×Ÿ
    st.session_state["macro_adjustments_result"] = result

    # Meta + KPIs
    _stamp_result(result, cfg)
    meta = state_get(MacroStateKeys.META, {})
    _render_top_kpis(meta)
    _render_risk_profile_banner()

    # ğŸ”„ ×“×—×™×¤×ª ××“×“×™ Macro + Risk ×œ-Analysis / Tab Comparison
    try:
        # ×××§×¨×• (×¨×’×™×©×•×ª ×’×œ×•×‘×œ×™×ª + mean_score)
        mean_score = _safe_float_or_none(meta.get("mean_score"))
        regime_label = str(meta.get("regime_label", "") or "")

        regime_map = {
            "risk_off": 0.1,
            "stagflation": 0.2,
            "slowdown": 0.3,
            "neutral": 0.5,
            "reflation": 0.7,
            "risk_on": 0.9,
        }
        macro_sensitivity = regime_map.get(regime_label, 0.5)
        macro_score = mean_score if mean_score is not None else 50.0

        push_macro_metrics_to_ctx(
            macro_sensitivity=macro_sensitivity,
            macro_score=macro_score,
        )

        # Risk metrics ×’×œ×•×‘×œ×™×™×
        push_risk_metrics_to_ctx(result, meta)
    except Exception:
        LOGGER.debug("push_macro/risk metrics to ctx failed (non-fatal)", exc_info=True)

    _render_live_health(cfg)

    # ----------------------------------------------------------------------
    # Backtest / Profile â€” ×§×‘×¦×™×, ×›×¤×ª×•×¨×™× ×•×ª×•×¦××•×ª
    # ----------------------------------------------------------------------
    if show_backtest_section:
        with st.expander("Backtest â€” ×˜×¢×Ÿ ×§×‘×¦×™×", expanded=False):
            ret_file = st.file_uploader(
                "Returns (CSV/Parquet)",
                type=["csv", "parquet"],
                key=keygen(TAB_KEY, "upl", "returns"),
            )
            pairs_file_bt = st.file_uploader(
                "Pairs Universe (CSV/Parquet)",
                type=["csv", "parquet"],
                key=keygen(TAB_KEY, "upl", "pairs"),
            )
    else:
        ret_file = None
        pairs_file_bt = None

    cols_actions = st.columns(3)
    with cols_actions[0]:
        if show_profile_section:
            run_profile = st.button(
                "×—×©×‘ Macro Profile",
                key=keygen(TAB_KEY, "act", "compute"),
            )
        else:
            st.button(
                "×—×©×‘ Macro Profile",
                key=keygen(TAB_KEY, "act", "compute_disabled"),
                disabled=True,
            )
            run_profile = False
    with cols_actions[1]:
        if show_backtest_section:
            run_bt = st.button(
                "Backtest",
                key=keygen(TAB_KEY, "act", "bt"),
            )
        else:
            st.button(
                "Backtest",
                key=keygen(TAB_KEY, "act", "bt_disabled"),
                disabled=True,
            )
            run_bt = False
    with cols_actions[2]:
        if read_only_flag:
            st.caption("××¦×‘ Read-only: ×—×™×©×•×‘×™× ×›×‘×“×™× (Profile/Backtest) × ×¢×•×œ×™× ××”×“×©×‘×•×¨×“.")
        else:
            st.write("")

    # --- Macro Profile ----------------------------------------------------
    if run_profile:
        try:
            from core.macro_engine import compute_profile  # type: ignore

            cfg_for_profile: Dict[str, Any] = dict(ui_cfg)
            cfg_for_profile["feature_params"] = dict(feature_params or {})

            if regime_model_cfg.get("mode") != "none":
                cfg_for_profile["regime_model"] = dict(regime_model_cfg)

            prof = compute_profile(pairs_df=pairs_df, cfg=cfg_for_profile)
            profile = getattr(prof, "profile", getattr(prof, "profile", {}))
            regimes_prob = getattr(prof, "regimes_prob", None)
            features_df = getattr(prof, "features_summary", None)

            state.macro_profile = profile
            state.macro_regimes_prob = regimes_prob
            state.macro_features_df = features_df

            state_set(MacroStateKeys.PROFILE, profile)
            state_set(MacroStateKeys.REGIMES_PROB, regimes_prob)
            state_set(MacroStateKeys.FEATURES_DF, features_df)
            st.success("Macro Profile ×—×•×©×‘ ×‘×”×¦×œ×—×”.")
        except Exception as e:  # noqa: BLE001
            LOGGER.exception("compute_profile failure: %s", e)
            st.error("×›×©×œ ×‘×—×™×©×•×‘ Macro Profile â€” ×•×“× ×©×§×‘×¦×™ core ×§×™×™××™×.")

    # --- Backtest ---------------------------------------------------------
    if run_bt:
        try:
            from core.macro_engine import (  # type: ignore
                backtest as macro_backtest,
                run_backtest_with_files,
            )

            with st.spinner("××¨×™×¥ Backtest ×××§×¨×•â€¦"):
                if ret_file is not None:
                    cfg_bt: Dict[str, Any] = dict(ui_cfg)
                    cfg_bt["feature_params"] = dict(feature_params or {})
                    if regime_model_cfg.get("mode") != "none":
                        cfg_bt["regime_model"] = dict(regime_model_cfg)
                    # ×”×× ×•×¢ ×‘×“"×› ××¦×¤×” ×œ-max_pair_weight ×‘×¤×•×¨××˜ fraction ×•×œ× ××—×•×–
                    if isinstance(cfg_bt.get("max_pair_weight"), (int, float)):
                        cfg_bt["max_pair_weight"] = float(cfg_bt["max_pair_weight"]) / 100.0

                    res_bt = run_backtest_with_files(
                        returns_obj=ret_file.getvalue(),
                        returns_name=str(ret_file.name),
                        pairs_obj=(
                            pairs_file_bt.getvalue()
                            if pairs_file_bt is not None
                            else None
                        ),
                        pairs_name=(
                            str(pairs_file_bt.name)
                            if pairs_file_bt is not None
                            else None
                        ),
                        cfg=cfg_bt,
                    )
                else:
                    res_bt = macro_backtest(cfg=dict(ui_cfg))

            st.success("Backtest ×”×•×©×œ×")
            c1, c2, c3, c4, c5 = st.columns(5)
            c1.metric("Sharpe", f"{getattr(res_bt, 'sharpe', 0.0):.2f}")
            c2.metric("Sortino", f"{getattr(res_bt, 'sortino', 0.0):.2f}")
            c3.metric("CAGR", f"{getattr(res_bt, 'cagr', 0.0):.2%}")
            c4.metric("Max DD", f"{getattr(res_bt, 'max_dd', 0.0):.2%}")
            c5.metric("Uplift vs EW", f"{getattr(res_bt, 'uplift_vs_base', 0.0):.2%}")

            bt_payload = {
                "sharpe": float(getattr(res_bt, "sharpe", 0.0)),
                "sortino": float(getattr(res_bt, "sortino", 0.0)),
                "cagr": float(getattr(res_bt, "cagr", 0.0)),
                "max_dd": float(getattr(res_bt, "max_dd", 0.0)),
                "uplift_vs_base": float(getattr(res_bt, "uplift_vs_base", 0.0)),
            }
            json_bytes = json.dumps(
                bt_payload,
                ensure_ascii=False,
                indent=2,
            ).encode("utf-8")
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ Backtest (JSON)",
                data=json_bytes,
                file_name="macro_backtest_result.json",
                mime="application/json",
                key=keygen(TAB_KEY, "bt", "dl_json"),
            )
            bt_df = pd.DataFrame([bt_payload])
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ Backtest (CSV)",
                data=bt_df.to_csv(index=False).encode("utf-8"),
                file_name="macro_backtest_result.csv",
                mime="text/csv",
                key=keygen(TAB_KEY, "bt", "dl_csv"),
            )
        except Exception as e:  # noqa: BLE001
            LOGGER.exception("macro backtest failure: %s", e)
            st.error("×›×©×œ ×‘×”×¨×¦×ª Backtest â€” ×•×“× ×©×§×‘×¦×™ core ×§×™×™××™×.")

    # ----------------------------------------------------------------------
    # Visuals & Analytics â€” Regimes, Features, Overlay, Shocks, DNA
    # ----------------------------------------------------------------------
    if show_regimes_section:
        st.subheader("×¦×™×¨ ×–××Ÿ ××©×˜×¨×™×")
        rp = state.macro_regimes_prob or state_get(MacroStateKeys.REGIMES_PROB)
        _render_regime_timeline(rp)
        _regimes_tools(rp)
    else:
        rp = None  # ×œ×™×ª×¨ ×‘×™×˜×—×•×Ÿ

    if show_features_section:
        st.subheader("××¤×ª ×—×•× â€” ×¤×™×¦'×¨×™ ×××§×¨×•")
        feat_df = state.macro_features_df or state_get(MacroStateKeys.FEATURES_DF)
        feat_fig = _render_macro_heatmap(feat_df)
        _features_tools(feat_df, params=feature_params, fig=feat_fig)

    if show_overlay_section:
        st.subheader("×“×™×¨×•×’ ×–×•×’×•×ª ×œ×¤×™ Macro Fit")
        profile = state.macro_profile or state_get(MacroStateKeys.PROFILE)
        _render_pair_fit_table(profile)

        st.subheader("Overlay â€” ××©×§×•×œ×•×ª ×•×¤×¢×•×œ×•×ª")
        _render_overlay_table(profile)
        _overlay_downloads(profile)
    else:
        profile = state.macro_profile or state_get(MacroStateKeys.PROFILE)

    # Macro Shocks
    if show_shocks_section:
        _render_macro_shocks_section(state)

    # DNA ×œ×–×•×’ × ×‘×—×¨
    if show_dna_section:
        _render_pair_macro_dna_section(state, pairs_df)

    # ----------------------------------------------------------------------
    # ×”×•×¨×“×•×ª ×©×œ AdjustmentResult (JSON/YAML) ×œ×¤×™ Feature Flags
    # ----------------------------------------------------------------------
    if get_flag("macro_download", default=False):
        try:
            snapshot = getattr(result, "regime_snapshot", None)
            if snapshot is not None:
                try:
                    snapshot = {
                        k: float(v)
                        for k, v in dict(snapshot).items()
                    }
                except Exception:  # noqa: BLE001
                    snapshot = dict(snapshot)  # type: ignore[arg-type]

            payload = {
                "meta": state_get(MacroStateKeys.META, {}),
                "result": {
                    "exposure_multiplier": float(
                        getattr(result, "exposure_multiplier", 1.0),
                    ),
                    "pair_adjustments": getattr(result, "pair_adjustments", {}),
                    "filters": getattr(result, "filters", {}),
                    "regime_snapshot": snapshot or {},
                    "pair_scores": getattr(result, "pair_scores", {}),
                    "caps_hints": getattr(result, "caps_hints", {}),
                },
            }
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ ×ª×•×¦××ª ×××§×¨×• (JSON)",
                data=json.dumps(payload, ensure_ascii=False, indent=2).encode("utf-8"),
                file_name="macro_adjustments_result.json",
                mime="application/json",
                key=keygen(TAB_KEY, "download"),
            )

            caps = getattr(result, "caps_hints", {})
            if isinstance(caps, dict) and caps:
                st.download_button(
                    label="â¬‡ï¸ ×”×•×¨×“ Caps Hints (JSON)",
                    data=json.dumps(caps, ensure_ascii=False, indent=2).encode("utf-8"),
                    file_name="macro_caps_hints.json",
                    mime="application/json",
                    key=keygen(TAB_KEY, "download", "caps"),
                )
        except Exception:  # noqa: BLE001
            LOGGER.debug("macro_download disabled due to error", exc_info=True)

    if get_flag("export_yaml", default=False) and _HAS_YAML:
        try:
            payload_yaml = {
                "meta": state_get(MacroStateKeys.META, {}),
                "result": {
                    "exposure_multiplier": float(
                        getattr(result, "exposure_multiplier", 1.0),
                    ),
                    "pair_adjustments": getattr(result, "pair_adjustments", {}),
                    "filters": getattr(result, "filters", {}),
                },
            }
            st.download_button(
                label="â¬‡ï¸ ×”×•×¨×“ ×ª×•×¦××ª ×××§×¨×• (YAML)",
                data=yaml.safe_dump(payload_yaml, allow_unicode=True).encode("utf-8"),
                file_name="macro_adjustments_result.yaml",
                mime="text/yaml",
                key=keygen(TAB_KEY, "download", "yaml"),
            )
        except Exception:  # noqa: BLE001
            LOGGER.debug("macro_yaml disabled due to error", exc_info=True)

    return result

def render_macro_tab(*args: Any, **kwargs: Any) -> None:
    """
    render_macro_tab â€” Universal Router Wrapper ×œ×˜××‘ ×”×××§×¨×• (HF-grade, v5+)
    =======================================================================

    ××” ×”×¤×•× ×§×¦×™×” ×”×–×• ×¢×•×©×” ×‘×¤×•×¢×œ (×’×‘×•×”):
    -----------------------------------
    1. Router ×—×›×:
       â€¢ ×ª×•××š ×‘×§×¨×™××” ×”×—×“×©×” (Dashboard v4):
            render_macro_tab(app_ctx, feature_flags, nav_payload=None)
       â€¢ ×ª×•××š ×‘×§×¨×™××” ×”×™×©× ×” (legacy):
            render_macro_tab(pairs, config, ctx=None, ctrl_macro=None)

    2. × ×™×”×•×œ ×§×•× ×˜×§×¡×˜ ×××§×¨×•:
       â€¢ ×©×•××¨ nav_payload / macro_ctx / macro_panels ×‘-session_state.
       â€¢ ×™×•×¦×¨ macro_run_id + macro_entry_meta + macro_entry_telemetry.
       â€¢ ××›×•×•×Ÿ Workspace:
            - env (backtest/live)
            - date_range ×œ×¤×™ date_window (1Y/3Y/5Y/10Y/MAX).
       â€¢ ××§×‘×¢ ×“×’×œ×™× ×—×›××™×:
            - macro_debug (ui_mode="power")
            - macro_show_regimes_table (macro_profile="risk")
            - macro_warn_pairs_quality / macro_show_source_summary (risk_mode=defensive/stress)
            - macro_read_only / risk_profile_from_macro / macro_preset_selected.

    3. ×©×›×‘×ª Macro Factors (×¨×¢×™×•×Ÿ 1â€“3):
       â€¢ ×‘×•× ×” DataFrame ×©×œ ×¤×§×˜×•×¨×™ ×××§×¨×• ××ª×•×š MacroBundle.
       â€¢ ××™×™×¦×¨ MacroSnapshot (××¦×‘ ×××§×¨×•: rates/curve/vol/credit/fx/risk + risk_on_score).
       â€¢ ××–×”×” shocks ×‘×¤×§×˜×•×¨×™× (detect_macro_shocks):
            - multi-window (×œ××©×œ 1/5/20 ×™××™×).
            - ××ª×™×™×’ direction ×•×—×•××¨×”.
       â€¢ ×©×•××¨ ×‘-session_state:
            - macro_factor_snapshot      (dict)
            - macro_factor_summary_text  (string ×§×¦×¨)
            - macro_factor_risk_on_score (float)
            - macro_factor_extreme_keys  (list)
            - macro_factor_shocks_meta   (summary ×œÖ¾Risk/Portfolio/Agents).

    4. ×©×›×‘×ª Macro Adjustments ×œ×–×•×’×•×ª (×¨×¢×™×•×Ÿ 4â€“7):
       â€¢ ×× ×™×© pairs_df ×•×œ× read_only:
            Regime â†’ Exposure Multiplier â†’ Pair Overlays:
            - macro_multiplier ×œ×›×œ ×–×•×’.
            - macro_include (×¤×™×œ×˜×¨).
            - macro_score (Macro Fit).
            - caps_hints (×ª×§×¨×•×ª ×¡×§×˜×•×¨/××–×•×¨/××˜×‘×¢).
       â€¢ ×©×•××¨ ××ª overlay ×‘-session_state:
            - macro_pair_multipliers
            - macro_pair_filters
            - macro_pair_scores
            - macro_pair_caps_hints
            - macro_regime_snapshot / macro_regime_label
            - macro_risk_alert (×œ×¨×™×¡×§ ×× ×’'×™×Ÿ).

    5. ×©×›×‘×ª Meta ×œ-Universe / Risk Budget / Agents (×¨×¢×™×•×Ÿ 8â€“10):
       â€¢ macro_universe_meta:
            - n_pairs, universe_hash (hash ×©×œ pair_id×™×).
       â€¢ macro_risk_budget_hint:
            - ×”××œ×¦×” ×¤×©×•×˜×” ×œ-risk budget ×œ×¤×™ exposure_multiplier + risk_mode.
       â€¢ macro_focus_pair_overlay:
            - overlay ×××•×§×“ ×œ×–×•×’ ××—×“ (focus_pair_id) ×œ×˜×•×‘×ª DNA/Pair Tab/Agents.

    6. ×‘×¡×•×£:
       â€¢ ×§×•×¨××ª ×œ×¤×•× ×§×¦×™×” render(pairs_df, cfg, bundle) â€“ ×× ×•×¢ ×”×××§×¨×• ×”×¤× ×™××™
         ×©×‘×•× ×” ××ª ×”-UI ×©×œ ×”×˜××‘.
    """

    from datetime import date, datetime, timedelta  # ×©×™× ×œ×‘: ×‘×œ×™ timezone ×›×“×™ ×œ× ×œ×©×‘×•×¨

    # Helper ×¤× ×™××™: ×”××¨×” ×-MacroBundle ×œ-DataFrame ×©×œ ×¤×§×˜×•×¨×™×
    def _bundle_to_factor_df(bundle: MacroBundle) -> pd.DataFrame:
        series_map: Dict[str, pd.Series] = {}
        data = getattr(bundle, "data", {}) or {}
        for key, md in data.items():
            s = getattr(md, "series", None)
            if s is None or s.empty:
                continue
            s = s.copy()
            if not isinstance(s.index, pd.DatetimeIndex):
                s.index = pd.to_datetime(s.index, errors="coerce")
            series_map[key] = s.sort_index().astype(float)
        if not series_map:
            return pd.DataFrame()
        df = pd.DataFrame(series_map).sort_index()
        if not isinstance(df.index, pd.DatetimeIndex):
            df.index = pd.to_datetime(df.index, errors="coerce")
        return df

    # ==========================
    # 1) × ×™×¡×™×•×Ÿ: ×¡×’× ×•×Ÿ ×—×“×© (app_ctx, feature_flags, nav_payload)
    # ==========================
    app_ctx = kwargs.get("app_ctx")
    feature_flags = kwargs.get("feature_flags")
    nav_payload = kwargs.get("nav_payload")

    # × ×¡×™×•×Ÿ ×œ×—×œ×¥ app_ctx ××ª×•×š args ×× ×œ× ×”×’×™×¢ ×‘-kwargs
    if app_ctx is None and args:
        candidate = args[0]
        if hasattr(candidate, "settings") or hasattr(candidate, "project_root"):
            app_ctx = candidate
            if len(args) > 1:
                feature_flags = args[1]
            if len(args) > 2:
                nav_payload = args[2]

    # ×¡×’× ×•×Ÿ ×—×“×© (Dashboard v4)
    if app_ctx is not None:
        # ---------- 1.A ×©××™×¨×ª payload×™× ×‘-session_state ----------
        macro_ctx: Dict[str, Any] = {}
        macro_panels: Dict[str, Any] = {}

        if isinstance(nav_payload, Mapping):
            try:
                state_set("macro_nav_payload", dict(nav_payload))
            except Exception:
                st.session_state["macro_nav_payload"] = dict(nav_payload)

            maybe_ctx = nav_payload.get("macro_ctx")
            if isinstance(maybe_ctx, Mapping):
                macro_ctx = dict(maybe_ctx)
                try:
                    state_set("macro_ctx_from_nav", macro_ctx)
                except Exception:
                    st.session_state["macro_ctx_from_nav"] = macro_ctx

            maybe_panels = nav_payload.get("macro_panels")
            if isinstance(maybe_panels, Mapping):
                macro_panels = dict(maybe_panels)
                try:
                    state_set("macro_panels_requested", macro_panels)
                except Exception:
                    st.session_state["macro_panels_requested"] = macro_panels
        else:
            nav_payload = {}
            macro_ctx = {}
            macro_panels = {}

        # ---------- 1.B run_id + Telemetry ×‘×¡×™×¡×™×ª ----------
        try:
            macro_run_id = str(uuid4())
            state_set("macro_run_id", macro_run_id)
        except Exception:
            macro_run_id = "unknown"

        env_from_ctx = macro_ctx.get("env") if isinstance(macro_ctx, Mapping) else None
        profile_from_ctx = macro_ctx.get("profile") if isinstance(macro_ctx, Mapping) else None

        if isinstance(feature_flags, Mapping):
            env_from_ctx = env_from_ctx or feature_flags.get("env")
            profile_from_ctx = profile_from_ctx or feature_flags.get("profile")

        ui_mode = macro_ctx.get("ui_mode") if isinstance(macro_ctx, Mapping) else None
        macro_profile = macro_ctx.get("macro_profile") if isinstance(macro_ctx, Mapping) else None
        risk_mode = macro_ctx.get("risk_mode") if isinstance(macro_ctx, Mapping) else None
        layout_profile = macro_ctx.get("layout_profile") if isinstance(macro_ctx, Mapping) else None
        default_view = (
            nav_payload.get("default_view")
            if isinstance(nav_payload, Mapping) and "default_view" in nav_payload
            else macro_ctx.get("default_view")
            if isinstance(macro_ctx, Mapping)
            else None
        )
        overlay_focus = (
            nav_payload.get("overlay_focus")
            if isinstance(nav_payload, Mapping) and "overlay_focus" in nav_payload
            else macro_ctx.get("overlay_focus")
            if isinstance(macro_ctx, Mapping)
            else None
        )
        date_window = (
            nav_payload.get("date_window")
            if isinstance(nav_payload, Mapping) and "date_window" in nav_payload
            else macro_ctx.get("date_window")
            if isinstance(macro_ctx, Mapping)
            else None
        )
        macro_preset = (
            nav_payload.get("macro_preset")
            if isinstance(nav_payload, Mapping) and "macro_preset" in nav_payload
            else macro_ctx.get("macro_preset")
            if isinstance(macro_ctx, Mapping)
            else None
        )
        focus_pair_id = (
            nav_payload.get("focus_pair_id")
            if isinstance(nav_payload, Mapping)
            else None
        )
        read_only_flag = bool(
            (isinstance(nav_payload, Mapping) and nav_payload.get("read_only"))
            or (isinstance(macro_ctx, Mapping) and macro_ctx.get("read_only"))
        )

        # Telemetry ×œ×§×•× ×˜×§×¡×˜ ×›× ×™×¡×” (×ª×™×§×•×Ÿ timezone: utcnow() + "Z")
        entry_meta = {
            "run_id": macro_run_id,
            "ts_utc": datetime.utcnow().isoformat(timespec="seconds") + "Z",
            "env": env_from_ctx,
            "profile": profile_from_ctx,
            "macro_profile": macro_profile,
            "risk_mode": risk_mode,
            "ui_mode": ui_mode,
            "layout_profile": layout_profile,
            "default_view": default_view,
            "overlay_focus": overlay_focus,
            "date_window": date_window,
            "macro_preset": macro_preset,
            "panels_requested": list(macro_panels.keys()) if macro_panels else [],
        }
        try:
            state_set("macro_entry_meta", entry_meta)
        except Exception:
            st.session_state["macro_entry_meta"] = entry_meta

        try:
            state_set(
                "macro_entry_telemetry",
                {
                    "run_id": macro_run_id,
                    "env": env_from_ctx,
                    "profile": profile_from_ctx,
                    "macro_profile": macro_profile,
                    "risk_mode": risk_mode,
                    "dt_utc": entry_meta["ts_utc"],
                },
            )
        except Exception:
            pass

        # ---------- 1.C ×›×™×•×•×Ÿ Workspace (env / date_range) ----------
        env_sidebar = "backtest"
        if str(env_from_ctx).lower() in {"prod", "live", "production"}:
            env_sidebar = "live"
        try:
            st.session_state[keygen(TAB_KEY, "ws", "env")] = env_sidebar
        except Exception:
            pass

        days_map = {"1Y": 365, "3Y": 365 * 3, "5Y": 365 * 5, "10Y": 365 * 10}
        if isinstance(date_window, str):
            dw = date_window.upper()
            if dw in days_map:
                end_d = date.today()
                start_d = end_d - timedelta(days=days_map[dw])
            elif dw == "MAX":
                end_d = date.today()
                start_d = end_d - timedelta(days=365 * 15)
            else:
                start_d = end_d = None

            if start_d is not None and end_d is not None:
                try:
                    st.session_state[keygen(TAB_KEY, "ws", "date_range")] = (start_d, end_d)
                except Exception:
                    pass

        # ---------- 1.D ×“×’×œ×™× ×—×›××™× (Debug / Regimes / Source Summary) ----------
        if ui_mode == "power":
            set_flag("macro_debug", True)
        if macro_profile == "risk":
            set_flag("macro_show_regimes_table", True)
        if risk_mode in {"defensive", "stress"}:
            set_flag("macro_warn_pairs_quality", True)
            set_flag("macro_show_source_summary", True)

        try:
            state_set("macro_read_only", bool(read_only_flag))
        except Exception:
            st.session_state["macro_read_only"] = bool(read_only_flag)

        if risk_mode:
            try:
                state_set("risk_profile_from_macro", str(risk_mode))
            except Exception:
                st.session_state["risk_profile_from_macro"] = str(risk_mode)

        if macro_preset:
            try:
                state_set("macro_preset_selected", str(macro_preset))
            except Exception:
                st.session_state["macro_preset_selected"] = str(macro_preset)

        if focus_pair_id:
            try:
                st.session_state[keygen(TAB_KEY, "dna", "pair")] = str(focus_pair_id)
            except Exception:
                pass

        should_autorefresh = False
        if env_sidebar == "live":
            try:
                if isinstance(feature_flags, Mapping) and feature_flags.get("market_data"):
                    should_autorefresh = True
            except Exception:
                pass
        try:
            state_set("macro_should_autorefresh", bool(should_autorefresh))
        except Exception:
            st.session_state["macro_should_autorefresh"] = bool(should_autorefresh)

        # ---------- 1.E Logging ----------
        LOGGER.info(
            "macro_tab.render_macro_tab[new] | run_id=%s | env=%s, profile=%s, macro_profile=%s, "
            "risk_mode=%s, ui_mode=%s, layout=%s, date_window=%s, preset=%s, read_only=%s",
            macro_run_id,
            env_from_ctx,
            profile_from_ctx,
            macro_profile,
            risk_mode,
            ui_mode,
            layout_profile,
            date_window,
            macro_preset,
            read_only_flag,
        )

        if macro_panels:
            try:
                active_panels = [k for k, v in macro_panels.items() if v]
            except Exception:
                active_panels = []
            LOGGER.debug(
                "macro_tab.render_macro_tab[new] | requested panels=%s",
                active_panels,
            )

        # ---------- 1.F ××¦×™××ª pairs_df ×××§×•×¨×•×ª ×©×•× ×™× ----------
        pairs_df: Optional[pd.DataFrame] = None

        if isinstance(nav_payload, Mapping):
            maybe_df = nav_payload.get("pairs_df")
            if isinstance(maybe_df, pd.DataFrame):
                pairs_df = maybe_df

        if pairs_df is None and isinstance(nav_payload, Mapping):
            maybe_pairs = nav_payload.get("pairs")
            if isinstance(maybe_pairs, list):
                pairs_df = _pairs_list_to_df_for_tab(maybe_pairs)

        if pairs_df is None and hasattr(app_ctx, "pairs_df"):
            maybe = getattr(app_ctx, "pairs_df")
            if isinstance(maybe, pd.DataFrame):
                pairs_df = maybe

        if pairs_df is None and hasattr(app_ctx, "universe"):
            maybe = getattr(app_ctx, "universe")
            if isinstance(maybe, pd.DataFrame):
                pairs_df = maybe

        if pairs_df is None:
            maybe = state_get("pairs_df")
            if isinstance(maybe, pd.DataFrame):
                pairs_df = maybe

        if pairs_df is None:
            LOGGER.debug(
                "macro_tab.render_macro_tab[new] | run_id=%s | pairs_df not found â†’ running in 'macro-only' mode.",
                macro_run_id,
            )
        else:
            LOGGER.debug(
                "macro_tab.render_macro_tab[new] | run_id=%s | using pairs_df with %s rows.",
                macro_run_id,
                len(pairs_df),
            )

        # ---------- 1.G ×‘× ×™×™×ª MacroConfig + MacroBundle ----------
        settings = getattr(app_ctx, "settings", None)
        if settings is not None and hasattr(settings, "macro"):
            macro_cfg: MacroConfig = getattr(settings, "macro")  # type: ignore[assignment]
        else:
            macro_cfg = MacroConfig()

        if macro_profile and hasattr(macro_cfg, "macro_profile"):
            macro_cfg.macro_profile = macro_profile  # type: ignore[attr-defined]

        bundle: MacroBundle = load_macro_bundle(macro_cfg)

        # ---------- 1.H ×©×›×‘×ª Macro Factors (Snapshot + Shocks) ----------
        factor_df = _bundle_to_factor_df(bundle)
        factor_snapshot = None
        factor_summary_text = None
        factor_shocks_meta: Dict[str, Any] = {}

        if not factor_df.empty:
            try:
                factor_snapshot = build_macro_snapshot(factor_df, cfg=None)  # ×-macro_factors
                factor_summary_text = summarize_macro_snapshot(factor_snapshot)
            except Exception:
                factor_snapshot = None
                factor_summary_text = None

            try:
                shocks_df = detect_macro_shocks(
                    factor_df,
                    cfg=None,
                    windows=(1, 5, 20),
                    z_threshold=3.0,
                    max_events_per_factor=50,
                )
            except Exception:
                shocks_df = pd.DataFrame()

            # ×©××™×¨×ª snapshot + summary + shocks ×‘-session_state
            if factor_snapshot is not None:
                snap_dict = factor_snapshot.to_dict()
                try:
                    state_set("macro_factor_snapshot", snap_dict)
                except Exception:
                    st.session_state["macro_factor_snapshot"] = snap_dict

                try:
                    state_set("macro_factor_summary_text", factor_summary_text or "")
                except Exception:
                    st.session_state["macro_factor_summary_text"] = factor_summary_text or ""

                # ×¨×¢×™×•×Ÿ: ×¨××ª risk-on ××•×”×“×ª / ×¢×•×™× ×ª ×œ×›×œ ×”××¢×¨×›×ª
                try:
                    risk_on_score = snap_dict.get("risk_on_score", 0.0)
                except Exception:
                    risk_on_score = 0.0
                try:
                    state_set("macro_factor_risk_on_score", float(risk_on_score))
                except Exception:
                    st.session_state["macro_factor_risk_on_score"] = float(risk_on_score)

                # ×¤×§×˜×•×¨×™× ×§×™×¦×•× ×™×™× (×œ×‘×œ×•×Ÿ/×‘×× ×¨)
                extreme_factors = snap_dict.get("extreme_factors") or []
                try:
                    state_set("macro_factor_extreme_keys", list(extreme_factors))
                except Exception:
                    st.session_state["macro_factor_extreme_keys"] = list(extreme_factors)

            if shocks_df is not None and not shocks_df.empty:
                # Summary ×§×¦×¨ ×©×œ shocks ×œ×¤×™ group/×¤×§×˜×•×¨
                try:
                    last_ts = shocks_df.index.max()
                    top_events = shocks_df.sort_values("severity_rank", ascending=False).head(20)
                    factor_shocks_meta = {
                        "last_ts": last_ts.isoformat(),
                        "n_events": int(len(shocks_df)),
                        "top_factors": list(top_events["factor_key"].value_counts().head(5).index),
                    }
                    state_set("macro_factor_shocks_meta", factor_shocks_meta)
                except Exception:
                    st.session_state["macro_factor_shocks_meta"] = factor_shocks_meta

        # ---------- 1.I ×©×›×‘×ª Macro Adjustments ×œ×–×•×’×•×ª ----------
        adj = None
        if pairs_df is not None and not read_only_flag:
            try:
                pairs_df = pairs_df.copy()
                adj = compute_adjustments(pairs_df, bundle, macro_cfg)
            except Exception:
                LOGGER.exception("macro_tab.render_macro_tab[new]: compute_adjustments failed")
                adj = None

        # ×©××™×¨×ª ×ª×•×¦××•×ª ×”×××§×¨×• ×‘-session_state ×œ×©×™××•×© ×‘×˜××‘×™× ××—×¨×™×
        if adj is not None:
            try:
                scores = list(adj.pair_scores.values()) if adj.pair_scores else []
                mean_score = sum(scores) / len(scores) if scores else None
            except Exception:
                mean_score = None

            try:
                state_set(
                    "macro_last_adjustments",
                    {
                        "run_id": macro_run_id,
                        "ts_utc": entry_meta["ts_utc"],
                        "regime_label": adj.regime_label,
                        "exposure_multiplier": adj.exposure_multiplier,
                        "n_pairs": len(adj.pair_adjustments),
                        "included": int(sum(1 for v in adj.filters.values() if v)),
                        "mean_macro_score": mean_score,
                    },
                )
            except Exception:
                st.session_state["macro_last_adjustments"] = {
                    "run_id": macro_run_id,
                    "regime_label": adj.regime_label,
                    "exposure_multiplier": adj.exposure_multiplier,
                }

            # overlay ×‘×¨××ª ×–×•×’
            try:
                state_set("macro_pair_multipliers", adj.pair_adjustments)
                state_set("macro_pair_filters", adj.filters)
                state_set("macro_pair_scores", adj.pair_scores)
                state_set("macro_pair_caps_hints", adj.caps_hints)
            except Exception:
                st.session_state["macro_pair_multipliers"] = adj.pair_adjustments
                st.session_state["macro_pair_filters"] = adj.filters
                st.session_state["macro_pair_scores"] = adj.pair_scores
                st.session_state["macro_pair_caps_hints"] = adj.caps_hints

            # snapshot ×©×œ Regime
            if adj.regime_snapshot is not None:
                try:
                    state_set("macro_regime_snapshot", adj.regime_snapshot.to_dict())
                except Exception:
                    st.session_state["macro_regime_snapshot"] = adj.regime_snapshot.to_dict()
            if adj.regime_label is not None:
                try:
                    state_set("macro_regime_label", adj.regime_label)
                except Exception:
                    st.session_state["macro_regime_label"] = adj.regime_label

            # ×¨×¢×™×•×Ÿ: macro_risk_alert ×œ×¨×™×¡×§ ×× ×’'×™×Ÿ
            risk_alert = False
            try:
                if adj.exposure_multiplier is not None and adj.exposure_multiplier < 0.8:
                    risk_alert = True
                if str(adj.regime_label or "").startswith("risk_off"):
                    risk_alert = True
            except Exception:
                pass
            try:
                state_set("macro_risk_alert", bool(risk_alert))
            except Exception:
                st.session_state["macro_risk_alert"] = bool(risk_alert)

            # meta ×¢×œ ×”-universe (×’×•×“×œ ×•-hash ×œ×¤×™ pair_id)
            try:
                if pairs_df is not None:
                    if "pair_id" in pairs_df.columns:
                        ids = list(pairs_df["pair_id"].astype(str))
                    else:
                        ids = [f"{row.get('a','?')}-{row.get('b','?')}" for _, row in pairs_df.iterrows()]
                    universe_hash = hash(tuple(ids))
                    universe_meta = {
                        "run_id": macro_run_id,
                        "n_pairs": len(ids),
                        "universe_hash": universe_hash,
                    }
                    state_set("macro_universe_meta", universe_meta)
            except Exception:
                pass

            # focus_pair_id â†’ overlay ×××•×§×“ ×œ×–×•×’ ××—×“
            if focus_pair_id is not None:
                pid = str(focus_pair_id)
                focused = {
                    "pair_id": pid,
                    "macro_multiplier": adj.pair_adjustments.get(pid),
                    "macro_include": adj.filters.get(pid),
                    "macro_score": adj.pair_scores.get(pid),
                    "caps_hint": adj.caps_hints.get(pid),
                }
                try:
                    state_set("macro_focus_pair_overlay", focused)
                except Exception:
                    st.session_state["macro_focus_pair_overlay"] = focused

            # ×¨×¢×™×•×Ÿ: macro_risk_budget_hint â€“ ×”××œ×¦×” ×œ×’×•×“×œ ×¡×™×›×•×Ÿ (0â€“1)
            try:
                exp_mult = float(adj.exposure_multiplier or 1.0)
            except Exception:
                exp_mult = 1.0
            base_budget = 1.0
            if risk_mode in {"defensive", "stress"}:
                base_budget = 0.7
            elif risk_mode in {"aggressive"}:
                base_budget = 1.3
            risk_budget_hint = max(0.3, min(1.5, base_budget * exp_mult))
            try:
                state_set("macro_risk_budget_hint", risk_budget_hint)
            except Exception:
                st.session_state["macro_risk_budget_hint"] = risk_budget_hint

        # ×’× ×× ××™×Ÿ pairs_df ××• read_only, ×¢×“×™×™×Ÿ ×§×•×¨××™× ×œ-render ×¢× cfg+bundle
        try:
            render(pairs_df=pairs_df, cfg=macro_cfg, bundle=bundle)
        except TypeError:
            render(pairs_df=pairs_df, cfg=None, bundle=None)

        LOGGER.info(
            "macro_tab.render_macro_tab[new] | run_id=%s | done",
            macro_run_id,
        )
        return

    # ==========================
    # 2) Legacy style (pairs, config, ctx=None, ctrl_macro=None)
    # ==========================
    if not args:
        LOGGER.error(
            "render_macro_tab called without app_ctx or pairs (no arguments); running macro-only.",
        )
        render(pairs_df=None, cfg=None, bundle=None)
        return

    pairs = args[0]
    try:
        pairs_df_legacy = _pairs_list_to_df_for_tab(pairs)
    except Exception:
        LOGGER.exception(
            "render_macro_tab[legacy]: failed to convert pairsâ†’pairs_df; falling back to empty universe.",
        )
        pairs_df_legacy = None

    LOGGER.info(
        "macro_tab.render_macro_tab[legacy] called with %s pairs",
        len(pairs) if isinstance(pairs, Sequence) else "unknown",
    )

    # ×’× ×‘××¦×‘ legacy â€“ × ×¨×™×¥ ×©×›×‘×ª ×××§×¨×• ×‘×¡×™×¡×™×ª ×× ×™×© pairs_df
    if pairs_df_legacy is not None and len(pairs_df_legacy) > 0:
        legacy_run_id = f"legacy-{uuid4()}"
        macro_cfg = MacroConfig()
        bundle = load_macro_bundle(macro_cfg)
        try:
            adj = compute_adjustments(pairs_df_legacy, bundle, macro_cfg)
            state_set(
                "macro_last_adjustments_legacy",
                {
                    "run_id": legacy_run_id,
                    "regime_label": adj.regime_label,
                    "exposure_multiplier": adj.exposure_multiplier,
                    "n_pairs": len(adj.pair_adjustments),
                },
            )
        except Exception:
            LOGGER.exception("macro_tab.render_macro_tab[legacy]: compute_adjustments failed")
            bundle = None
            macro_cfg = None  # type: ignore[assignment]
        render(pairs_df=pairs_df_legacy, cfg=macro_cfg, bundle=bundle)
    else:
        render(pairs_df=None, cfg=None, bundle=None)


def _safe_float_or_none(x: Any) -> Optional[float]:
    try:
        if x is None:
            return None
        v = float(x)
        if not (v == v):  # NaN check
            return None
        return v
    except Exception:
        return None

def push_macro_metrics_to_ctx(
    *,
    macro_sensitivity: Any,
    macro_score: Any,
    max_dd_60d: Any = None,
    vol_60d: Any = None,
    ctx_key: str = "macro_metrics",
) -> None:
    """
    ×©×•××¨ ××“×“×™ ×××§×¨×• ×¨×œ×•×•× ×˜×™×™× ×œ-Tab Comparison ×‘×ª×•×š st.session_state[ctx_key].

    ××¤×ª×—×™ ×”-keys ××•×ª×××™× ×œ-render_tab_comparison_lab:
      - "macro_sensitivity" / "macro_regime_score"
      - "macro_score" / "tab_score"
      - "max_dd_60d" / "macro_max_dd"
      - "vol_60d" / "macro_vol_60d"
    """
    metrics: Dict[str, float] = {}


    ms = _safe_float_or_none(macro_sensitivity)
    if ms is not None:
        metrics["macro_sensitivity"] = ms
        metrics["macro_regime_score"] = ms  # alias ××•×¤×¦×™×•× ×œ×™

    sc = _safe_float_or_none(macro_score)
    if sc is not None:
        metrics["macro_score"] = sc
        metrics["tab_score"] = sc  # alias ×›×œ×œ×™

    dd = _safe_float_or_none(max_dd_60d)
    if dd is not None:
        metrics["max_dd_60d"] = dd
        metrics["macro_max_dd"] = dd

    vol = _safe_float_or_none(vol_60d)
    if vol is not None:
        metrics["vol_60d"] = vol
        metrics["macro_vol_60d"] = vol

    st.session_state[ctx_key] = metrics

def push_risk_metrics_to_ctx(
    result: AdjustmentResult,
    meta: Mapping[str, Any],
    ctx_key: str = "risk_metrics",
) -> None:
    """
    ×©×•××¨ ××“×“×™ ×¡×™×›×•×Ÿ ×’×œ×•×‘×œ×™×™× ×œ-Tab Comparison ×‘×ª×•×š st.session_state[ctx_key].

    ××‘×•×¡×¡ ×¢×œ:
      - result.exposure_multiplier
      - meta['pairs'] / meta['included'] ×-_stamp_result
      - risk_profile_from_macro (×× ×§×™×™× ×‘-session_state)
    """
    metrics: Dict[str, float] = {}

    exp_mult = _safe_float_or_none(getattr(result, "exposure_multiplier", 1.0))
    if exp_mult is None:
        exp_mult = 1.0

    pairs = _safe_float_or_none(meta.get("pairs"))
    included = _safe_float_or_none(meta.get("included"))

    if pairs is not None and pairs > 0 and included is not None:
        inclusion_ratio = max(0.0, min(1.0, included / pairs))
    else:
        inclusion_ratio = 1.0

    # risk_score ×¤×©×•×˜: ×›××” ×—×©×•×¤×™× Ã— ×›××” ×–×•×’×•×ª ××©×—×§×™× ×‘×¤× ×™×
    risk_score = 100.0 * inclusion_ratio * min(exp_mult, 2.0) / 2.0

    metrics["risk_exposure"] = float(exp_mult)
    metrics["risk_inclusion_ratio"] = float(inclusion_ratio)
    metrics["risk_score"] = float(risk_score)

    # × × ×¡×” ×œ××©×•×š ×’× risk_profile ××”×××§×¨×• (×× ×”×’×™×¢ ××”-dashboard)
    risk_profile = state_get("risk_profile_from_macro", None)
    if risk_profile is not None:
        metrics["risk_profile"] = float("nan")  # ×¨×§ placeholder ××¡×¤×¨×™
        # × ×©××•×¨ ×’× ××ª ×”×˜×§×¡×˜ ×‘××¤×ª×— × ×¤×¨×“
        try:
            # st.session_state ×××¤×©×¨ ×’× non-float values, ××– × ×©×™× dict ××•×¨×›×‘
            pass
        except Exception:
            pass

    st.session_state[ctx_key] = metrics
    # ×‘× ×•×¡×£, × ×©××•×¨ ×˜×§×¡×˜×•××œ×™ × ×¤×¨×“ ×× ×¨×•×¦×™×:
    if risk_profile is not None:
        st.session_state[f"{ctx_key}_label"] = str(risk_profile)

def _get_macro_panels_flags() -> Dict[str, bool]:
    """
    ××—×–×™×¨ dict ×©×œ ×¤×× ×œ×™× ××‘×•×§×©×™× ××”-dashboard (×× ×§×™×™×),
    ×œ×¤×™ ××” ×©×”-router ×›×ª×‘ ×‘-session_state["macro_panels_requested"].
    ×× ××™×Ÿ ×›×œ×•× â€“ ××—×–×™×¨ dict ×¨×™×§, ×•×”×˜××‘ ××ª× ×”×’ ×œ×¤×™ ×‘×¨×™×¨×ª ×”××—×“×œ ×©×œ×•.
    """
    panels_req = state_get("macro_panels_requested", None)
    if isinstance(panels_req, Mapping):
        try:
            return {str(k): bool(v) for k, v in panels_req.items()}
        except Exception:  # noqa: BLE001
            return {}
    return {}

# ---------------------------------------------------------------------------
# ×ª××™××•×ª ×œ-pd.np (×œ×©×™××•×© ×œ×•×’××¨×™×ª××™ ×‘×ª×•×š _build_spread_series ×× ×¦×¨×™×š)
# ---------------------------------------------------------------------------
try:  # ×”×ª×××” ×œ××—×•×¨ ×‘××§×¨×” ×©××©×ª××©×™× ×‘-pd.np.log
    import numpy as _np  # type: ignore

    if not hasattr(pd, "np"):
        pd.np = _np  # type: ignore[attr-defined]
except Exception:  # noqa: BLE001
    pass


__all__ = ["render", "render_macro_tab"]

