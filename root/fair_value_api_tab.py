# -*- coding: utf-8 -*-
"""
fair_value_api_tab.py â€” Fair Value Engine / Optimizer / Advisor API Lab (v2)
=============================================================================

×˜××‘ Streamlit ××‘×•×“×“ ×©×¢×•×‘×“ ×¨×§ ××•×œ ×”-HTTP API ×”××§×•××™ ×©×œ×š (root/api_server.py).

××¦×‘×™×:
- âš™ï¸ Engine (/engine/run)   â€” ××¨×™×¥ ××ª FairValueEngine ×•××¨××” ×ª×•×¦××•×ª + ×’×¨×¤×™×.
- ğŸ§  Advisor (/advisor/run) â€” ××¨×™×¥ Engine ×‘×¤× ×™×, ×× ×ª×— ××ª ×”-universe ×•××—×–×™×¨ ×¢×¦×•×ª ×œ×©×™×¤×•×¨.
- ğŸ§¬ Optimizer (/optimizer/run) â€” ××¨×™×¥ optimize_fair_value ×•××¦×™×’ ××ª bestParams.

××§×•×¨×•×ª ×“××˜×”:
- Demo data (×¡×™××•×œ×¦×™×” ××•×‘× ×™×ª).
- ×”×¢×œ××ª CSV (×ª××¨×™×›×™× + ×˜×™×§×¨×™×).
- JSON ×’×•×œ××™.
- ×˜×¢×™× ×ª JSON ×©××•×¨ (payload previously downloaded).

×ª×•×¡×¤×•×ª ×‘×’×¨×¡×” ×–×•:
- ×›×¤×ª×•×¨ Download JSON ×œ×›×œ payload (Engine / Advisor / Optimizer).
- ××¤×©×¨×•×ª ×œ×˜×¢×•×Ÿ payload ××§×•×‘×¥ JSON.
- ×”×™×¡×˜×•×¨×™×™×ª ×¨×™×¦×•×ª Advisor + ×”×©×•×•××ª ×©×ª×™ ×¨×™×¦×•×ª (KPIs + ×”×‘×“×œ ×¢×¦×•×ª).
"""

from __future__ import annotations

from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

import itertools
import json

import numpy as np
import pandas as pd
import plotly.express as px
import requests
import streamlit as st
from streamlit.errors import StreamlitSecretNotFoundError
from root.optimization_tab import api_optimize_pair, api_optimize_pairs_batch
try:
    from core.app_context import AppContext
except Exception:
    AppContext = None  # fallback ×× ××™×Ÿ / ×‘×–××Ÿ ×‘×“×™×§×•×ª

import logging

logger = logging.getLogger(__name__)

# =====================================
#  ×”×’×“×¨×•×ª ×‘×¡×™×¡ ×œ-API
# =====================================
def _get_app_ctx() -> Any:
    """
    ×× ×¡×” ×œ×”×—×–×™×¨ AppContext ××—×“:

    ×¡×“×¨ ×¢×“×™×¤×•×™×•×ª:
    1. st.session_state["app_ctx"] ×× ×§×™×™×.
    2. AppContext.get_global() ×× ×”×¤×•× ×§×¦×™×” ×§×™×™××ª.
    3. ××—×¨×ª â†’ None.
    """
    # 1. ××”-session_state (dashoard.py ×‘×“"×› ×©× ×©× ××ª ×”-app_ctx)
    ctx = None
    try:
        ctx = st.session_state.get("app_ctx")
    except Exception:
        ctx = None

    # 2. AppContext.get_global() ×× ×¢×“×™×™×Ÿ ××™×Ÿ
    if ctx is None and AppContext is not None:
        try:
            if hasattr(AppContext, "get_global"):
                ctx = AppContext.get_global()
        except Exception:
            ctx = None

    return ctx


def _get_fair_value_config():
    """
    ×× ×¡×” ×œ×”×—×–×™×¨ FairValueAPIConfig ××ª×•×š ×”-AppContext.
    ××—×–×™×¨ None ×× ××™×Ÿ ××• ×× disabled.
    """
    ctx = _get_app_ctx()
    if ctx is None:
        return None

    cfg = getattr(ctx, "fair_value_api", None)
    # ×™×›×•×œ ×œ×”×™×•×ª ×©×–×” dict ××• Pydantic; × ×•×•×“× ×©×”×•× ×œ× ×¨×™×§
    if cfg is None:
        return None

    try:
        # ×× ×–×” ××•×“×œ Pydantic â€” ×™×© ×œ×• dict / model_dump; ×× dataclass â€” × × ×™×— ×©×™×© attr.
        is_enabled = getattr(cfg, "is_enabled", getattr(cfg, "enabled", False))
        if not is_enabled:
            return None
    except Exception:
        return None

    return cfg

DEFAULT_API_BASE = "http://localhost:8000"

def _resolve_api_base() -> str:
    """
    ××—×–×™×¨ ××ª ×‘×¡×™×¡ ×”-API ×œ×©×™×¨×•×ª ×”-Fair Value.

    ×× ×™×© secrets.toml ×¢× FAIR_VALUE_API_URL â†’ ×™×©×ª××© ×‘×•.
    ×× ××™×Ÿ secrets ×‘×›×œ×œ â†’ × ×©×ª××© ×‘-DEFAULT_API_BASE ×‘×œ×™ ×œ×”×¤×™×œ ××ª ×”×˜××‘.
    """
    try:
        return st.secrets.get("FAIR_VALUE_API_URL", DEFAULT_API_BASE)
    except StreamlitSecretNotFoundError:
        logger.info(
            "FairValue: no secrets.toml found; using DEFAULT_API_BASE=%s",
            DEFAULT_API_BASE,
        )
        return DEFAULT_API_BASE
    except Exception as exc:
        logger.warning(
            "FairValue: failed to read FAIR_VALUE_API_URL from secrets (%s); "
            "using DEFAULT_API_BASE=%s",
            exc,
            DEFAULT_API_BASE,
        )
        return DEFAULT_API_BASE
# =====================================
#  Helpers â€” HTTP
# =====================================

def _get_json(path: str, timeout: int = 5) -> Dict[str, Any]:
    """
    GET JSON ×¢× ×©×™××•×© ×‘-FairValueAPIConfig ×× ×–××™×Ÿ (timeouts / headers / TLS).
    """
    base = _resolve_api_base()
    url = f"{base.rstrip('/')}/{path.lstrip('/')}"

    cfg = _get_fair_value_config()
    req_kwargs: Dict[str, Any] = {}

    if cfg is not None:
        # × ×©×ª××© ×‘-timeout ×”×›×œ×œ×™ / verify / headers
        try:
            req_kwargs.update(cfg.as_requests_kwargs())
        except Exception:
            # fallback: × ×‘× ×” ×™×“× ×™×ª
            req_kwargs["timeout"] = getattr(cfg, "total_timeout_sec", timeout) or timeout
            req_kwargs["headers"] = getattr(cfg, "headers", {}) or {}
            req_kwargs["verify"] = getattr(cfg, "verify_tls", True)
    else:
        req_kwargs["timeout"] = timeout

    resp = requests.get(url, **req_kwargs)
    try:
        data = resp.json()
    except Exception:
        data = {"raw": resp.text}
    if not resp.ok:
        raise RuntimeError(f"HTTP {resp.status_code}: {data}")
    return data



def _post_json(path: str, payload: Dict[str, Any], timeout: int = 60) -> Dict[str, Any]:
    base = _resolve_api_base()
    url = f"{base.rstrip('/')}/{path.lstrip('/')}"
    resp = requests.post(url, json=payload, timeout=timeout)
    try:
        data = resp.json()
    except Exception:
        data = {"raw": resp.text}
    if not resp.ok:
        raise RuntimeError(f"HTTP {resp.status_code}: {data}")
    return data



def _check_health() -> Tuple[bool, Dict[str, Any]]:
    try:
        data = _get_json("/health", timeout=3)
        return True, data
    except Exception as e:
        return False, {"error": str(e)}


# =====================================
#  Helpers â€” Data construction
# =====================================

def _build_demo_prices(n_days: int = 252) -> Dict[str, Any]:
    """
    ×‘×•× ×” price matrix ×¤×©×•×˜×” (3 ×˜×™×§×¨×™×, N ×™××™×) ×œ×¡×‘×™×‘×ª ×“××•.

    - ×©×œ×•×©×” ×¡×™××‘×•×œ×™×: SPY, QQQ, IWM.
    - ××”×œ×š ×¨× ×“×•××œ×™ ×¢× ×§×•×¨×œ×¦×™×” ×’×‘×•×”×” ×‘×™×Ÿ SPY/QQQ, ×§×¦×ª ×©×•× ×” ×œ-IWM.
    """
    end = datetime.utcnow().date()
    dates = [end - timedelta(days=i) for i in range(n_days)]
    dates = sorted(dates)

    rng = np.random.default_rng(42)
    base_r = rng.normal(0, 0.01, size=n_days)
    r_spy = base_r
    r_qqq = base_r + rng.normal(0, 0.004, size=n_days)
    r_iwm = base_r * 0.7 + rng.normal(0, 0.008, size=n_days)

    p_spy = 100 * np.exp(np.cumsum(r_spy))
    p_qqq = 100 * np.exp(np.cumsum(r_qqq))
    p_iwm = 100 * np.exp(np.cumsum(r_iwm))

    time_index = [datetime.combine(d, datetime.min.time()) for d in dates]

    prices_wide = {
        "SPY": p_spy.round(4).tolist(),
        "QQQ": p_qqq.round(4).tolist(),
        "IWM": p_iwm.round(4).tolist(),
    }

    pairs = [
        ["SPY", "QQQ"],
        ["SPY", "IWM"],
        ["QQQ", "IWM"],
    ]

    return {
        "timeIndex": time_index,
        "pricesWide": prices_wide,
        "pairs": pairs,
    }


def _build_from_csv(uploaded_file, key_prefix: str) -> Optional[Dict[str, Any]]:
    """
    ×§×¨×™××ª CSV ××”××©×ª××©:
    - ×¢××•×“×ª ×ª××¨×™×š (× ×‘×—×¨×ª ×¢×œ ×™×“×•)
    - ×¢××•×“×•×ª ××—×™×¨×™× (×˜×™×§×¨×™×)
    - ×‘×—×™×¨×ª ×–×•×’×•×ª ×œ× ×™×ª×•×—
    """
    try:
        df = pd.read_csv(uploaded_file)
    except Exception as e:
        st.error(f"×§×¨×™××ª ×”-CSV × ×›×©×œ×”: {e}")
        return None

    if df.empty:
        st.error("×§×•×‘×¥ ×”-CSV ×¨×™×§.")
        return None

    st.markdown("**×ª×¦×•×’×” ××§×“×™××” ×©×œ ×”×“××˜×”:**")
    st.dataframe(df.head(), use_container_width=True)

    cols = list(df.columns)
    date_col = st.selectbox(
        "×¢××•×“×ª ×ª××¨×™×š:",
        options=cols,
        index=0,
        key=f"{key_prefix}_date_col",
    )

    value_cols = [c for c in cols if c != date_col]
    if not value_cols:
        st.error("×œ× × ××¦××• ×¢××•×“×•×ª ××—×™×¨×™× (×—×•×¥ ××¢××•×“×ª ×”×ª××¨×™×š).")
        return None

    selected_symbols = st.multiselect(
        "×‘×—×¨ ×˜×™×§×¨×™× (×¢××•×“×•×ª ××—×™×¨×™×):",
        options=value_cols,
        default=value_cols[: min(5, len(value_cols))],
        key=f"{key_prefix}_symbols",
    )

    if len(selected_symbols) < 2:
        st.info("×¦×¨×™×š ×œ×¤×—×•×ª 2 ×˜×™×§×¨×™× ×›×“×™ ×œ×‘× ×•×ª ×–×•×’×•×ª.")
        return None

    all_pairs = list(itertools.combinations(selected_symbols, 2))
    default_pairs = all_pairs[: min(10, len(all_pairs))]

    selected_pairs = st.multiselect(
        "×‘×—×¨ ×–×•×’×•×ª ×œ× ×™×ª×•×—:",
        options=[f"{a}/{b}" for (a, b) in all_pairs],
        default=[f"{a}/{b}" for (a, b) in default_pairs],
        key=f"{key_prefix}_pairs",
    )

    if not selected_pairs:
        st.info("×”××¢×¨×›×ª ×œ× ×ª×¨×™×¥ ×›×œ×•× ×‘×œ×™ ×œ×¤×—×•×ª ×–×•×’ ××—×“.")
        return None

    try:
        idx = pd.to_datetime(df[date_col], errors="coerce")
    except Exception as e:
        st.error(f"×›×©×œ ×‘×”××¨×ª ×¢××•×“×ª ×”×ª××¨×™×š ×œ-datetime: {e}")
        return None

    mask = idx.notna()
    if not mask.any():
        st.error("×¢××•×“×ª ×”×ª××¨×™×š ×œ× ×”×¦×œ×™×—×” ×œ×¢×‘×•×¨ ×”××¨×” ×œ-datetime.")
        return None

    df = df.loc[mask].reset_index(drop=True)
    idx = idx.loc[mask]

    prices_wide: Dict[str, List[float]] = {}
    for sym in selected_symbols:
        try:
            series = pd.to_numeric(df[sym], errors="coerce")
        except Exception:
            continue
        prices_wide[sym] = series.fillna(method="ffill").fillna(method="bfill").tolist()

    time_index = [dt.to_pydatetime() for dt in idx]

    pairs: List[List[str]] = []
    for s in selected_pairs:
        a, b = s.split("/")
        pairs.append([a.strip(), b.strip()])

    return {
        "timeIndex": time_index,
        "pricesWide": prices_wide,
        "pairs": pairs,
    }


def _config_overrides_ui(key_prefix: str) -> Dict[str, Any]:
    """
    UI ×‘×¡×™×¡×™ ×œ-configOverrides ×œ-Engine.
    ××—×–×™×¨ ××™×œ×•×Ÿ ×©××ª××™× ×œ-EngineConfigOverridesModel ×‘-API.
    """
    st.markdown("#### âš™ï¸ ×”×’×“×¨×•×ª Engine (configOverrides)")

    col1, col2, col3 = st.columns(3)

    with col1:
        window = st.number_input(
            "window (×—×™×©×•×‘ fair value)",
            min_value=20,
            max_value=252 * 3,
            value=126,
            step=10,
            key=f"{key_prefix}_window",
        )
        min_overlap = st.number_input(
            "min_overlap",
            min_value=20,
            max_value=int(window),
            value=min(60, int(window)),
            step=5,
            key=f"{key_prefix}_min_overlap",
        )
        log_mode = st.checkbox(
            "log_mode (log prices)",
            value=True,
            key=f"{key_prefix}_log_mode",
        )

    with col2:
        z_in = st.number_input(
            "z_in (×›× ×™×¡×” ×œ×¤×•×–×™×¦×™×”)",
            min_value=0.5,
            max_value=5.0,
            value=2.0,
            step=0.1,
            key=f"{key_prefix}_z_in",
        )
        z_out = st.number_input(
            "z_out (×™×¦×™××” ××¤×•×–×™×¦×™×”)",
            min_value=0.5,
            max_value=6.0,
            value=0.5,
            step=0.1,
            key=f"{key_prefix}_z_out",
        )
        use_winsor = st.checkbox(
            "use_winsor_for_z",
            value=True,
            key=f"{key_prefix}_use_winsor",
        )

    with col3:
        target_vol = st.number_input(
            "target_vol_ann (×™×¢×“ ×ª× ×•×“×ª×™×•×ª ×©× ×ª×™×ª)",
            min_value=0.01,
            max_value=1.0,
            value=0.15,
            step=0.01,
            key=f"{key_prefix}_target_vol",
        )
        kelly_fraction = st.number_input(
            "kelly_fraction",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            key=f"{key_prefix}_kelly_fraction",
        )
        max_leverage = st.number_input(
            "max_leverage",
            min_value=0.5,
            max_value=10.0,
            value=3.0,
            step=0.5,
            key=f"{key_prefix}_max_leverage",
        )

    overrides: Dict[str, Any] = {
        "window": int(window),
        "min_overlap": int(min_overlap),
        "log_mode": bool(log_mode),
        "z_in": float(z_in),
        "z_out": float(z_out),
        "use_winsor_for_z": bool(use_winsor),
        "target_vol_ann": float(target_vol),
        "kelly_fraction": float(kelly_fraction),
        "max_leverage": float(max_leverage),
    }
    return overrides


def _normalize_pair_field(rows: List[Dict[str, Any]]) -> None:
    """
    ×× ×¨××œ ××ª ×”×©×“×” pair ×œ×ª×¦×•×¨×” "A/B" ×›×“×™ ×©×™×”×™×” × ×•×— ×œ×”×¦×™×’ ×‘-DataFrame.
    ×¢×•×‘×“ in-place.
    """
    for r in rows:
        pair_val = r.get("pair")
        if isinstance(pair_val, dict) and "__root__" in pair_val:
            root = r["pair"]["__root__"]
            if isinstance(root, (list, tuple)) and len(root) == 2:
                r["pair"] = f"{root[0]}/{root[1]}"
        elif isinstance(pair_val, (list, tuple)) and len(pair_val) == 2:
            r["pair"] = f"{pair_val[0]}/{pair_val[1]}"


def _payload_download_ui(payload: Dict[str, Any], label: str, key_prefix: str) -> None:
    """
    ××¦×™×’ ×›×¤×ª×•×¨ Download ×œ-payload JSON.
    """
    b = json.dumps(payload, indent=2, default=str).encode("utf-8")
    st.download_button(
        label=label,
        data=b,
        file_name=f"{key_prefix}_payload_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json",
        key=f"{key_prefix}_download_btn",
    )


def _payload_upload_json_ui(key_prefix: str) -> Optional[Dict[str, Any]]:
    """
    ×××¤×©×¨ ×œ×˜×¢×•×Ÿ payload ×-JSON ×©××•×¨ (××”-Download).
    """
    uploaded = st.file_uploader(
        "××• ×˜×¢×Ÿ payload ××§×•×‘×¥ JSON ×©××•×¨:",
        type=["json"],
        key=f"{key_prefix}_upload_json",
    )
    if uploaded is None:
        return None

    try:
        raw = uploaded.read().decode("utf-8")
        data = json.loads(raw)
        st.success("×˜×¢× ×ª payload ×-JSON.")
        with st.expander("ğŸ” JSON ×˜×¢×•×Ÿ", expanded=False):
            st.json(data)
        return data
    except Exception as e:
        st.error(f"×›×©×œ ×‘×§×¨×™××ª JSON: {e}")
        return None


# =====================================
#  Engine Section
# =====================================

def _render_engine_section() -> None:
    st.subheader("âš™ï¸ Engine â€“ /engine/run")

    dataset_mode = st.radio(
        "××§×•×¨ ×“××˜×” ×œ-Engine:",
        options=["Demo", "Upload CSV", "Raw JSON", "Load saved JSON"],
        horizontal=True,
        key="fv_engine_dataset_mode",
    )

    payload: Optional[Dict[str, Any]] = None

    if dataset_mode == "Demo":
        base = _build_demo_prices()
        overrides = _config_overrides_ui("engine_demo")
        payload = {
            "timeIndex": [dt.isoformat() for dt in base["timeIndex"]],
            "pricesWide": base["pricesWide"],
            "pairs": base["pairs"],
            "configOverrides": overrides,
        }
        with st.expander("ğŸ” Preview payload (Demo + overrides)", expanded=False):
            st.json(payload)
        _payload_download_ui(payload, "â¬‡ï¸ ×”×•×¨×“ Engine payload (Demo)", "engine_demo")

    elif dataset_mode == "Upload CSV":
        uploaded = st.file_uploader(
            "×”×¢×œ×” ×§×•×‘×¥ ××—×™×¨×™× ×‘×¤×•×¨××˜ CSV (Date + ×˜×™×§×¨×™×):",
            type=["csv"],
            key="fv_engine_csv",
        )
        if uploaded is not None:
            base = _build_from_csv(uploaded, key_prefix="engine_csv")
            if base is not None:
                overrides = _config_overrides_ui("engine_csv")
                payload = {
                    "timeIndex": [dt.isoformat() for dt in base["timeIndex"]],
                    "pricesWide": base["pricesWide"],
                    "pairs": base["pairs"],
                    "configOverrides": overrides,
                }
                with st.expander("ğŸ” Preview payload (CSV + overrides)", expanded=False):
                    st.json(payload)
                _payload_download_ui(payload, "â¬‡ï¸ ×”×•×¨×“ Engine payload (CSV)", "engine_csv")
        else:
            st.info("×”×¢×œ×” ×§×•×‘×¥ CSV ×›×“×™ ×œ×‘× ×•×ª payload.")

    elif dataset_mode == "Load saved JSON":
        payload = _payload_upload_json_ui("engine_load")
    else:  # Raw JSON
        raw = st.text_area(
            "Engine request JSON (timeIndex, pricesWide, pairs, configOverrides)",
            value=json.dumps(
                {
                    "timeIndex": [],
                    "pricesWide": {},
                    "pairs": [],
                    "configOverrides": {},
                },
                indent=2,
                default=str,
            ),
            height=260,
            key="fv_engine_raw_json",
        )
        try:
            payload = json.loads(raw)
        except Exception:
            st.error("JSON ×œ× ×ª×§×™×Ÿ, ×ª×§×Ÿ ×œ×¤× ×™ ×©×œ×™×—×”.")
            payload = None

    if payload is None:
        st.info("××™×Ÿ payload ×œ×˜××‘ Fair Value (×œ× × ×©×œ×— ×–×•×’/Universe ××”×˜××‘×™× ×”××—×¨×™×). "
                "××¤×©×¨ ×œ×‘×—×•×¨ ×–×•×’/Universe ××ª×•×š ×”-UI ×©×œ ×”×˜××‘.")
        return  # ×©×•×‘, return ×‘××§×•× st.stop()


    if st.button("ğŸš€ ×”×¨×¥ /engine/run", type="primary", key="fv_engine_send"):
        with st.spinner("××¨×™×¥ ××ª FairValueEngine ×“×¨×š ×”-API..."):
            try:
                data = _post_json("/engine/run", payload)
            except Exception as e:
                st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”-API: {e}")
                return

        st.success("Engine ×”×—×–×™×¨ ×ª×©×•×‘×”.")

        meta = data.get("meta", {})
        rows = data.get("rows", [])

        col_meta1, col_meta2, col_meta3 = st.columns(3)
        with col_meta1:
            st.markdown("**Meta**")
            st.json(meta)
        with col_meta2:
            st.metric("××¡×¤×¨ ×–×•×’×•×ª", len(rows))
        with col_meta3:
            st.caption("×”× ×ª×•× ×™× ××˜×•×¤×œ×™× ×‘×¦×“ ×”-Engine, ×–×” ×¨×§ UI ×œ×§×¨×™××”.")

        if not rows:
            st.info("×œ× ×—×–×¨×• rows ××”-Engine.")
            return

        _normalize_pair_field(rows)
        df = pd.DataFrame(rows)

        st.markdown("### ğŸ“‹ ×ª×•×¦××•×ª ×’×•×œ××™×•×ª")
        st.dataframe(df, use_container_width=True)

        st.markdown("### ğŸ“Š × ×™×ª×•×— ××”×™×¨ ×©×œ universe")

        metrics_cols = st.multiselect(
            "×‘×—×¨ ×¢××•×“×•×ª ××™×›×•×ª/×¡×™×›×•×Ÿ ×œ×”×¦×’×” ×›×’×¨×¤×™×:",
            options=[c for c in df.columns if c in ["dsr_net", "psr_net", "sr_net", "net_edge_z", "turnover_est", "avg_hold_days"]],
            default=[c for c in ["dsr_net", "net_edge_z"] if c in df.columns],
            key="fv_engine_metric_cols",
        )

        col_kpi1, col_kpi2, col_kpi3 = st.columns(3)
        with col_kpi1:
            st.metric("Pairs count", len(df))
        with col_kpi2:
            if "dsr_net" in df.columns:
                frac_good = float((df["dsr_net"] > 0).mean() * 100.0)
                st.metric("% ×¢× DSR>0", f"{frac_good:.1f}%")
            elif "sr_net" in df.columns:
                frac_good = float((df["sr_net"] > 0).mean() * 100.0)
                st.metric("% ×¢× Sharpe>0", f"{frac_good:.1f}%")
            else:
                st.metric("% pairs with edge>0", "N/A")
        with col_kpi3:
            if "rp_weight" in df.columns:
                w = df["rp_weight"].abs().fillna(0.0)
                s = float(w.sum()) or 1.0
                top5 = float(w.sort_values(ascending=False).head(5).sum() / s * 100)
                st.metric("×¨×™×›×•×– Top-5", f"{top5:.1f}%")
            else:
                st.metric("×¨×™×›×•×– Top-5", "N/A")

        if metrics_cols:
            target_metric = st.selectbox(
                "××“×“ ×¢×™×§×¨×™ ×œ× ×™×ª×•×—:",
                options=metrics_cols,
                index=0,
                key="fv_engine_target_metric",
            )
            st.markdown(f"#### ×”×ª×¤×œ×’×•×ª {target_metric}")
            fig = px.histogram(df, x=target_metric, nbins=30)
            st.plotly_chart(fig, use_container_width=True)

            st.markdown(f"#### Top pairs ×œ×¤×™ {target_metric}")
            top_n = st.slider("×›××” ×–×•×’×•×ª ×œ×”×¦×™×’ (Top-N):", min_value=5, max_value=50, value=15, step=5, key="fv_engine_top_n")
            df_top = df.sort_values(by=target_metric, ascending=False).head(top_n)
            st.dataframe(df_top, use_container_width=True)
        else:
            st.info("×‘×—×¨ ×œ×¤×—×•×ª ××“×“ ××—×“ ×›×“×™ ×œ×¨××•×ª ×’×¨×¤×™× ×•-Top pairs.")


# =====================================
#  Advisor Section (×¢× ×”×©×•×•××ª ×¨×™×¦×•×ª)
# =====================================

def _init_advisor_run_store() -> None:
    """
    ××•×•×“× ×©×™×© ××§×•× ×‘×”×™×¡×˜×•×¨×™×” ×©×œ ×¨×™×¦×•×ª Advisor ×‘-session_state.
    """
    if "fv_advisor_runs" not in st.session_state:
        st.session_state["fv_advisor_runs"] = []  # list of dicts


def _store_advisor_run(summary: Dict[str, Any], advice: List[Dict[str, Any]], payload: Dict[str, Any]) -> None:
    """
    ×©×•××¨ ×¨×™×¦×” ××—×ª ×©×œ Advisor ×œ×”×™×¡×˜×•×¨×™×” (×¢×“ 10 ×¨×™×¦×•×ª ××—×¨×•× ×•×ª).
    """
    _init_advisor_run_store()
    runs: List[Dict[str, Any]] = st.session_state["fv_advisor_runs"]

    run_id = f"run_{len(runs) + 1}"
    entry = {
        "id": run_id,
        "timestamp": datetime.utcnow().isoformat(),
        "summary": summary,
        "advice": advice,
        "payload": payload,
    }
    runs.append(entry)
    if len(runs) > 10:
        del runs[0]
    st.session_state["fv_advisor_runs"] = runs


def _render_advisor_compare_ui() -> None:
    """
    ×××¤×©×¨ ×œ×‘×—×•×¨ ×©×ª×™ ×¨×™×¦×•×ª Advisor ×•×œ×”×©×•×•×ª ×‘×™× ×™×”×Ÿ:
    - KPIs ××¨×›×–×™×™×
    - ×”×‘×“×œ ×‘×¢×¦×•×ª (IDs ×©× ×•×¡×¤×•/× ×¢×œ××•)
    """
    _init_advisor_run_store()
    runs: List[Dict[str, Any]] = st.session_state["fv_advisor_runs"]

    if len(runs) < 2:
        st.info("×›×“×™ ×œ×”×©×•×•×ª ×¨×™×¦×•×ª ×¦×¨×™×š ×œ×¤×—×•×ª 2 ×¨×™×¦×•×ª Advisor. ×ª×¨×™×¥ ×›××” ×¤×¢××™× ×¢× ×¤×¨××˜×¨×™× ×©×•× ×™×.")
        return

    st.markdown("### ğŸ” ×”×©×•×•××ª ×¨×™×¦×•×ª Advisor")

    options = [f"{r['id']} â€” {r['timestamp']}" for r in runs]
    col_a, col_b = st.columns(2)
    with col_a:
        sel_a = st.selectbox("×¨×™×¦×” A:", options=options, index=len(options) - 2, key="fv_adv_cmp_a")
    with col_b:
        sel_b = st.selectbox("×¨×™×¦×” B:", options=options, index=len(options) - 1, key="fv_adv_cmp_b")

    if sel_a == sel_b:
        st.warning("×‘×—×¨ ×©×ª×™ ×¨×™×¦×•×ª ×©×•× ×•×ª ×œ×”×©×•×•××”.")
        return

    run_a = runs[options.index(sel_a)]
    run_b = runs[options.index(sel_b)]

    sum_a = run_a["summary"]
    sum_b = run_b["summary"]

    st.markdown("#### KPIs ×¢×™×§×¨×™×™× (A vs B)")
    kpi_keys = [
        ("n_pairs", "××¡×¤×¨ ×–×•×’×•×ª"),
        ("frac_good_pairs", "% ×–×•×’×•×ª ×¢× edge>0"),
        ("concentration_top5_pct", "×¨×™×›×•×– Top-5"),
        ("avg_halflife", "Halflife ×××•×¦×¢"),
        ("avg_turnover_est", "Turnover ×××•×¦×¢"),
        ("avg_edge_z", "Edge ×××•×¦×¢ (net_edge_z)"),
    ]

    for key, label in kpi_keys:
        col1, col2, col3 = st.columns([2, 2, 1])
        with col1:
            st.markdown(f"**{label} â€” A**")
            st.write(sum_a.get(key))
        with col2:
            st.markdown(f"**{label} â€” B**")
            st.write(sum_b.get(key))
        with col3:
            try:
                va = float(sum_a.get(key)) if sum_a.get(key) is not None else None
                vb = float(sum_b.get(key)) if sum_b.get(key) is not None else None
                if va is not None and vb is not None:
                    diff = vb - va
                    st.write(f"Î” {diff:+.3f}")
                else:
                    st.write("Î” N/A")
            except Exception:
                st.write("Î” N/A")

    st.markdown("#### ×©×™× ×•×™ ×‘×¢×¦×•×ª (Advice delta)")

    ids_a = {a["id"] for a in run_a["advice"]}
    ids_b = {b["id"] for b in run_b["advice"]}

    added = ids_b - ids_a
    removed = ids_a - ids_b
    unchanged = ids_a & ids_b

    col_add, col_rem, col_same = st.columns(3)
    with col_add:
        st.markdown("**×¢×¦×•×ª ×—×“×©×•×ª (×‘-B ×•×œ× ×‘-A):**")
        if not added:
            st.write("××™×Ÿ.")
        else:
            for adv_id in sorted(added):
                st.write(f"- {adv_id}")
    with col_rem:
        st.markdown("**×¢×¦×•×ª ×©× ×¢×œ××• (×‘-A ×•×œ× ×‘-B):**")
        if not removed:
            st.write("××™×Ÿ.")
        else:
            for adv_id in sorted(removed):
                st.write(f"- {adv_id}")
    with col_same:
        st.markdown("**×¢×¦×•×ª ××©×•×ª×¤×•×ª:**")
        if not unchanged:
            st.write("××™×Ÿ.")
        else:
            for adv_id in sorted(unchanged):
                st.write(f"- {adv_id}")


def _render_advisor_section() -> None:
    st.subheader("ğŸ§  Advisor â€“ /advisor/run")

    st.caption("×”-Advisor ××¨×™×¥ ××ª ×”-Engine ×‘×¤× ×™×, ×× ×ª×— ××ª ×”-universe ×•× ×•×ª×Ÿ ×¢×¦×•×ª ×¤×¨××˜×¨×™×•×ª ×œ×©×™×¤×•×¨.")

    dataset_mode = st.radio(
        "××§×•×¨ ×“××˜×” ×œ-Advisor:",
        options=["Demo", "Upload CSV", "Raw JSON", "Load saved JSON"],
        horizontal=True,
        key="fv_advisor_dataset_mode",
    )

    payload: Optional[Dict[str, Any]] = None

    if dataset_mode == "Demo":
        base = _build_demo_prices()
        overrides = _config_overrides_ui("advisor_demo")
        payload = {
            "timeIndex": [dt.isoformat() for dt in base["timeIndex"]],
            "pricesWide": base["pricesWide"],
            "pairs": base["pairs"],
            "configOverrides": overrides,
        }
        with st.expander("ğŸ” Preview payload (Demo + overrides)", expanded=False):
            st.json(payload)
        _payload_download_ui(payload, "â¬‡ï¸ ×”×•×¨×“ Advisor payload (Demo)", "advisor_demo")

    elif dataset_mode == "Upload CSV":
        uploaded = st.file_uploader(
            "×”×¢×œ×” ×§×•×‘×¥ ××—×™×¨×™× ×‘×¤×•×¨××˜ CSV (Date + ×˜×™×§×¨×™×):",
            type=["csv"],
            key="fv_advisor_csv",
        )
        if uploaded is not None:
            base = _build_from_csv(uploaded, key_prefix="advisor_csv")
            if base is not None:
                overrides = _config_overrides_ui("advisor_csv")
                payload = {
                    "timeIndex": [dt.isoformat() for dt in base["timeIndex"]],
                    "pricesWide": base["pricesWide"],
                    "pairs": base["pairs"],
                    "configOverrides": overrides,
                }
                with st.expander("ğŸ” Preview payload (CSV + overrides)", expanded=False):
                    st.json(payload)
                _payload_download_ui(payload, "â¬‡ï¸ ×”×•×¨×“ Advisor payload (CSV)", "advisor_csv")
        else:
            st.info("×”×¢×œ×” ×§×•×‘×¥ CSV ×›×“×™ ×œ×‘× ×•×ª payload.")

    elif dataset_mode == "Load saved JSON":
        payload = _payload_upload_json_ui("advisor_load")
    else:
        raw = st.text_area(
            "Advisor request JSON (×›××• EngineRunRequest)",
            value=json.dumps(
                {
                    "timeIndex": [],
                    "pricesWide": {},
                    "pairs": [],
                    "configOverrides": {},
                },
                indent=2,
                default=str,
            ),
            height=260,
            key="fv_advisor_raw_json",
        )
        try:
            payload = json.loads(raw)
        except Exception:
            st.error("JSON ×œ× ×ª×§×™×Ÿ, ×ª×§×Ÿ ×œ×¤× ×™ ×©×œ×™×—×”.")
            payload = None

    if payload is None:
        st.info("××™×Ÿ payload ×œ×˜××‘ Fair Value (×œ× × ×©×œ×— ×–×•×’/Universe ××”×˜××‘×™× ×”××—×¨×™×). "
                "××¤×©×¨ ×œ×‘×—×•×¨ ×–×•×’/Universe ××ª×•×š ×”-UI ×©×œ ×”×˜××‘.")
        return  # ×©×•×‘, return ×‘××§×•× st.stop()

    if st.button("ğŸ§  ×”×¨×¥ /advisor/run", type="primary", key="fv_advisor_send"):
        with st.spinner("××¨×™×¥ Advisor (Engine + × ×™×ª×•×—) ×“×¨×š ×”-API..."):
            try:
                data = _post_json("/advisor/run", payload)
            except Exception as e:
                st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”-API: {e}")
                return

        st.success("Advisor ×”×—×–×™×¨ ×ª×©×•×‘×”.")

        summary = data.get("summary", {})
        advice = data.get("advice", [])

        _store_advisor_run(summary, advice, payload)

        st.markdown("### ğŸ“Š Summary â€” ×ª××•× ×ª ××¦×‘ ×©×œ ×”-universe")

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("××¡×¤×¨ ×–×•×’×•×ª", summary.get("n_pairs", 0))
        with col2:
            frac_good = summary.get("frac_good_pairs")
            st.metric("% ×–×•×’×•×ª ×¢× edge>0", f"{frac_good:.1f}%" if frac_good is not None else "N/A")
        with col3:
            c5 = summary.get("concentration_top5_pct")
            st.metric("×¨×™×›×•×– Top-5", f"{c5:.1f}%" if c5 is not None else "N/A")
        with col4:
            hl = summary.get("avg_halflife")
            st.metric("Halflife ×××•×¦×¢ (×™××™×)", f"{hl:.1f}" if hl is not None else "N/A")

        with st.expander("ğŸ” Summary full JSON", expanded=False):
            st.json(summary)

        st.markdown("### ğŸ“‹ ×¢×¦×•×ª ×œ×©×™×¤×•×¨ (Advisor)")

        if not advice:
            st.info("×”-Advisor ×œ× ×”×—×–×™×¨ ×¢×¦×•×ª. ×™×™×ª×›×Ÿ ×©×”-universe × ×¨××” ×¡×‘×™×¨ ×œ×¤×™ ×”×”×™×’×™×•×Ÿ ×”× ×•×›×—×™.")
        else:
            def _sev_emoji(sev: str) -> str:
                sev = (sev or "").lower()
                if sev == "critical":
                    return "ğŸ›‘"
                if sev == "warning":
                    return "âš ï¸"
                return "â„¹ï¸"

            for item in advice:
                sev = item.get("severity", "info")
                emoji = _sev_emoji(sev)
                header = f"{emoji} [{sev.upper()}] {item.get('category', '')} â€” {item.get('id', '')}"
                with st.expander(header, expanded=(sev in {"critical", "warning"})):
                    st.markdown(f"**Message:** {item.get('message','')}")
                    st.markdown(f"**Rationale:** {item.get('rationale','')}")
                    suggested = item.get("suggested_changes", {}) or {}
                    if suggested:
                        st.markdown("**Suggested changes:**")
                        for k, v in suggested.items():
                            st.markdown(f"- **{k}**: {v}")

    # ×‘×œ×•×§ ×”×©×•×•××ª ×¨×™×¦×•×ª
    with st.expander("ğŸ” ×”×©×•×•××ª ×¨×™×¦×•×ª Advisor (×œ×¤× ×™/××—×¨×™ ×©×™× ×•×™ ×¤×¨××˜×¨×™×)", expanded=False):
        _render_advisor_compare_ui()

def _render_fv_local_single_opt_section() -> None:
    """
    ××¨×™×¥ api_optimize_pair ×¢×œ ×–×•×’ ××—×“ ××ª×•×š ×”×§×•× ×˜×§×¡×˜ ×©×œ Fair Value,
    ×‘×œ×™ ×©×™××•×© ×‘-HTTP API, ××œ× ×™×©×™×¨×•×ª ×‘×× ×•×¢ ×”××•×¤×˜×™××™×–×¦×™×” ×”×¤× ×™××™.
    """
    st.markdown("### ğŸ”¬ Local Pairs Optimiser (Single Pair, HF-grade)")

    # × × ×¡×” ×œ×”×©×ª××© ×‘×–×•×’ ×©× ×‘×—×¨ ×‘-dashboard (×× ×™×©)
    sel_pair = st.session_state.get("selected_pair", "")
    default_sym1, default_sym2 = "SPY", "QQQ"

    if isinstance(sel_pair, str) and sel_pair:
        for sep in ("|", "/", "\\", ":", "-"):
            if sep in sel_pair:
                a, b = sel_pair.split(sep, 1)
                default_sym1, default_sym2 = a.strip(), b.strip()
                break

    col1, col2, col3 = st.columns([1.2, 1.2, 1.0])
    with col1:
        sym1 = st.text_input("Symbol A (local optimiser)", value=default_sym1, key="fv_loc_sym1")
    with col2:
        sym2 = st.text_input("Symbol B (local optimiser)", value=default_sym2, key="fv_loc_sym2")
    with col3:
        n_trials = st.number_input(
            "n_trials",
            min_value=20,
            max_value=1000,
            value=150,
            step=10,
            key="fv_loc_n_trials",
        )

    timeout_min = st.number_input(
        "Timeout (minutes)",
        min_value=1,
        max_value=60,
        value=10,
        step=1,
        key="fv_loc_timeout",
    )

    st.markdown("**Metric weights (local optimisation)**")
    cws1, cws2, cws3, cws4 = st.columns(4)
    with cws1:
        w_sh = cws1.number_input("W Sharpe", 0.0, 1.0, 0.3, 0.05, key="fv_loc_w_sharpe")
    with cws2:
        w_pf = cws2.number_input("W Profit", 0.0, 1.0, 0.4, 0.05, key="fv_loc_w_profit")
    with cws3:
        w_dd = cws3.number_input("W Drawdown", 0.0, 1.0, 0.2, 0.05, key="fv_loc_w_dd")
    with cws4:
        w_sr = cws4.number_input("W Sortino", 0.0, 1.0, 0.1, 0.05, key="fv_loc_w_sortino")

    weights = {
        "Sharpe": float(w_sh),
        "Profit": float(w_pf),
        "Drawdown": float(w_dd),
        "Sortino": float(w_sr),
    }

    run_btn = st.button("ğŸš€ Run local optimisation for this pair", key="fv_loc_run_single")

    if not run_btn:
        return

    with st.spinner(f"Optimising {sym1}-{sym2} via api_optimize_pairâ€¦"):
        df_res, meta = api_optimize_pair(
            sym1,
            sym2,
            ranges=None,     # ×›×¨×’×¢ × ×•×ª× ×™× ×œ×• ×œ×‘× ×•×ª ×œ×¤×™ profile ×“×™×¤×•×œ×˜
            weights=weights,
            n_trials=int(n_trials),
            timeout_min=int(timeout_min),
            direction="maximize",
            sampler_name="TPE",
            pruner_name="median",
            profile="default",
            multi_objective=False,
            objective_metrics=None,
            param_mapping=None,
        )

    st.markdown("#### ğŸ§¾ Meta (local optimiser)")
    st.json(meta)

    if df_res is None or df_res.empty:
        st.warning("Local optimisation produced no rows for this pair.")
        return

    st.markdown("#### ğŸ… Top 10 configs (local optimiser)")
    top10 = df_res.copy()
    if "Score" in top10.columns:
        top10 = top10.sort_values("Score", ascending=False).head(10)
    else:
        top10 = top10.head(10)

    st.dataframe(top10, use_container_width=True)

    # ×©×•××¨×™× ×¡×™×›×•× ×œ-session ×œ×˜×•×‘×ª ×¡×•×›×Ÿ/×˜××‘ ××—×¨
    try:
        st.session_state.setdefault("fv_local_opt_single", {})
        st.session_state["fv_local_opt_single"][f"{sym1}-{sym2}"] = {
            "meta": meta,
            "top_params": top10.to_dict(orient="records"),
        }
    except Exception:
        pass


def _render_fv_local_batch_opt_section() -> None:
    """
    ××¨×™×¥ api_optimize_pairs_batch ×¢×œ ×¨×©×™××ª ×–×•×’×•×ª ××ª×•×š ×”-Fair Value Lab.
    """
    st.markdown("### ğŸ§ª Local Batch Optimiser (Pairs universe)")

    st.caption("×”×–×Ÿ ×¨×©×™××ª ×–×•×’×•×ª (××• ×”×©×ª××© ×‘×‘×¨×™×¨×ª ××—×“×œ) ×œ×”×¨×¦×ª ××•×¤×˜×™××™×–×¦×™×” ×¤× ×™××™×ª ×¢×œ ×›××” pairs ×‘×™×—×“.")

    default_pairs_list = st.session_state.get("fv_universe_pairs", ["SPY-QQQ", "SPY-IWM"])
    default_text = "\n".join(default_pairs_list)

    pairs_text = st.text_area(
        "Pairs (one per line, format: SYM1-SYM2)",
        value=default_text,
        key="fv_loc_batch_pairs_text",
    )

    pairs: List[Tuple[str, str]] = []
    for ln in pairs_text.splitlines():
        ln = ln.strip()
        if not ln:
            continue
        sep_used = None
        for sep in ("|", "/", "\\", ":", "-"):
            if sep in ln:
                sep_used = sep
                break
        if not sep_used:
            continue
        a, b = ln.split(sep_used, 1)
        a, b = a.strip(), b.strip()
        if a and b:
            pairs.append((a, b))

    if not pairs:
        st.info("Add at least one pair to run batch optimisation.")
        return

    st.write("Pairs to optimise:", ", ".join([f"{a}-{b}" for a, b in pairs]))

    n_trials = st.number_input(
        "n_trials per pair",
        min_value=20,
        max_value=1000,
        value=80,
        step=10,
        key="fv_loc_batch_n_trials",
    )
    timeout_min = st.number_input(
        "Timeout per pair (minutes)",
        min_value=1,
        max_value=60,
        value=6,
        step=1,
        key="fv_loc_batch_timeout",
    )

    run_batch_btn = st.button("ğŸš€ Run local batch optimisation", key="fv_loc_batch_run")

    if not run_batch_btn:
        return

    with st.spinner(f"Running local batch optimisation for {len(pairs)} pairsâ€¦"):
        df_batch, meta_batch = api_optimize_pairs_batch(
            pairs,
            ranges=None,
            weights=None,     # ×”-API ×›×‘×¨ ××˜×¤×œ ×‘-fallbacks ×—×›××™×
            n_trials=int(n_trials),
            timeout_min=int(timeout_min),
            direction="maximize",
            sampler_name="TPE",
            pruner_name="median",
            profile="default",
            multi_objective=False,
            objective_metrics=None,
            param_mapping=None,
        )

    st.markdown("#### ğŸ§¾ Batch meta (local optimiser)")
    st.json(
        {
            "status": meta_batch.get("status"),
            "duration_sec": meta_batch.get("duration_sec"),
            "n_pairs": meta_batch.get("n_pairs"),
        }
    )

    if df_batch is None or df_batch.empty:
        st.warning("Batch optimisation produced no rows.")
        return

    per_pair = meta_batch.get("per_pair", {})
    summary_rows = []
    for label, info in per_pair.items():
        summary_rows.append(
            {
                "Pair": label,
                "Best Score": info.get("best_score"),
                "Best Sharpe": info.get("best_sharpe"),
                "Rows": info.get("rows"),
            }
        )
    if summary_rows:
        df_summary = pd.DataFrame(summary_rows)
        st.markdown("#### ğŸ“Š Per-pair summary (local optimiser)")
        st.dataframe(df_summary, use_container_width=True)

    st.markdown("#### ğŸ” Full batch df (top 200 rows)")
    st.dataframe(df_batch.head(200), use_container_width=True)

    # ×©××™×¨×” ×œ-session ×œ×©×™××•×© ×¢×ª×™×“×™
    st.session_state["fv_local_batch_opt_df"] = df_batch
    st.session_state["fv_local_batch_opt_meta"] = meta_batch

# =====================================
#  Optimizer Section
# =====================================

def _render_optimizer_section() -> None:
    st.subheader("ğŸ§¬ Optimizer â€“ /optimizer/run")

    # ----- Local HF-grade optimiser using internal engine -----
    with st.expander("ğŸ”¬ Local Pairs Optimiser (internal engine)", expanded=False):
        _render_fv_local_single_opt_section()

    with st.expander("ğŸ§ª Local Batch Optimiser (internal engine)", expanded=False):
        _render_fv_local_batch_opt_section()

    st.markdown("---")
    st.markdown("### ğŸŒ Remote Optimizer API â€“ /optimizer/run")

    mode = st.radio(
        "××§×•×¨ ×“××˜×” ×œ-Optimizer:",
        options=["Demo", "Upload CSV", "Raw JSON", "Load saved JSON"],
        horizontal=True,
        key="fv_opt_dataset_mode",
    )

    payload: Optional[Dict[str, Any]] = None

    if mode == "Demo":
        base = _build_demo_prices()
        st.markdown("#### âš™ï¸ OptConfig (Demo)")
        col1, col2, col3 = st.columns(3)
        with col1:
            n_trials = st.number_input(
                "n_trials",
                min_value=5,
                max_value=500,
                value=20,
                step=5,
                key="fv_opt_demo_n_trials",
            )
            timeout_sec = st.number_input(
                "timeout_sec",
                min_value=5,
                max_value=600,
                value=60,
                step=5,
                key="fv_opt_demo_timeout",
            )
        with col2:
            target = st.selectbox(
                "target",
                options=["dsr_net", "psr_net", "sr_net"],
                index=0,
                key="fv_opt_demo_target",
            )
            use_ensemble = st.checkbox(
                "use_ensemble",
                value=False,
                key="fv_opt_demo_use_ensemble",
            )
        with col3:
            n_folds = st.number_input(
                "n_folds",
                min_value=2,
                max_value=10,
                value=3,
                step=1,
                key="fv_opt_demo_n_folds",
            )
            test_frac = st.slider(
                "test_frac",
                min_value=0.05,
                max_value=0.5,
                value=0.2,
                step=0.05,
                key="fv_opt_demo_test_frac",
            )

        opt_config = {
            "n_trials": int(n_trials),
            "timeout_sec": int(timeout_sec),
            "sampler": "tpe",
            "seed": 42,
            "pruner": "median",
            "target": target,
            "use_ensemble": bool(use_ensemble),
            "agg": "median",
            "trim_alpha": 0.1,
            "penalty_turnover": 0.0,
            "min_avg_hold": 0.0,
            "n_folds": int(n_folds),
            "test_frac": float(test_frac),
            "purge_frac": 0.02,
        }

        payload = {
            "timeIndex": [dt.isoformat() for dt in base["timeIndex"]],
            "pricesWide": base["pricesWide"],
            "pairs": base["pairs"],
            "optConfig": opt_config,
        }

        with st.expander("ğŸ” Preview payload (Demo OptConfig)", expanded=False):
            st.json(payload)
        _payload_download_ui(payload, "â¬‡ï¸ ×”×•×¨×“ Optimizer payload (Demo)", "opt_demo")

    elif mode == "Upload CSV":
        uploaded = st.file_uploader(
            "×”×¢×œ×” ×§×•×‘×¥ CSV (Date + ×˜×™×§×¨×™×):",
            type=["csv"],
            key="fv_opt_csv",
        )
        if uploaded is not None:
            base = _build_from_csv(uploaded, key_prefix="opt_csv")
            if base is not None:
                st.markdown("#### âš™ï¸ OptConfig (CSV)")
                col1, col2 = st.columns(2)
                with col1:
                    n_trials = st.number_input(
                        "n_trials",
                        min_value=5,
                        max_value=500,
                        value=30,
                        step=5,
                        key="fv_opt_csv_n_trials",
                    )
                with col2:
                    target = st.selectbox(
                        "target",
                        options=["dsr_net", "psr_net", "sr_net"],
                        index=0,
                        key="fv_opt_csv_target",
                    )

                opt_config = {
                    "n_trials": int(n_trials),
                    "target": target,
                }

                payload = {
                    "timeIndex": [dt.isoformat() for dt in base["timeIndex"]],
                    "pricesWide": base["pricesWide"],
                    "pairs": base["pairs"],
                    "optConfig": opt_config,
                }
                with st.expander("ğŸ” Preview payload (CSV OptConfig)", expanded=False):
                    st.json(payload)
                _payload_download_ui(payload, "â¬‡ï¸ ×”×•×¨×“ Optimizer payload (CSV)", "opt_csv")
        else:
            st.info("×”×¢×œ×” CSV ×›×“×™ ×œ×”×¨×™×¥ ××•×¤×˜×™××™×–×¦×™×”.")
    elif mode == "Load saved JSON":
        payload = _payload_upload_json_ui("opt_load")
    else:
        raw = st.text_area(
            "Optimizer request JSON (timeIndex, pricesWide, pairs, optConfig, ...)",
            value=json.dumps(
                {
                    "timeIndex": [],
                    "pricesWide": {},
                    "pairs": [],
                    "optConfig": {
                        "n_trials": 10,
                        "target": "dsr_net",
                    },
                },
                indent=2,
                default=str,
            ),
            height=260,
            key="fv_opt_raw_json",
        )
        try:
            payload = json.loads(raw)
        except Exception:
            st.error("JSON ×œ× ×ª×§×™×Ÿ, ×ª×§×Ÿ ×œ×¤× ×™ ×©×œ×™×—×”.")
            payload = None

    if payload is None:
        st.info("××™×Ÿ payload ×œ×˜××‘ Fair Value (×œ× × ×©×œ×— ×–×•×’/Universe ××”×˜××‘×™× ×”××—×¨×™×). "
                "××¤×©×¨ ×œ×‘×—×•×¨ ×–×•×’/Universe ××ª×•×š ×”-UI ×©×œ ×”×˜××‘.")
        return  # ×©×•×‘, return ×‘××§×•× st.stop()

    if st.button("ğŸš€ ×”×¨×¥ /optimizer/run", type="primary", key="fv_opt_send"):
        with st.spinner("××¨×™×¥ optimize_fair_value ×“×¨×š ×”-API..."):
            try:
                data = _post_json("/optimizer/run", payload)
            except Exception as e:
                st.error(f"×©×’×™××” ×‘×§×¨×™××ª ×”-API: {e}")
                return

        st.success("Optimizer ×”×—×–×™×¨ ×ª×©×•×‘×”.")

        st.markdown("### ğŸ† ×ª×•×¦××•×ª ××•×¤×˜×™××™×–×¦×™×”")
        st.json(data)

        best_params = data.get("bestParams") or {}
        if best_params:
            st.markdown("#### ğŸ“‹ bestParams ×›×˜×‘×œ×”")
            df_params = pd.DataFrame(
                [{"param": k, "value": v} for k, v in best_params.items()]
            )
            st.dataframe(df_params, use_container_width=True)


# =====================================
#  Entry point for dashboard
# =====================================

def render_fair_value_api_tab() -> None:
    """
    ×˜××‘ ××‘×•×“×“ â€“ ×œ× × ×•×’×¢ ×‘×©×•× State ×’×œ×•×‘×œ×™ ×©×œ ×”×“×©×‘×•×¨×“.
    ××™×•×¢×“ ×œ×‘×“×™×§×”/××©×—×§ ×¢× Fair Value API ×‘×œ×‘×“.
    """
    st.markdown("## ğŸ§¬ Fair Value API Lab â€” Sandbox ××‘×•×“×“")
    st.caption(
        "×”×˜××‘ ×”×–×” ×¢×•×‘×“ ×¨×§ ××•×œ ×”-API ×”××§×•××™ (root/api_server.py) ×“×¨×š HTTP. "
        "×”×•× ×œ× ××©× ×” ×©×•× ×“×‘×¨ ×‘×§×•× ×¤×™×’, ×“××˜×” ××• ×˜×‘×œ××•×ª ××—×¨×•×ª."
    )

    cfg = _get_fair_value_config()
    current_base = _resolve_api_base()

    st.write(f"**API base:** `{current_base}`")

    if cfg is not None:
        col_cfg1, col_cfg2 = st.columns(2)
        with col_cfg1:
            st.markdown("**FairValueAPIConfig**")
            st.write(f"Profile: `{getattr(cfg, 'profile', 'unknown')}`")
            st.write(f"Enabled: `{getattr(cfg, 'is_enabled', getattr(cfg, 'enabled', False))}`")
            st.write(f"Connect timeout: `{getattr(cfg, 'connect_timeout_sec', None)}` sec")
            st.write(f"Read timeout: `{getattr(cfg, 'read_timeout_sec', None)}` sec")
        with col_cfg2:
            st.markdown("**Rate & Logging**")
            st.write(f"Max concurrent requests: `{getattr(cfg, 'max_concurrent_requests', None)}`")
            st.write(f"Max requests/minute: `{getattr(cfg, 'max_requests_per_minute', None)}`")
            st.write(f"log_requests: `{getattr(cfg, 'log_requests', None)}`")
            st.write(f"log_payloads: `{getattr(cfg, 'log_payloads', None)}`")
    else:
        st.info(
            "×œ× × ××¦× FairValueAPIConfig ×¤×¢×™×œ ×‘×§×•× ×˜×§×¡×˜. "
            "×”×˜××‘ ××©×ª××© ×‘-FAIR_VALUE_API_URL (secrets) ××• ×‘×‘×¨×™×¨×ª ××—×“×œ ×œ×•×§××œ×™×ª."
        )

    ok, health = _check_health()
    col_h1, col_h2 = st.columns(2)
    with col_h1:
        if ok:
            st.success("API Online âœ…")
        else:
            st.error("API Offline âŒ â€” ×•×“× ×©-uvicorn ×©×œ api_server.py ×¨×¥.")
    with col_h2:
        st.markdown("**/health response:**")
        st.json(health)

    mode = st.radio(
        "×‘×—×¨ ××¦×‘ ×¢×‘×•×“×”:",
        options=["âš™ï¸ Engine", "ğŸ§  Advisor", "ğŸ§¬ Optimizer"],
        horizontal=True,
        key="fv_mode",
    )

    if mode.startswith("âš™ï¸"):
        _render_engine_section()
    elif mode.startswith("ğŸ§ "):
        _render_advisor_section()
    else:
        _render_optimizer_section()


__all__ = ["render_fair_value_api_tab"]
