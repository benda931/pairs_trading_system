#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
hedge_fund_upgrade_agent.py
===========================

×¡×•×›×Ÿ GPT ×œ×©×“×¨×•×’ ××¢×¨×›×ª pairs-trading ×œ×¨××ª ×§×¨×Ÿ ×’×™×“×•×¨, ×›×•×œ×œ:

- ×¡×¨×™×§×” ××œ××” ×©×œ ×›×œ ×”×ª×§×™×™×” (×§×‘×¦×™ Python)
- ×‘× ×™×™×ª ×ª×•×›× ×™×ª ×©×“×¨×•×’ (phases) + ×˜××¡×§×™× ×œ×›×œ ×§×•×‘×¥
- ×©×“×¨×•×’ ×§×‘×¦×™× ×‘×•×“×“×™× ××• ×›×œ ×”×¤×¨×•×™×§×˜ ×‘×¢×–×¨×ª OpenAI Responses API
- ×’×™×‘×•×™×™× ××•×˜×•××˜×™×™× ×œ×›×œ ×§×•×‘×¥ ×œ×¤× ×™ ×›×ª×™×‘×”

×©×™××•×© ×‘×¡×™×¡×™:

    # 0. ×”×ª×§× ×ª ×—×‘×™×œ×” ×•×”×’×“×¨×ª ××¤×ª×—
    pip install openai
    export OPENAI_API_KEY="sk-..."

    # 1. ×™×¦×™×¨×ª ×ª×•×›× ×™×ª ×©×“×¨×•×’ + ×˜××¡×§×™× ×œ×›×œ ×§×•×‘×¥
    python hedge_fund_upgrade_agent.py plan --root .

    # 2. ×©×“×¨×•×’ ×§×•×‘×¥ ×¡×¤×¦×™×¤×™ ×œ×¤×™ ×”×˜××¡×§×™× ××”×ª×•×›× ×™×ª
    python hedge_fund_upgrade_agent.py upgrade-file \
        --root . \
        --file core/sql_store.py \
        --apply

    # 3. ×©×“×¨×•×’ ×›×œ ×”×§×‘×¦×™× ×œ×¤×™ ×”×ª×•×›× ×™×ª (×‘×”×ª×—×œ×” ×‘×œ×™ --apply, ×›×“×™ ×œ×¨××•×ª)
    python hedge_fund_upgrade_agent.py upgrade-all --root .
    python hedge_fund_upgrade_agent.py upgrade-all --root . --apply
"""

from __future__ import annotations

import argparse
import json
import os
import re
import textwrap
from dataclasses import dataclass, asdict
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional

from dotenv import load_dotenv
from openai import OpenAI  # pip install openai

# ×œ×˜×¢×•×Ÿ ××ª ×§×•×‘×¥ .env ×›×“×™ ×©×”-OPENAI_API_KEY ×™×™×›× ×¡ ×œ-Environment
PROJECT_ROOT = Path(__file__).resolve().parent
load_dotenv(PROJECT_ROOT / ".env")  # ğŸ‘ˆ ×›××Ÿ ×”×•× ×§×•×¨× ××ª .env ×©×œ×š


OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise RuntimeError(
        "OPENAI_API_KEY is not set. Make sure you have a .env file with 'OPENAI_API_KEY=sk-...' "
        "in the project root or set the environment variable."
    )

# ======================================================================
# ×§×•× ×¤×™×’×•×¨×¦×™×” ×›×œ×œ×™×ª
# ======================================================================

# ××•×“×œ ×‘×¨×™×¨×ª ××—×“×œ â€“ ××¤×©×¨ ×œ×©× ×•×ª ×œ-gpt-5, gpt-4.1 ×•×›×Ÿ ×”×œ××”
DEFAULT_MODEL = os.getenv("HEDGE_FUND_UPGRADER_MODEL", "gpt-5.1")
# ×¨××ª reasoning ×œ××•×“×œ×™× ×ª×•××›×™× (gpt-5 / gpt-5.1)
DEFAULT_REASONING = os.getenv("HEDGE_FUND_UPGRADER_REASONING", "medium")  # none/low/medium/high

# ×§×•×‘×¥ ×¤×¨×•××˜ ×××¡×˜×¨ (×× ×™×© ×œ×š ×›×‘×¨ "×¤×•×¨××˜ ×¤×¨×•××˜.txt")
DEFAULT_MASTER_PROMPT = Path("×¤×¨×•××˜×™×") / "×¤×•×¨××˜ ×¤×¨×•××˜.txt"

# ×§×•×‘×¥ ×”×ª×•×›× ×™×ª (JSON) + ×’×¨×¡×ª Markdown ×× ×•×©×™×ª
DEFAULT_PLAN_JSON = "hedge_fund_upgrade_plan.json"
DEFAULT_PLAN_MD = "hedge_fund_upgrade_plan.md"

# ×ª×™×§×™×•×ª ×œ×”×ª×¢×œ× ××”×Ÿ ×‘×¡×¨×™×§×”
IGNORE_DIRS = {
    ".git",
    ".hg",
    ".svn",
    ".venv",
    ".mypy_cache",
    ".pytest_cache",
    "__pycache__",
    ".idea",
    ".vscode",
    "dist",
    "build",
    ".eggs",
}

# ======================================================================
# ××•×“×œ × ×ª×•× ×™×
# ======================================================================

@dataclass
class FileInfo:
    rel_path: str
    size_bytes: int
    n_lines: int
    header: str


@dataclass
class RepoSnapshot:
    root: Path
    files: List[FileInfo]


@dataclass
class FilePlan:
    """
    ×ª×™××•×¨ ×”-"×ª×¤×§×™×“" ×©×œ ×§×•×‘×¥ ×‘××¢×¨×›×ª + ×˜××¡×§×™× ×§×©×•×¨×™×.
    """
    rel_path: str
    role: str
    priority: str  # high / medium / low
    categories: List[str]
    tasks: List[str]
    phase_ids: List[str]


@dataclass
class Phase:
    id: str
    name: str
    order: int
    description: str
    milestones: List[str]


@dataclass
class UpgradePlan:
    project_root: str
    phases: List[Phase]
    files: List[FilePlan]


# ======================================================================
# Utilities
# ======================================================================

def debug(msg: str) -> None:
    print(f"[hedge-fund-upgrader] {msg}")


def load_text(path: Path) -> str:
    return path.read_text(encoding="utf-8")


def save_text(path: Path, content: str) -> None:
    path.write_text(content, encoding="utf-8")


def backup_file(path: Path) -> Path:
    """
    ×™×•×¦×¨ ×’×™×‘×•×™ ×œ×§×•×‘×¥ ×œ×¤× ×™ ×©×›×ª×‘×ª ×¢×œ×™×•.
    example: core/sql_store.py -> core/sql_store.py.gpt_backup
    """
    backup = path.with_suffix(path.suffix + ".gpt_backup")
    backup.write_text(path.read_text(encoding="utf-8"), encoding="utf-8")
    return backup


def extract_header_from_source(source: str) -> str:
    """
    ××—×œ×¥ ×©×•×¨×” "××ª××¨×ª" ×œ×§×•×‘×¥: docstring ××•×“×•×œ×¨×™ ××• ×”×¢×¨×”/×©×•×¨×” ×¨××©×•× ×”.
    """
    import ast

    header = ""
    try:
        mod = ast.parse(source)
        doc = ast.get_docstring(mod)
        if doc:
            header = doc.strip().splitlines()[0].strip()
    except Exception:
        header = ""

    if not header:
        for line in source.splitlines():
            stripped = line.strip()
            if not stripped:
                continue
            if stripped.startswith("#"):
                stripped = stripped.lstrip("#").strip()
            header = stripped
            break

    return header[:200]


def iter_python_files(root: Path) -> List[Path]:
    files: List[Path] = []
    for p in root.rglob("*.py"):
        if any(part in IGNORE_DIRS for part in p.parts):
            continue
        files.append(p)
    files.sort()
    return files


def scan_repo(root: Path) -> RepoSnapshot:
    root = root.resolve()
    file_infos: List[FileInfo] = []
    for p in iter_python_files(root):
        try:
            src = p.read_text(encoding="utf-8")
        except Exception:
            continue
        rel = str(p.relative_to(root))
        header = extract_header_from_source(src)
        size_bytes = len(src.encode("utf-8"))
        n_lines = src.count("\n") + 1
        file_infos.append(
            FileInfo(
                rel_path=rel,
                size_bytes=size_bytes,
                n_lines=n_lines,
                header=header,
            )
        )
    return RepoSnapshot(root=root, files=file_infos)


def build_repo_summary_text(snapshot: RepoSnapshot, max_files: int = 250) -> str:
    lines: List[str] = []
    lines.append(f"Project root: {snapshot.root}")
    lines.append("")
    lines.append("Python files overview (trimmed):")
    lines.append("")

    for i, info in enumerate(snapshot.files):
        prefix = f"{i+1:03d}. {info.rel_path}  (lines={info.n_lines}, bytes={info.size_bytes})"
        if info.header:
            prefix += f"  â€”  {info.header}"
        lines.append(prefix)
        if i + 1 >= max_files:
            remaining = len(snapshot.files) - max_files
            if remaining > 0:
                lines.append(f"... ({remaining} more files omitted from summary)")
            break

    return "\n".join(lines)


def extract_code_block_from_markdown(text: str) -> Optional[str]:
    """
    ××—×¤×© ××ª ×”×‘×œ×•×§ ×”×¨××©×•×Ÿ ×©×œ ```python ...``` ××• ``` ... ``` ×•××—×–×™×¨ ××ª ×”×§×•×“.
    ×¤×—×•×ª ×¨×’×™×© ×œ×‘×¢×™×•×ª ×‘×¤×•×¨××˜ (×•××¤×™×œ×• ××¡×ª×“×¨ ×× ××™×Ÿ ×¡×•×’×¨ ``` ×‘×¡×•×£).
    """
    # ×§×•×“× × × ×¡×” ×œ××¦×•× ```python
    start = text.find("```python")
    if start == -1:
        # ×× ××™×Ÿ, × × ×¡×” ×›×œ ``` ×¨××©×•×Ÿ
        start = text.find("```")
    if start == -1:
        return None

    # × ×–×•×– ×œ×©×•×¨×” ×©××—×¨×™ ×”-```...`
    newline_after = text.find("\n", start)
    if newline_after == -1:
        return None

    # × ×—×¤×© ××ª ×”-``` ×”×¡×•×’×¨ ××—×¨×™ ×ª×—×™×œ×ª ×”×§×•×“
    end = text.find("```", newline_after)
    if end == -1:
        # ×× ××™×Ÿ ×¡×•×’×¨, × ×™×§×— ×¢×“ ×¡×•×£ ×”×˜×§×¡×˜
        code = text[newline_after:].strip()
    else:
        code = text[newline_after:end].strip()

    return code or None


def apply_unified_diff(original: str, diff_text: str) -> str:
    """
    ××§×‘×œ ×ª×•×›×Ÿ ×§×•×‘×¥ ××§×•×¨×™ + unified diff (×›××• ××” ×©×”××•×“×œ ××—×–×™×¨ ×‘-```diff)
    ×•××—×–×™×¨ ××ª ×”×ª×•×›×Ÿ ×”×—×“×© ××—×¨×™ ×”×—×œ×ª ×”×“×™×¤.

    ×× ×™×— diff ×¢×‘×•×¨ ×§×•×‘×¥ ××—×“, ×‘×¤×•×¨××˜ @@ -l,s +l2,s2 @@ ...
    """
    orig_lines = original.splitlines(keepends=True)
    diff_lines = diff_text.splitlines(keepends=False)

    result: List[str] = []
    i = 0  # ××™× ×“×§×¡ ×‘×©×•×¨×•×ª ×”××§×•×¨
    idx = 0  # ××™× ×“×§×¡ ×‘×©×•×¨×•×ª ×”×“×™×¤

    def parse_hunk_header(line: str) -> Optional[tuple[int, int, int, int]]:
        # ×“×•×’××”: @@ -12,5 +12,7 @@ ...
        m = re.match(r"@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@", line)
        if not m:
            return None
        l1 = int(m.group(1))
        s1 = int(m.group(2) or "1")
        l2 = int(m.group(3))
        s2 = int(m.group(4) or "1")
        return l1, s1, l2, s2

    while idx < len(diff_lines):
        line = diff_lines[idx]
        # ×“×™×œ×•×’ ×¢×œ header×™× ×›×œ×œ×™×™×
        if line.startswith("diff ") or line.startswith("index "):
            idx += 1
            continue
        if line.startswith("--- ") or line.startswith("+++ "):
            idx += 1
            continue
        if line.startswith("@@"):
            hunk = parse_hunk_header(line)
            if not hunk:
                idx += 1
                continue
            old_start, old_count, new_start, new_count = hunk

            # ×œ×”×•×¡×™×£ ××ª ×›×œ ×”×©×•×¨×•×ª ×©×œ× ×©×™×™×›×•×ª ×œ-hunk ×”×–×” (unchanged prefix)
            target_index = old_start - 1  # 1-based -> 0-based
            while i < target_index and i < len(orig_lines):
                result.append(orig_lines[i])
                i += 1

            # ×œ×¢×‘×“ ××ª ×”-hunk
            idx += 1
            while idx < len(diff_lines) and not diff_lines[idx].startswith("@@"):
                l = diff_lines[idx]
                if not l:
                    idx += 1
                    continue
                tag = l[0]
                content = l[1:]
                if tag == " ":
                    # ×©×•×¨×” ×œ×œ× ×©×™× ×•×™ â€“ × ×œ×§×—×ª ××”××§×•×¨
                    if i < len(orig_lines):
                        result.append(orig_lines[i])
                        i += 1
                    else:
                        # fallback â€“ ××™×Ÿ ××¡×¤×™×§ ×©×•×¨×•×ª ××§×•×¨
                        result.append(content + "\n")
                elif tag == "-":
                    # ×©×•×¨×” ×©× ××—×§×” â€“ ××“×œ×’×™× ×¢×œ ×©×•×¨×ª ×”××§×•×¨
                    i += 1
                elif tag == "+":
                    # ×©×•×¨×” ×—×“×©×” â€“ ××•×¡×™×¤×™× ×œ-result
                    result.append(content + "\n")
                idx += 1
            continue

        # ×× ×œ× ×‘×ª×•×š hunk ×•×œ× header â€“ ××ª×§×“××™×
        idx += 1

    # ×œ×”×•×¡×™×£ ×›×œ ××” ×©× ×©××¨ ×‘×¡×•×£ ×”××§×•×¨
    while i < len(orig_lines):
        result.append(orig_lines[i])
        i += 1

    return "".join(result)


# ======================================================================
# OpenAI client wrapper
# ======================================================================

_client: Optional[OpenAI] = None


def get_client() -> OpenAI:
    global _client
    if _client is None:
        _client = OpenAI(api_key=OPENAI_API_KEY)
    return _client



def call_gpt_raw(
    *,
    model: str,
    instructions: str,
    user_input: str,
    reasoning_effort: Optional[str] = None,
    max_output_tokens: int = 8192,
) -> str:
    """
    ×§×¨×™××” ×‘×¡×™×¡×™×ª ×œ-Responses API, ××—×–×™×¨×” ×˜×§×¡×˜ ×—×•×¤×©×™ (output_text).
    """
    client = get_client()
    kwargs: Dict[str, Any] = {
        "model": model,
        "instructions": instructions,
        "input": user_input,
        "max_output_tokens": max_output_tokens,
    }
    if reasoning_effort:
        kwargs["reasoning"] = {"effort": reasoning_effort}

    resp = client.responses.create(**kwargs)
    # ×¡×¤×¨×™×™×ª Python ××¡×¤×§×ª output_text ×©××—×‘×¨ ××ª ×›×œ ×§×˜×¢×™ ×”×˜×§×¡×˜ ×™×—×“. :contentReference[oaicite:0]{index=0}
    return resp.output_text  # type: ignore[attr-defined]


def call_gpt_json(
    *,
    model: str,
    instructions: str,
    user_input: str,
    reasoning_effort: Optional[str] = None,
    max_output_tokens: int = 8192,
) -> Dict[str, Any]:
    """
    ××‘×§×© ××”××•×“×œ JSON ×‘×œ×‘×“ ×•×× ×¡×” ×œ×¤×¢× ×— ×œ-dict.
    ×× JSON ×œ× ×ª×§×™×Ÿ â€“ ×–×•×¨×§ ×—×¨×™×’×” ×¢× ×”×ª×©×•×‘×” ×”×’×•×œ××™×ª ×œ×§×‘×œ×ª debug.
    """
    text = call_gpt_raw(
        model=model,
        instructions=instructions,
        user_input=user_input,
        reasoning_effort=reasoning_effort,
        max_output_tokens=max_output_tokens,
    )
    text_stripped = text.strip()

    # ×œ×¤×¢××™× ×”××•×“×œ ××—×–×™×¨ JSON ×¢×˜×•×£ ×‘-```json ...```
    if text_stripped.startswith("```"):
        m = re.search(r"```json(.*?)(```)", text_stripped, flags=re.DOTALL | re.IGNORECASE)
        if not m:
            m = re.search(r"```(.*?)(```)", text_stripped, flags=re.DOTALL)
        if m:
            text_stripped = m.group(1).strip()

    try:
        return json.loads(text_stripped)
    except Exception as exc:
        raise RuntimeError(
            f"Failed to parse JSON from model. Error: {exc}\n\nRaw output:\n{text_stripped[:4000]}"
        )


def load_master_prompt(path: Path) -> str:
    """
    ×˜×•×¢×Ÿ ×§×•×‘×¥ ×¤×¨×•××˜ ×××¡×˜×¨ (system/developer message).
    ×× ×œ× ×§×™×™× â€“ ×™×—×–×™×¨ ×”× ×—×™×•×ª ×‘×¨×™×¨×ª ××—×“×œ ×©××ª××§×“×•×ª ×‘×©×“×¨×•×’ ×œ×¨××ª ×§×¨×Ÿ ×’×™×“×•×¨.
    """
    if path.is_file():
        return load_text(path)

    default = textwrap.dedent(
        """
        You are my senior quant + platform architect for a pairs-trading system
        that must be upgraded to **hedge-fund / live-trading quality**.

        Always optimize for:
        - Capital safety and risk controls
        - Deterministic behavior and reproducibility
        - Clean architecture (separation: data ingest / research / execution / web UI / infra)
        - Type hints, docstrings, logging, and error handling
        - Minimal but high-impact diff (avoid rewriting everything at once)
        """
    ).strip()
    return default


# ======================================================================
# Brief: ××” ×–×” "×¨××ª ×§×¨×Ÿ ×’×™×“×•×¨" ××‘×—×™× ×ª ×”××•×“×œ
# ======================================================================

HEDGE_FUND_BRIEF = """
Goal: Upgrade this pairs-trading project into a **hedge-fund-grade, live-trading Web application**.

Key dimensions:

1) Web / App Layer
   - Provide a single coherent user entry point (dashboard or web app).
   - Separate research UI from live trading & monitoring screens.
   - Make it easy to switch between environments: dev / research / paper / live.

2) Data Layer & Backfills
   - Robust ingestion from brokers and/or market data vendors (e.g. IBKR, Yahoo, etc.).
   - Centralized storage (SQL/Parquet/DuckDB/SQLite/Postgres) with explicit schemas and indices.
   - Clear policies for:
       * history length,
       * intraday vs end-of-day,
       * gaps detection and anomaly logging.

3) Signal & Portfolio Layer
   - Clean separation between:
       * signal generation (fair values, spreads, zâ€‘scores),
       * portfolio construction and sizing,
       * risk overlays (stop loss, max leverage, exposure constraints).
   - Same parameters and risk rules shared between backtest and live.

4) Execution / Broker Layer
   - Single broker abstraction with:
       * configuration for paper vs live,
       * retry/backoff and circuit breakers,
       * safe order construction, idempotent re-sends.
   - Clear distinction between:
       * desired position / target,
       * current fills / slippage / rejected orders.

5) Observability & Ops
   - Structured logs per component (ingest, signals, execution, web, background jobs).
   - Simple health endpoints or checks for all critical services.
   - Self-diagnostics for failing data sources, misaligned configs, or stuck positions.

6) Code Quality & Safety
   - Strong type hints, well named modules, minimal global state.
   - Avoid duplication and dead code; mark TODOs clearly.
   - Keep changes as small and localized as possible while moving toward the target architecture.
"""


# ======================================================================
# ×‘× ×™×™×ª ×¤×¨×•××¤×˜ ×œ×ª×•×›× ×™×ª ×©×“×¨×•×’ (plan)
# ======================================================================

def build_plan_prompt(snapshot: RepoSnapshot) -> str:
    summary = build_repo_summary_text(snapshot)
    return textwrap.dedent(
        f"""
        You are a senior quant + platform architect.

        {HEDGE_FUND_BRIEF}

        Below is a **snapshot** of the project, listing each Python file with a short header:

        ---
        {summary}
        ---

        TASK
        ====
        Design a **full upgrade plan** to move this project to hedge-fund-grade.

        The plan MUST be returned as **pure JSON**, with no markdown and no extra commentary.

        JSON SHAPE (STRICT)
        ====================
        {{
          "project_root": "string - informational only",
          "phases": [
            {{
              "id": "string - machine readable id, e.g. 'phase_architecture'",
              "name": "Human readable phase name",
              "order": 1,
              "description": "Short description of what this phase achieves",
              "milestones": ["bullet of key milestones"]
            }},
            ...
          ],
          "files": [
            {{
              "rel_path": "relative/path/to/file.py",
              "role": "short description of what this file should represent in a hedge-fund architecture",
              "priority": "high|medium|low",
              "categories": [
                "one or more of: 'web_ui', 'api', 'data_ingest', 'research', 'backtest', 'live_trading', 'risk', 'infra', 'utils', 'tests', 'other'"
              ],
              "tasks": [
                "Concrete todo item for this specific file, e.g. 'Convert ad-hoc DB calls to SqlStore abstraction'",
                "Another todo item ...",
                "3-8 items per important file; 1-3 items for low-priority helpers"
              ],
              "phase_ids": [
                "ids of phases where this file is primarily modified, e.g. ['phase_architecture', 'phase_live_trading']"
              ]
            }},
            ...
          ]
        }}

        RULES
        =====
        - Include **every** Python file listed in the snapshot in the "files" array.
        - For critical components (brokers, data ingest, sql store, risk, live trading, web/dashboard):
          * Assign priority="high".
          * Provide 4-10 specific, actionable tasks.
        - For smaller helpers or utilities, priority="low" with fewer tasks is ok.
        - Make phase ids and categories consistent and machine-friendly.
        - Do NOT use markdown. Return **valid JSON only**.
        """
    ).strip()

def build_phases_prompt(snapshot: RepoSnapshot) -> str:
    """
    ×¤×¨×•××¤×˜ ×©××‘×§×© ××”××•×“×œ ×œ×”×—×–×™×¨ *×¨×§* ××ª ×¨×©×™××ª ×”-phases (×‘×œ×™ files).
    """
    summary = build_repo_summary_text(snapshot, max_files=80)
    return textwrap.dedent(
        f"""
        You are a senior quant + platform architect.

        {HEDGE_FUND_BRIEF}

        Below is a snapshot of the project, listing key Python files:

        ---
        {summary}
        ---

        TASK
        ====
        Design the high-level upgrade phases to move this project to hedge-fund-grade.

        The output MUST be **pure JSON** of the form:

        {{
          "phases": [
            {{
              "id": "phase_architecture",
              "name": "Architecture & Environment Modes",
              "order": 1,
              "description": "Short 1-3 sentence description",
              "milestones": [
                "Short bullet milestone",
                "Another milestone"
              ]
            }},
            ...
          ]
        }}

        RULES
        =====
        - Keep 4â€“8 phases.
        - Keep descriptions and milestones concise.
        - Do NOT include any "files" array here.
        - Do NOT use markdown. Return valid JSON only.
        """
    ).strip()


def build_file_chunk_prompt(
    snapshot: RepoSnapshot,
    phases: List[Phase],
    files_chunk: List[FileInfo],
    chunk_index: int,
    total_chunks: int,
) -> str:
    """
    ×¤×¨×•××¤×˜ ×©××‘×§×© ××”××•×“×œ ×œ×”×—×–×™×¨ FilePlan ×¨×§ ×¢×‘×•×¨ ×§×‘×•×¦×ª ×§×‘×¦×™× ××—×ª (chunk).
    """
    # × ×¡×›× ×§×¦×ª ××ª ×”×©×•×¨×©, ××‘×œ × ×ª×¨×›×– ×‘×¨×©×™××ª ×”×§×‘×¦×™× ×©×œ ×”-chunk
    root_summary = build_repo_summary_text(snapshot, max_files=40)

    files_lines = []
    for fi in files_chunk:
        files_lines.append(
            f"- {fi.rel_path} (lines={fi.n_lines}, bytes={fi.size_bytes}) â€” {fi.header}"
        )
    files_text = "\n".join(files_lines)

    phases_lines = []
    for ph in sorted(phases, key=lambda p: p.order):
        phases_lines.append(f"- {ph.id}: {ph.name} (order={ph.order})")
    phases_text = "\n".join(phases_lines)

    return textwrap.dedent(
        f"""
        You are designing per-file upgrade tasks for a hedge-fund-grade pairs-trading system.

        GLOBAL CONTEXT
        ==============
        {HEDGE_FUND_BRIEF}

        Project snapshot (trimmed)
        --------------------------
        {root_summary}

        Existing upgrade phases
        -----------------------
        {phases_text}

        FILE CHUNK {chunk_index+1}/{total_chunks}
        ==========================
        Below is the list of files you must cover in THIS chunk only:

        {files_text}

        TASK
        ====
        For **each file listed above**, produce a JSON object describing its role and concrete upgrade tasks.

        The output MUST be **pure JSON** of the form:

        {{
          "files": [
            {{
              "rel_path": "relative/path/to/file.py",
              "role": "short description of what this file should represent in a hedge-fund architecture",
              "priority": "high|medium|low",
              "categories": [
                "one or more of: 'web_ui', 'api', 'data_ingest', 'research', 'backtest', 'live_trading', 'risk', 'infra', 'utils', 'tests', 'other'"
              ],
              "tasks": [
                "Concrete todo item for this specific file (short)",
                "Another todo item (short)",
                "Use 2â€“6 tasks depending on priority"
              ],
              "phase_ids": [
                "ids of phases where this file is primarily modified, e.g. ['phase_architecture', 'phase_live_trading']"
              ]
            }},
            ...
          ]
        }}

        RULES
        =====
        - You MUST include an entry in "files" for EVERY file in this chunk.
        - You MUST NOT include files that are not listed in this chunk.
        - Keep text concise and avoid repetition.
        - Use reasonable priorities:
          * 'high' for core/ root/ scripts/ pieces in architecture, data, execution, web, risk.
          * 'medium' for supporting modules.
          * 'low' for small helpers/utilities.
        - Make sure phase_ids refer only to the existing phase ids: {", ".join(p.id for p in phases)}.
        - Do NOT include a top-level "phases" key here.
        - Do NOT use markdown. Return valid JSON only.
        """
    ).strip()

# ======================================================================
# ×‘× ×™×™×ª ×¤×¨×•××¤×˜ ×œ×©×“×¨×•×’ ×§×•×‘×¥ ×™×—×™×“
# ======================================================================

def build_upgrade_file_prompt(
    *,
    snapshot: RepoSnapshot,
    plan: UpgradePlan,
    target_file: FilePlan,
    current_source: str,
) -> str:
    """
    ××™×™×¦×¨ ×¤×¨×•××¤×˜ ××¤×•×¨×˜ ×¢×‘×•×¨ ×§×•×‘×¥ ×™×—×™×“: ×ª×™××•×¨ ×ª×¤×§×™×“ ×”×§×•×‘×¥ + ×”×˜××¡×§×™× + ×§×•× ×˜×§×¡×˜.
    """
    summary = build_repo_summary_text(snapshot, max_files=80)

    # ×¡×™×›×•× ×§×¦×¨ ×©×œ ×”×˜××¡×§×™× ×œ×§×•×‘×¥
    tasks_bullets = "\n".join(f"- {t}" for t in target_file.tasks) or "- (no tasks in plan)"

    # ×‘××™×œ×• phases ×”×§×•×‘×¥ ××©×ª×ª×£
    phases_by_id = {ph.id: ph for ph in plan.phases}
    phase_lines: List[str] = []
    for pid in target_file.phase_ids:
        ph = phases_by_id.get(pid)
        if not ph:
            continue
        phase_lines.append(f"- {pid}: {ph.name} (order={ph.order})")
    phases_text = "\n".join(phase_lines) or "- (file not mapped to any phase explicitly)"

    # ×§×•× ×˜×§×¡×˜ ×§×¦×¨ ×¢×œ ×¤×¨×•×™×§×˜×™× × ×•×¡×¤×™× â€“ ×‘××™×•×—×“ ×¢×œ ×›×™×•×•× ×™ ×§×¨×Ÿ ×’×™×“×•×¨
    other_high_priority_files = [
        f for f in plan.files if f.priority == "high" and f.rel_path != target_file.rel_path
    ]
    other_high_lines: List[str] = []
    for f in other_high_priority_files[:15]:
        cats = ",".join(f.categories)
        other_high_lines.append(f"- {f.rel_path}  [{cats}]: {f.role}")
    others_text = "\n".join(other_high_lines) or "- (no other high-priority files listed)"

    return textwrap.dedent(
        f"""
        You are editing ONE file inside a pairs-trading project that must be upgraded to
        **hedge-fund-grade live trading**.

        GLOBAL CONTEXT
        ==============
        {HEDGE_FUND_BRIEF}

        Project snapshot (trimmed)
        --------------------------
        {summary}

        Target file (from the upgrade plan)
        ===================================
        - path: {target_file.rel_path}
        - role: {target_file.role}
        - priority: {target_file.priority}
        - categories: {", ".join(target_file.categories) if target_file.categories else "(none)"}

        This file participates in phases:
        ---------------------------------
        {phases_text}

        Concrete tasks for THIS file
        ============================
        {tasks_bullets}

        Other high-priority files for reference
        =======================================
        {others_text}

        CURRENT FILE CONTENT
        ====================
        ```python
        {current_source}
        ```

        YOUR JOB
        ========
        - Bring this file to **production / hedge-fund-grade** quality while:
          * Respecting the tasks listed for this file.
          * Keeping backwards compatibility as much as reasonable (avoid breaking imports/APIs silently).
          * Minimizing diff size: prefer focused refactors over rewrites.
          * Improving type hints, docstrings, logging, and risk-safety checks where relevant.
          * Improving integration with data layer, live trading, risk, and web layers where appropriate.

        - If you detect obvious bugs, fix them.
        - If the file is obsolete, add a clear comment at the top explaining how it should be replaced.

         OUTPUT FORMAT (STRICT)
        ======================
        1. A short section "Summary of changes" as markdown bullets (max ~10 bullets).
        2. A single ```python``` block containing the **FULL updated file**. This block is MANDATORY.
           - If you are unsure or cannot improve the file, STILL return the original file inside the ```python``` block.
           - Do NOT omit the ```python``` block under any circumstances.
        3. A "Sanity checklist" section with manual tests I should run (pytest, manual run, etc.).


        Do NOT modify any other files in this response; only this one fileâ€™s contents are allowed in the code block.
        """
    ).strip()


# ======================================================================
# ×”××¨×” ×-JSON dict ×œ-UpgradePlan
# ======================================================================

def plan_from_dict(d: Dict[str, Any]) -> UpgradePlan:
    phases: List[Phase] = []
    for ph in d.get("phases", []):
        phases.append(
            Phase(
                id=ph["id"],
                name=ph["name"],
                order=int(ph.get("order", 0)),
                description=ph.get("description", ""),
                milestones=list(ph.get("milestones", []) or []),
            )
        )

    files: List[FilePlan] = []
    for f in d.get("files", []):
        files.append(
            FilePlan(
                rel_path=f["rel_path"],
                role=f.get("role", ""),
                priority=f.get("priority", "medium"),
                categories=list(f.get("categories", []) or []),
                tasks=list(f.get("tasks", []) or []),
                phase_ids=list(f.get("phase_ids", []) or []),
            )
        )

    return UpgradePlan(
        project_root=d.get("project_root", ""),
        phases=phases,
        files=files,
    )


def plan_to_dict(plan: UpgradePlan) -> Dict[str, Any]:
    return {
        "project_root": plan.project_root,
        "phases": [asdict(ph) for ph in plan.phases],
        "files": [asdict(f) for f in plan.files],
    }


# ======================================================================
# ×™×¦×™×¨×ª Markdown ×× ×•×©×™ ××”×ª×•×›× ×™×ª
# ======================================================================

def render_plan_markdown(plan: UpgradePlan) -> str:
    lines: List[str] = []
    lines.append(f"# Hedge-Fund Upgrade Plan")
    if plan.project_root:
        lines.append(f"_Project root: {plan.project_root}_")
    lines.append("")

    # Phases
    lines.append("## Phases")
    for ph in sorted(plan.phases, key=lambda p: p.order):
        lines.append(f"### {ph.order}. {ph.name}  (`{ph.id}`)")
        if ph.description:
            lines.append("")
            lines.append(ph.description)
        if ph.milestones:
            lines.append("")
            lines.append("**Milestones:**")
            for m in ph.milestones:
                lines.append(f"- {m}")
        lines.append("")

    # Files
    lines.append("## Files & Tasks")
    for f in sorted(plan.files, key=lambda x: x.rel_path):
        lines.append(f"### `{f.rel_path}`")
        lines.append(f"- Role: {f.role or '(n/a)'}")
        lines.append(f"- Priority: `{f.priority}`")
        if f.categories:
            lines.append(f"- Categories: {', '.join(f.categories)}")
        if f.phase_ids:
            lines.append(f"- Phases: {', '.join(f.phase_ids)}")
        if f.tasks:
            lines.append("")
            lines.append("**Tasks:**")
            for t in f.tasks:
                lines.append(f"- {t}")
        lines.append("")

    return "\n".join(lines)


# ======================================================================
# ×¤×§×•×“×•×ª CLI
# ======================================================================

def cmd_plan(args: argparse.Namespace) -> None:
    root: Path = args.root.resolve()
    debug(f"Scanning repo at: {root}")
    snapshot = scan_repo(root)

    if not snapshot.files:
        raise SystemExit("No Python files found under root.")

    system_instructions = load_master_prompt(args.master_prompt)

    # ============================
    # ×©×œ  code_block 1: ×œ×‘× ×•×ª phases ×‘×œ×‘×“
    # ============================
    debug("Requesting phases (no files yet)...")
    phases_prompt = build_phases_prompt(snapshot)
    phases_json = call_gpt_json(
        model=args.model,
        instructions=system_instructions,
        user_input=phases_prompt,
        reasoning_effort=args.reasoning,
        max_output_tokens=args.max_tokens,
    )

    phases_raw = phases_json.get("phases", [])
    if not isinstance(phases_raw, list) or not phases_raw:
        raise RuntimeError(f"Model did not return a valid 'phases' array. Got: {phases_json}")

    phases: List[Phase] = []
    for ph in phases_raw:
        phases.append(
            Phase(
                id=ph["id"],
                name=ph["name"],
                order=int(ph.get("order", 0)),
                description=ph.get("description", ""),
                milestones=list(ph.get("milestones", []) or []),
            )
        )

    debug(f"Received {len(phases)} phases.")

    # ============================
    # ×©×œ×‘ 2: ×œ×•×œ××” ×¢×œ ×§×‘×¦×™× (chunks)
    # ============================
    chunk_size = args.chunk_size
    files_plans: List[FilePlan] = []

    total_files = len(snapshot.files)
    total_chunks = (total_files + chunk_size - 1) // chunk_size

    debug(f"Building file plans in {total_chunks} chunks (chunk_size={chunk_size}, total_files={total_files}).")

    for ci in range(total_chunks):
        start = ci * chunk_size
        end = min(start + chunk_size, total_files)
        chunk = snapshot.files[start:end]

        debug(f"Requesting file plans for chunk {ci+1}/{total_chunks} (files {start+1}-{end})...")
        chunk_prompt = build_file_chunk_prompt(
            snapshot=snapshot,
            phases=phases,
            files_chunk=chunk,
            chunk_index=ci,
            total_chunks=total_chunks,
        )

        chunk_json = call_gpt_json(
            model=args.model,
            instructions=system_instructions,
            user_input=chunk_prompt,
            reasoning_effort=args.reasoning,
            max_output_tokens=args.max_tokens,
        )

        chunk_files_raw = chunk_json.get("files", [])
        if not isinstance(chunk_files_raw, list) or not chunk_files_raw:
            debug(f"[WARN] Empty or invalid 'files' in chunk {ci+1}; skipping.")
            continue

        for f in chunk_files_raw:
            try:
                fp = FilePlan(
                    rel_path=f["rel_path"],
                    role=f.get("role", ""),
                    priority=f.get("priority", "medium"),
                    categories=list(f.get("categories", []) or []),
                    tasks=list(f.get("tasks", []) or []),
                    phase_ids=list(f.get("phase_ids", []) or []),
                )
                files_plans.append(fp)
            except Exception as exc:
                debug(f"[WARN] Failed to parse FilePlan in chunk {ci+1}: {exc}")

    debug(f"Collected {len(files_plans)} file plans from all chunks.")

    # ============================
    # ×‘× ×™×™×ª UpgradePlan ×•×©××™×¨×”
    # ============================
    plan = UpgradePlan(
        project_root=str(root),
        phases=phases,
        files=files_plans,
    )

    json_path = root / args.plan_json
    md_path = root / args.plan_md

    save_text(json_path, json.dumps(plan_to_dict(plan), indent=2, ensure_ascii=False))
    save_text(md_path, render_plan_markdown(plan))

    debug(f"Wrote JSON plan: {json_path}")
    debug(f"Wrote Markdown plan: {md_path}")
    print()
    print(f"Plan created with {len(plan.phases)} phases and {len(plan.files)} files (chunk_size={chunk_size}).")
    print(f"- JSON : {json_path}")
    print(f"- Markdown : {md_path}")


def load_existing_plan(root: Path, json_name: str) -> UpgradePlan:
    path = (root / json_name).resolve()
    if not path.is_file():
        raise SystemExit(f"Plan JSON not found: {path}. Run 'plan' first.")
    data = json.loads(path.read_text(encoding="utf-8"))
    return plan_from_dict(data)


def find_file_plan(plan: UpgradePlan, rel_path: str) -> Optional[FilePlan]:
    rel_norm = rel_path.replace("\\", "/")
    for f in plan.files:
        if f.rel_path.replace("\\", "/") == rel_norm:
            return f
    return None


def cmd_upgrade_file(args: argparse.Namespace) -> None:
    """
    ××©×“×¨×’ ×§×•×‘×¥ ×™×—×™×“ ×œ×¤×™ ×”-Plan.

    ×œ×•×’×™×§×” ×—×“×©×”:
    ------------
    - always: Dry-run (apply=False) â†’ ×§×•×¨× ×œ-GPT, ×©×•××¨ ××ª ×›×œ ×”×ª×©×•×‘×” ×œ-dump, ××—×œ×¥ ×§×•×“ ×•××“×¤×™×¡ Summary.
    - apply=True:
        1) ×× ×™×© dump ×§×™×™× (logs/upgrade_<safe_rel>_dump.md) â†’ ××©×ª××© ×‘×• ×•×œ× ×§×•×¨× ×œ-GPT ×©×•×‘.
        2) ×× ××™×Ÿ dump â†’ ×§×•×¨× ×œ-GPT, ×©×•××¨ dump, ××—×œ×¥ ×§×•×“ ×•××™×™×©×.
    - ×œ× ×›×•×ª×‘ ×œ×§×•×‘×¥ ×× ××™×Ÿ ×‘×œ×•×§ ```python``` ××• ×× ×”×§×•×“ ×–×”×” ×œ××§×•×¨.
    """
    root: Path = args.root.resolve()
    plan = load_existing_plan(root, args.plan_json)

    target_path = (root / args.file).resolve()
    if not target_path.is_file():
        raise SystemExit(f"Target file not found: {target_path}")

    rel = str(target_path.relative_to(root))
    file_plan = find_file_plan(plan, rel)
    if not file_plan:
        raise SystemExit(f"File `{rel}` not found in plan. Re-run 'plan' or check JSON.")

    debug(f"Upgrading file according to plan: {rel}")

    snapshot = scan_repo(root)
    current_source = load_text(target_path)
    system_instructions = load_master_prompt(args.master_prompt)

    # × ×ª×™×‘×™ ×œ×•×’ ×•×“×××¤
    logs_dir = PROJECT_ROOT / "logs"
    logs_dir.mkdir(exist_ok=True)
    safe_rel = rel.replace("\\", "_").replace("/", "_")
    dump_path = logs_dir / f"upgrade_{safe_rel}_dump.md"

    response_text: str

    # ×× apply=True ×•×™×© ×›×‘×¨ dump â†’ × ×©×ª××© ×‘×• ×•×œ× × ×§×¨× ×©×•×‘ ×œ-GPT
    if args.apply and dump_path.is_file():
        debug(f"Using existing dump for {rel}: {dump_path}")
        response_text = load_text(dump_path)
    else:
        # ×§×•×¨××™× ×œ-GPT ×•××™×™×¦×¨×™× dump ×—×“×©
        user_input = build_upgrade_file_prompt(
            snapshot=snapshot,
            plan=plan,
            target_file=file_plan,
            current_source=current_source,
        )

        debug(f"Calling model={args.model} for file upgrade (apply={args.apply})")
        response_text = call_gpt_raw(
            model=args.model,
            instructions=system_instructions,
            user_input=user_input,
            reasoning_effort=args.reasoning,
            max_output_tokens=args.max_tokens,
        )

        # ×©×•××¨×™× ××ª ×›×œ ×”×ª×©×•×‘×” ×œ-dump
        save_text(dump_path, response_text)
        debug(f"Full model response saved to: {dump_path}")

    # ××—×œ×¥ ×§×•×“ ××ª×•×š ×”-dump / ×”×ª×©×•×‘×”
    code = extract_code_block_from_markdown(response_text)
    if code is None:
        debug("WARNING: Could not find code/diff block in response; not modifying file.")
        print(response_text)
        return

    # × ×–×”×” ×× ×–×” diff ××• ×§×•×‘×¥ ××œ×:
    is_diff = (
        "```diff" in response_text
        or code.lstrip().startswith("@@")
        or code.lstrip().startswith("--- ")
        or code.lstrip().startswith("diff ")
    )

    if is_diff:
        debug("Detected unified diff in response; applying patch to current source.")
        new_source = apply_unified_diff(current_source, code)
    else:
        # ×× ×™×— ×©×–×” ×§×•×‘×¥ Python ××œ×
        new_source = code


    # ×× Apply: × ×›×ª×•×‘ ×œ×§×•×‘×¥ (×× ×™×© ×©×™× ×•×™ ×××™×ª×™)
    if args.apply:
        if code.strip() == current_source.strip():
            debug("No changes detected between generated code and current file; skipping write.")
            return
        backup = backup_file(target_path)
        debug(f"Backup written: {backup}")
        save_text(target_path, code)
        debug(f"File updated: {target_path}")
    else:
        debug("Dry run only: not writing file. Use --apply to save changes.")
        print("\n===== MODEL RESPONSE (truncated) =====\n")
        print(textwrap.shorten(response_text, width=5000, placeholder="\n... [truncated] ..."))



def cmd_upgrade_all(args: argparse.Namespace) -> None:
    root: Path = args.root.resolve()
    plan = load_existing_plan(root, args.plan_json)
    snapshot = scan_repo(root)
    system_instructions = load_master_prompt(args.master_prompt)

    # × ×¢×‘×•×¨ ×œ×¤×™ ×¡×“×¨ ×—×©×™×‘×•×ª ×•××– ×œ×¤×™ ×©×, ×›×“×™ ×©×§×•×“ ×§×¨×™×˜×™ ×™×§×‘×œ ×ª×©×•××ª ×œ×‘ ×§×•×“×.
    file_plans = sorted(
        plan.files,
        key=lambda f: ({"high": 0, "medium": 1, "low": 2}.get(f.priority, 1), f.rel_path),
    )

    for fp in file_plans:
        target_path = (root / fp.rel_path).resolve()
        if not target_path.is_file():
            debug(f"[SKIP] Missing file listed in plan: {fp.rel_path}")
            continue

        debug("=" * 80)
        debug(f"Upgrading {fp.rel_path} (priority={fp.priority}, apply={args.apply})")
        current_source = load_text(target_path)
        user_input = build_upgrade_file_prompt(
            snapshot=snapshot,
            plan=plan,
            target_file=fp,
            current_source=current_source,
        )

        try:
            response_text = call_gpt_raw(
                model=args.model,
                instructions=system_instructions,
                user_input=user_input,
                reasoning_effort=args.reasoning,
                max_output_tokens=args.max_tokens,
            )
        except Exception as exc:
            debug(f"ERROR calling model for {fp.rel_path}: {exc}")
            continue

        code = extract_code_block_from_markdown(response_text)
        if code is None:
            debug(f"[WARN] No python code block for {fp.rel_path}; skipping file update.")
            continue

        if args.apply:
            backup = backup_file(target_path)
            debug(f"[{fp.rel_path}] Backup: {backup}")
            save_text(target_path, code)
            debug(f"[{fp.rel_path}] Updated.")
        else:
            debug(f"[{fp.rel_path}] Dry run only (no write).")

    debug("Finished upgrade-all.")


def cmd_show_plan(args: argparse.Namespace) -> None:
    root: Path = args.root.resolve()
    plan = load_existing_plan(root, args.plan_json)

    print(f"Hedge-fund upgrade plan for project: {plan.project_root}")
    print(f"- Phases: {len(plan.phases)}")
    print(f"- Files : {len(plan.files)}")
    print("")

    print("PHASES:")
    for ph in sorted(plan.phases, key=lambda p: p.order):
        print(f"  {ph.order}. {ph.name}  ({ph.id})")
    print("")

    if args.verbose:
        print("FILES:")
        for f in sorted(plan.files, key=lambda x: x.rel_path):
            cats = ", ".join(f.categories)
            print(f"  - {f.rel_path}  [{f.priority}]  ({cats})")
            if args.verbose >= 2:
                for t in f.tasks:
                    print(f"      * {t}")


# ======================================================================
# CLI setup
# ======================================================================


def build_parser() -> argparse.ArgumentParser:
    p = argparse.ArgumentParser(
        description="GPT-based hedge-fund upgrade agent for your pairs-trading project.",
    )
    p.add_argument(
        "--model",
        type=str,
        default=DEFAULT_MODEL,
        help=f"OpenAI model id (default: {DEFAULT_MODEL})",
    )
    p.add_argument(
        "--reasoning",
        type=str,
        default=DEFAULT_REASONING,
        help="Reasoning effort for GPT-5/GPT-5.1 models (none/low/medium/high).",
    )
    p.add_argument(
        "--max-tokens",
        type=int,
        default=8192,
        help="max_output_tokens for the Responses API.",
    )
    p.add_argument(
        "--chunk-size",
        type=int,
        default=40,
        help="Number of files per GPT chunk when building the plan (to avoid huge JSON).",
    )

    sub = p.add_subparsers(dest="command", required=True)

    # plan
    sp = sub.add_parser("plan", help="Scan repo and generate hedge-fund upgrade plan + tasks for each file.")
    sp.add_argument("--root", type=Path, default=Path("."), help="Project root directory.")
    sp.add_argument(
        "--master-prompt",
        type=Path,
        default=DEFAULT_MASTER_PROMPT,
        help="Path to your master prompt (system instructions).",
    )
    sp.add_argument(
        "--plan-json",
        type=str,
        default=DEFAULT_PLAN_JSON,
        help="Output JSON plan filename.",
    )
    sp.add_argument(
        "--plan-md",
        type=str,
        default=DEFAULT_PLAN_MD,
        help="Output Markdown plan filename.",
    )
    sp.set_defaults(func=cmd_plan)

    # upgrade-file
    sf = sub.add_parser("upgrade-file", help="Upgrade a single file using the existing plan.")
    sf.add_argument("--root", type=Path, default=Path("."), help="Project root directory.")
    sf.add_argument("--file", type=str, required=True, help="Relative path of file to upgrade.")
    sf.add_argument(
        "--master-prompt",
        type=Path,
        default=DEFAULT_MASTER_PROMPT,
        help="Path to your master prompt (system instructions).",
    )
    sf.add_argument(
        "--plan-json",
        type=str,
        default=DEFAULT_PLAN_JSON,
        help="Plan JSON filename (must exist).",
    )
    sf.add_argument(
        "--apply",
        action="store_true",
        help="Actually overwrite the file (with .gpt_backup). Default: dry run.",
    )
    sf.set_defaults(func=cmd_upgrade_file)

    # upgrade-all
    sa = sub.add_parser(
        "upgrade-all",
        help="Upgrade all files from the plan, ordered by priority. Think of it as Aâ†’Z automation.",
    )
    sa.add_argument("--root", type=Path, default=Path("."), help="Project root directory.")
    sa.add_argument(
        "--master-prompt",
        type=Path,
        default=DEFAULT_MASTER_PROMPT,
        help="Path to your master prompt (system instructions).",
    )
    sa.add_argument(
        "--plan-json",
        type=str,
        default=DEFAULT_PLAN_JSON,
        help="Plan JSON filename (must exist).",
    )
    sa.add_argument(
        "--apply",
        action="store_true",
        help="If set, writes changes to disk (with backups). Otherwise dry-run.",
    )
    sa.set_defaults(func=cmd_upgrade_all)

    # show-plan
    ss = sub.add_parser("show-plan", help="Print a quick summary of the existing plan.")
    ss.add_argument("--root", type=Path, default=Path("."), help="Project root directory.")
    ss.add_argument(
        "--plan-json",
        type=str,
        default=DEFAULT_PLAN_JSON,
        help="Plan JSON filename (must exist).",
    )
    ss.add_argument(
        "-v",
        "--verbose",
        action="count",
        default=0,
        help="Show more detail (e.g. tasks for each file with -vv).",
    )
    ss.set_defaults(func=cmd_show_plan)

    return p


def main() -> None:
    parser = build_parser()
    args = parser.parse_args()
    args.func(args)


if __name__ == "__main__":
    main()
